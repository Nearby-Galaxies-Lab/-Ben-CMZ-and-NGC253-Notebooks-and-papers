{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5c8564-b572-4681-9045-0d4ddc6bd720",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#HCO+ 1-0 all resses starting at 4.3\n",
    "\n",
    "\n",
    "Num=0\n",
    "Overlaps=0#4\n",
    "Ram_Limiter=1#What percent of the cube my ram can handle\n",
    "LineN=\"HCO+ J1-0_New\"\n",
    "Name = \"HCO+ J1-0_Abs_New\"\n",
    "name = \"HCO+ J1_0_CM_Contours_DS_10_Abs_New.jpeg\"\n",
    "Num_per_kg= 6.0221409*10**23/(2.8*10**-3)#6.0221409*10**23/29.0180*10**-3#num/kg for h2\n",
    "\n",
    "Abs_Levels = [\"All\",\"None\",\"No Clusters\", \"None (m)\", \"None All Channels\"]\n",
    "\n",
    "\n",
    "\n",
    "iterations = 5\n",
    "iter_factor = 1/5\n",
    "Line_Name = '_NGC_HCOp_J1_0_'\n",
    "ovs = 3 #over sample factor for beam\n",
    "min_vel = 3.3#km/s\n",
    "FOV = [70,360]#pc\n",
    "Min_res=4.3*u.pc#Smallest resolution\n",
    "Min_beam_req = 1/5\n",
    "\n",
    "Params = [iterations,iter_factor,ovs,min_vel,FOV,Min_res,Min_beam_req]\n",
    "savePath='/home/ben/Documents/Grad Stuff/MM data/Result Files'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "np.savetxt(Line_Name+\"_Params\", Params,fmt='%s')#[iterations,iter_factor ,Line_Name,Name,ovs,min_vel,FOV,Min_res,Min_beam_req]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import sys, traceback\n",
    "print(sys.executable)\n",
    "print(sys.version)\n",
    "print(sys.version_info)\n",
    "from __future__ import print_function\n",
    "import pyspeckit\n",
    "import pylab as pl\n",
    "import astropy.units as u\n",
    "\n",
    "\n",
    "from scousepy import scouse\n",
    "import scousepy \n",
    "from scousepy.configmaker import ConfigMaker\n",
    "print('scousepy',scousepy.__file__ )\n",
    "from scousepy.io import output_ascii_indiv\n",
    "import math\n",
    "import astropy\n",
    "print('astropy',astropy.__version__ )\n",
    "from spectral_cube import SpectralCube      # This is a handy package for working with 3D data cubes\n",
    "from spectral_cube import LazyMask\n",
    "from astropy.coordinates import SkyCoord\n",
    "from reproject import reproject_interp      \n",
    "from reproject.mosaicking import find_optimal_celestial_wcs \n",
    "import regions\n",
    "import reproject\n",
    "print('reproject',reproject.__version__)\n",
    "import spectral_cube\n",
    "print('spectral_cube',spectral_cube.__version__)\n",
    "import numpy as np                          \n",
    "import pylab                                \n",
    "import matplotlib \n",
    "import matplotlib.gridspec as gridspec                                                                                             \n",
    "import scipy\n",
    "import astropy.io.fits as fits                                                          \n",
    "from astropy.wcs import WCS                 \n",
    "from astropy import units as u              \n",
    "import pyspeckit as psk   \n",
    "import astrodendro\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib import pyplot as plt\n",
    "# Suppress warnings we don't care about:\n",
    "import sys\n",
    "import gc\n",
    "from astropy.convolution import Gaussian1DKernel\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "%matplotlib inline\n",
    "from astrodendro.analysis import PPVStatistic\n",
    "import os\n",
    "\n",
    "print(astrodendro.__file__)\n",
    "\n",
    "from matplotlib.patches import Ellipse\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import radio_beam\n",
    "from astropy.table import Table\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.optimize import leastsq\n",
    "#%matplotlib widget\n",
    "Num_per_kg= 6.0221409*10**23/(2.8*10**-3)#6.0221409*10**23/29.0180*10**-3#num/kg for h2\n",
    "\n",
    "#Create a function that uses the dendrogram input to calculate all the quantities, and has the size and linewidth requirements of the Shetty paper\n",
    "#Requires the computed dendrogram, the data from the line image, the velocity axis, and the data from the Continuum image, as well as metadata for the structures\n",
    "#Finds Size, Linewidth, Luminosity, and Column Density of a structure for each structure and returns them in [[][]] arrays [Leaves][Branches]\n",
    "#Continuum is in Jansky/Beam, Line data should have the unit specified in the metadata as 'data_unit'\n",
    "\n",
    "def Dendro_Arrays(Dendrogram,LineData,DataVel,ContData,metadata,ColD = True,beam_size=999,beam_req = 999999):\n",
    "    SizeA,SigmaA,LuminA,CDA,SIDS,MOM0_FLUX,Distances,V_rms_err = [[],[],[],[]],[[],[],[],[]],[[],[]],[[],[]],[[],[]],[[],[]],[[],[]],[[],[]]\n",
    "    print(metadata)\n",
    "    \n",
    "    d_copy= Dendrogram\n",
    "    #catalog = astrodendro.ppv_catalog(d, metadata)\n",
    "    center = SkyCoord('00h47m33.14s' ,'-25d17m17.52s',frame='icrs')\n",
    "    center_ra_pix,center_dec_pix = int(metadata['wcsu'][:][:][0].world_to_pixel(center)[0]),int(metadata['wcsu'][:][:][0].world_to_pixel(center)[1])\n",
    "    sliced= LineData[12]\n",
    "    CubeShape = np.shape(sliced)\n",
    "    for t in Dendrogram.all_structures: \n",
    "\n",
    "        I = t.indices()\n",
    "        Cont = True\n",
    "        if t.is_branch:\n",
    "                if t.parent==None:\n",
    "                    Cont=True\n",
    "                else:\n",
    "                    Cont = True\n",
    "        \n",
    "        for lmi in range(len(I[0])):\n",
    "            NansNE=0\n",
    "            NansSE=0\n",
    "            NansNW=0\n",
    "            NansSW=0\n",
    "            Length = 10\n",
    "            #I[1][lmi+10]>\n",
    "            for lmj in range(Length):\n",
    "                #Check four 45 degree prongs from each point and see if they have at least 7 nans in 10 pixels. If that happens its too close to the boundary\n",
    "                try:\n",
    "\n",
    "                    if(sliced[I[1][lmi]+lmj,I[2][lmi]-lmj]>0 or sliced[I[1][lmi]+lmj,I[2][lmi]-lmj]<0 ):\n",
    "                        pass\n",
    "                    else:\n",
    "                        NansSE+=1\n",
    "                    if(sliced[I[1][lmi]-lmj,I[2][lmi]-lmj]>0 or sliced[I[1][lmi]-lmj,I[2][lmi]-lmj]<0 ):\n",
    "                        pass\n",
    "                    else:\n",
    "                        NansSW+=1\n",
    "                    if(sliced[I[1][lmi]-lmj,I[2][lmi]+lmj]>0 or sliced[I[1][lmi]-lmj,I[2][lmi]+lmj]<0 ):\n",
    "                        pass\n",
    "                    else:\n",
    "                        NansNW+=1\n",
    "                    if(sliced[I[1][lmi]+lmj,I[2][lmi]+lmj]>0 or sliced[I[1][lmi]+lmj,I[2][lmi]+lmj]<0 ):\n",
    "                        pass\n",
    "                    else:\n",
    "                        NansNE+=1\n",
    "                except:\n",
    "                    #only fails if the I goes close to the boundary of the cube and tries to get a pixel outside the cube\n",
    "                    Cont = False\n",
    "            if(NansNE>Length-3 or NansNW>Length-3 or NansSE>Length-3 or NansSW>Length-3):\n",
    "                Cont=False\n",
    "                break\n",
    "\n",
    "        if(Cont):\n",
    "            s = PPVStatistic(t,metadata=metadata)\n",
    "            s_radius = s.radius\n",
    "            s_v_rms = s.v_rms\n",
    "            if((float((s_radius*np.pi/180*3.5/u.deg)))*10**6<beam_size*7 and (float((s_radius*np.pi/180*3.5/u.deg)))*10**6>beam_size*beam_req and (float(s_v_rms/u.km*u.s))>.01):\n",
    "            \n",
    "            \n",
    "\n",
    "                nproj_pix=len(set(zip(*tuple(I[i] for i in [1,2]))))\n",
    "                v_IWM = np.nansum(LineData[I]*(DataVel[I[0]])/u.km*u.s)/np.nansum(LineData[I])\n",
    "                sig_Sh = np.sqrt(np.nansum(LineData[I]*((DataVel[I[0]])/u.km*u.s-v_IWM)**2)/np.nansum(LineData[I])) \n",
    "                \n",
    "                #The flux from the continuum\n",
    "                #Convert to Jansky from Jansky per beam:\n",
    "                if(ColD ==True):\n",
    "                    Cont_Flux=0\n",
    "\n",
    "                    proj = tuple(set(zip(*tuple(I[i] for i in [1,2]))))\n",
    "                    for lmi in range(len(proj)):\n",
    "\n",
    "                        Cont_Flux+=ContData[proj[lmi]]\n",
    "                    Cont_Flux=Cont_Flux/(metadata['beam_area_ratioc']*(2*np.sqrt(2*np.log(2))))*u.pix**2*u.beam/u.beam*u.Jy#SHould be input as Jansky /beam and will be converted to Jansky, then to unitless. The beam is changed from FWHM to Gaussian\n",
    "                    Dust_Column = Flux_to_Mass(Cont_Flux)*Num_per_kg/((s_radius*np.pi/180*3.5/u.deg)**2*(3.086*10**24)**2)/np.pi*(1.989*10**30*u.kg/u.M_sun)/u.kg\n",
    "                else:\n",
    "                    Dust_Column=0\n",
    "                if(str(Dust_Column) == str(np.nan) or str(Dust_Column)==str(np.inf)):\n",
    "                    Dust_Column=0\n",
    "                lum = Flux_to_Lum(s.flux)\n",
    "                s_flux = s.flux\n",
    "\n",
    "                Index = tuple(I[i] for i in [0,1,2])\n",
    "                K_Km_s_Flux=np.nansum(LineData[Index]*metadata[\"velocity_scale\"])#Find the total flux from the structures in K km/s, assuming the input data is in K as it should be, \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                Distance = np.sqrt((float(s.x_cen/u.pix)-center_ra_pix)**2+(float(s.y_cen/u.pix)- center_dec_pix)**2)*metadata['spatial_scale']*np.pi/180*3.5*10**6/u.deg#pc dist from barycenter\n",
    "                \n",
    "                \n",
    "                V_err= Get_V_rms_err(dend1=d_copy,idx=int(t.idx),struct=t,m=m,NF=1,iterations=5,metadata=metadata)\n",
    "                \n",
    "                \n",
    "                if(t.is_leaf):\n",
    "\n",
    "                    SizeA[0].append((float((s_radius*np.pi/180*3.5/u.deg)))) #define size as astrodendro\n",
    "                    SigmaA[0].append((float(s_v_rms/u.km*u.s)))#\n",
    "                    CDA[0].append(float(Dust_Column))\n",
    "                    LuminA[0].append(float(lum*u.Hz*u.s/u.erg))\n",
    "                    SIDS[0].append(float(t.idx))\n",
    "                    MOM0_FLUX[0].append(float(K_Km_s_Flux*u.s/u.km))\n",
    "                    Distances[0].append(float(Distance))\n",
    "                    V_rms_err[0].append(float(V_err))\n",
    "                if(t.is_branch\t):\n",
    "\n",
    "                    SizeA[1].append((float((s_radius*np.pi/180*3.5/u.deg)))) #define size as astrodendro\n",
    "                    SigmaA[1].append((float(s_v_rms/u.km*u.s)))#\n",
    "                    CDA[1].append(float(Dust_Column))\n",
    "                    LuminA[1].append(float(lum*u.Hz*u.s/u.erg))\n",
    "                    SIDS[1].append(float(t.idx))\n",
    "                    MOM0_FLUX[1].append(float(K_Km_s_Flux*u.s/u.km))\n",
    "                    Distances[1].append(float(Distance))\n",
    "                    V_rms_err[1].append(float(V_err))\n",
    "                del s\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "    SizeA[0] = np.array(SizeA[0],dtype=type(1.))\n",
    "    SizeA[1] = np.array(SizeA[1],dtype=type(1.))\n",
    "    SizeA[2] = np.array(SizeA[2],dtype=type(1.))\n",
    "    SizeA[3] = np.array(SizeA[3],dtype=type(1.))\n",
    "    SigmaA[0] = np.array(SigmaA[0],dtype=type(1.))\n",
    "    SigmaA[1] = np.array(SigmaA[1],dtype=type(1.))\n",
    "    SigmaA[2] = np.array(SigmaA[2],dtype=type(1.))\n",
    "    SigmaA[3] = np.array(SigmaA[3],dtype=type(1.))\n",
    "    CDA[0] = np.array(CDA[0],dtype=type(1.))\n",
    "    CDA[1] = np.array(CDA[1],dtype=type(1.))\n",
    "    LuminA[0] = np.array(LuminA[0],dtype=type(1.))\n",
    "    LuminA[1] = np.array(LuminA[1],dtype=type(1.))\n",
    "    SIDS[0] = np.array(SIDS[0],dtype=type(1.))\n",
    "    SIDS[1] = np.array(SIDS[1],dtype=type(1.))\n",
    "    MOM0_FLUX[0] = np.array(MOM0_FLUX[0],dtype=type(1.))\n",
    "    MOM0_FLUX[1] = np.array(MOM0_FLUX[1],dtype=type(1.))\n",
    "    Distances[0] = np.array(Distances[0],dtype=type(1.))\n",
    "    Distances[1] = np.array(Distances[1],dtype=type(1.))\n",
    "    V_rms_err[0] = np.array(V_rms_err[0],dtype=type(1.))\n",
    "    V_rms_err[1] = np.array(V_rms_err[1],dtype=type(1.))\n",
    "    \n",
    "    return np.array(SizeA),np.array(SigmaA),np.array(CDA),np.array(LuminA),np.array(SIDS),np.array(MOM0_FLUX),np.array(Distances),np.array(V_rms_err)\n",
    "\n",
    "#Make a function to make an image \n",
    "\n",
    "#Data to plot, minimum of color bar, maximum, WCS projection for coords, and position of the image in the larger figure\n",
    "def Make_Plot(Name,Name2,Data,vmin,vmax,WCS,rows,columns,index,show):\n",
    "    \n",
    "\n",
    "    ax = pylab.subplot(rows,columns,index,projection=WCS) \n",
    "    RA = ax.coords[0]                                                                  # \n",
    "    Dec = ax.coords[1]\n",
    "    im = pylab.imshow(Data,vmin=vmin,vmax=vmax,cmap='rainbow')\n",
    "    RA.set_ticks(size=-3)                                                                                      \n",
    "    Dec.set_ticks(size=-3) \n",
    "    RA.set_ticklabel(exclude_overlapping=True) \n",
    "    Dec.set_ticklabel(exclude_overlapping=True)                                                                                     \n",
    "    pylab.xlabel('Right Ascension',fontsize=20,labelpad=1)                               \n",
    "    pylab.ylabel('Declination',fontsize=20,labelpad=1)\n",
    "    ax.tick_params(axis = 'both', which = 'major', labelsize = 15)    \n",
    "    cb=pylab.colorbar(im,fraction=0.1,pad=0.0)                                     \n",
    "    cb.set_label(label=Name,fontsize=10,rotation=270,labelpad=20) \n",
    "    cb.ax.tick_params(which = 'major', labelsize = 10)   \n",
    "    pylab.annotate(s=Name2,fontsize=10,xy=(0.02,1.05),xycoords=\"axes fraction\")  \n",
    "    if(show==True):\n",
    "        pylab.show()\n",
    "def Make_Plot_Anno(Name,Name2,Data,vmin,vmax,WCS,rows,columns,index,show,pos1,pos2):\n",
    "    \n",
    "\n",
    "    ax = pylab.subplot(rows,columns,index,projection=WCS) \n",
    "    RA = ax.coords[0]                                                                  # \n",
    "    Dec = ax.coords[1]\n",
    "    im = pylab.imshow(Data,vmin=vmin,vmax=vmax,cmap='rainbow')\n",
    "    RA.set_ticks(size=-3)                                                                                      \n",
    "    Dec.set_ticks(size=-3) \n",
    "    RA.set_ticklabel(exclude_overlapping=True) \n",
    "    Dec.set_ticklabel(exclude_overlapping=True)                                                                                     \n",
    "    pylab.xlabel('Right Ascension',fontsize=20,labelpad=1)                               \n",
    "    pylab.ylabel('Declination',fontsize=20,labelpad=1)\n",
    "    ax.tick_params(axis = 'both', which = 'major', labelsize = 15)    \n",
    "    cb=pylab.colorbar(im,fraction=.1,pad=0.0)                                     \n",
    "    cb.set_label(label=Name,fontsize=10,rotation=270,labelpad=20) \n",
    "    cb.ax.tick_params(which = 'major', labelsize = 10)   \n",
    "    pylab.annotate(s=Name2,fontsize=10,xy=(pos1,pos2),xycoords=\"axes fraction\")  \n",
    "    if(show==True):\n",
    "        pylab.show()\n",
    "        \n",
    "        \n",
    "#Put this up here for the column density map\n",
    "def Flux_to_Mass(flux):\n",
    "    J_to_e = 10**-23*u.erg/u.s/u.cm**2/u.Hz/u.Jy\n",
    "    flux_erg = flux*J_to_e\n",
    "    L = 4*np.pi*(3.5*3.086*10**24)**2*flux_erg*u.cm**2 #Megaparsec is converted to cm\n",
    "    \n",
    "    \n",
    "    a_850 = 6.7*10**19*u.erg/u.s/u.Hz/u.M_sun #6.7+-1.7\n",
    "    \n",
    "    M_mol = L/a_850#Just in Solar mass*1.989*10**30*u.kg/u.M_sun #Determines mass of the cont for 850 in kg\n",
    "    return M_mol\n",
    "def Flux_to_Lum(flux):\n",
    "    J_to_e = 10**-23*u.erg/u.s/u.cm**2/u.Hz/u.Jy\n",
    "    flux_erg = flux*J_to_e\n",
    "    L = 4*np.pi*(3.5*3.086*10**24)**2*flux_erg*u.cm**2 #Megaparsec is converted to cm\n",
    "    \n",
    "    return L\n",
    "\n",
    "\n",
    "def Get_V_rms_err(dend1,struct,idx,m,NF,iterations,metadata):\n",
    "    \n",
    "    \n",
    "    vs=[]\n",
    "    np.random.seed((99)**2*123)\n",
    "    for llll in range(iterations):\n",
    "        \n",
    "        #print(llll)\n",
    "        s = dend1.__getitem__(idx)\n",
    "        #s = struct#copy.deepcopy(struct)\n",
    "        #s2 = struct#copy.deepcopy(struct)\n",
    "        npixels = np.product(np.shape(s.values()))\n",
    "        #print(np.shape(s.values()),s.values())\n",
    "        \n",
    "        additional_noise = np.random.normal(0., m*NF, npixels)\n",
    "        additional_noise = np.reshape(additional_noise, np.shape(s.values()))\n",
    "        #add or subract noise to the values and calculate the v rms, them find the std of that array and\n",
    "        # call that the uncertainty in v rms for a structure\n",
    "        dat1P = dend1.data[s.indices()]\n",
    "        dend1.data[s.indices()]+= additional_noise\n",
    "        s = dend1.__getitem__(idx)\n",
    "        vs.append(float(PPVStatistic(s,metadata=metadata).v_rms/u.km*u.s))\n",
    "        dend1.data[s.indices()]= dat1P#reset the dend data\n",
    "        \n",
    "        dend1.data[s.indices()]-= additional_noise\n",
    "        #s._values+=additional_noise\n",
    "        #print(s.values(),s._values)\n",
    "        \n",
    "        #s2._values-=additional_noise\n",
    "        s = dend1.__getitem__(idx)\n",
    "        #print(dat1P[0],s._values[0],\"kaasl\")\n",
    "        vs.append(float(PPVStatistic(s,metadata=metadata).v_rms/u.km*u.s))\n",
    "        \n",
    "        del s\n",
    "        #del s2\n",
    "        \n",
    "    v_rms_std = np.nanstd(vs)\n",
    "    #print(v_rms_std)\n",
    "    return v_rms_std\n",
    "\n",
    "#Return a cropped cube for some ra and dec, also crops the velocity axis if needed (0 for no crop)\n",
    "def Crop(cube,WCS,Np1,Np2,BadVel,D2):\n",
    "    NraDP1 = [int(WCS.world_to_pixel(Np1)[0]),int(WCS.world_to_pixel(Np1)[1])]\n",
    "    NraDP2 = [int(WCS.world_to_pixel(Np2)[0]),int(WCS.world_to_pixel(Np2)[1])]\n",
    "    if(D2==False):\n",
    "        return cube[BadVel:np.shape(cube)[0]-BadVel,NraDP1[1]:NraDP2[1],NraDP1[0]:NraDP2[0]]\n",
    "    if(D2==True):\n",
    "        return cube[NraDP1[1]:NraDP2[1],NraDP1[0]:NraDP2[0]]\n",
    "\n",
    "    \n",
    "def Read_Clusters(FileName):\n",
    "    \n",
    "    sh= len(np.genfromtxt(FileName,usecols=0))\n",
    "    Data=[]\n",
    "    for lmi in range(50):\n",
    "        try:\n",
    "            Data.append(np.genfromtxt(FileName,usecols=lmi,dtype=type(\"2d4m\")))\n",
    "            #print(np.genfromtxt(FileName,usecols=lmi,dtype=type(\"2d4m\"),skip_header=1))\n",
    "        except:\n",
    "            pass\n",
    "    return Data\n",
    "def Find_Clusters_NGC(Data):\n",
    "    for lmi in range(len(Data)):\n",
    "        if \"ID\" in Data[lmi]:\n",
    "            IDs= Data[lmi][1:9999]\n",
    "        if \"RA\" in Data[lmi]: \n",
    "            RAs= Data[lmi][1:9999]\n",
    "        if \"Dec\" in Data[lmi]:\n",
    "            Decs= Data[lmi][1:9999]\n",
    "        if \"r_deconv\" in Data[lmi]: \n",
    "            R_deconv= Data[lmi][1:9999]#pc\n",
    "        if \"glon\" in Data[lmi]: \n",
    "            glons= Data[lmi][1:9999]#\n",
    "        if \"glat\" in Data[lmi]: \n",
    "            glats= Data[lmi][1:9999]#\n",
    "            \n",
    "    return IDs,RAs,Decs,R_deconv\n",
    "#Take the cont in Jy and find the HWHM from the structures in the catalog\n",
    "def Find_Clusters(Data,wcs,Cont_Data,header):\n",
    "    for lmi in range(len(Data)):\n",
    "        if \"ID\" in Data[lmi]:\n",
    "            IDs= Data[lmi][1:9999]\n",
    "        if \"RA\" in Data[lmi]: \n",
    "            RAs= Data[lmi][1:9999]\n",
    "        if \"Dec\" in Data[lmi]:\n",
    "            Decs= Data[lmi][1:9999]\n",
    "        if \"r_deconv\" in Data[lmi]: \n",
    "            R_deconv= Data[lmi][1:9999]#pc\n",
    "        if \"glon\" in Data[lmi]: \n",
    "            glons= Data[lmi][1:9999]#\n",
    "        if \"glat\" in Data[lmi]: \n",
    "            glats= Data[lmi][1:9999]#\n",
    "        if \"herschel_column\" in Data[lmi]: \n",
    "            CD= (Data[lmi][1:9999])#pc\n",
    "            \n",
    "        if \"flux_integrated\" in Data[lmi]: \n",
    "            Flux_1p3mm= Data[lmi][1:9999]#pc\n",
    "    #remove nan \n",
    "    for lmii in range(len(CD)):\n",
    "        try:\n",
    "            if CD[lmii]=='np.nan':\n",
    "                CD= np.delete(CD, lmii)\n",
    "                Flux_1p3mm= np.delete(Flux_1p3mm, lmii)\n",
    "                IDs= np.delete(IDs, lmii)\n",
    "                glats= np.delete(glats, lmii)\n",
    "                glons= np.delete(glons, lmii)\n",
    "                \n",
    "        except:\n",
    "            CD = np.array(CD,dtype=type(1.2**5))#float\n",
    "            break\n",
    "    glats_New=[]\n",
    "    glons_New=[]\n",
    "    CDs_New=[]\n",
    "    IDs_New=[]\n",
    "    Flux_1p3mm_New=[]\n",
    "\n",
    "    #print(CD,sorted(CD),type(CD),type(CD[0]))\n",
    "    nth = sorted(CD)[len(CD)-34]#34 most dense leaves\n",
    "    #print(nth,\"A\",CD,sorted(CD))\n",
    "    for lmj in range(len(CD)):\n",
    "        if CD[lmj]>nth:\n",
    "            glats_New.append(glats[lmj])\n",
    "            glons_New.append(glons[lmj])\n",
    "            CDs_New.append(CD[lmj])\n",
    "            IDs_New.append(int(IDs[lmj]))\n",
    "            Flux_1p3mm_New.append(Flux_1p3mm[lmj])\n",
    "    HWHM_rad = []      \n",
    "    #print(Flux_1p3mm_New,glats_New,glons_New,CDs_New,IDs_New)\n",
    "    for lmi in range(len(CDs_New)):\n",
    "        glat = glats_New[lmi]\n",
    "        glon = glons_New[lmi]\n",
    "        Flux = float(Flux_1p3mm_New[lmi])#INtegerated flux in jy\n",
    "        \n",
    "        Circle_R = 0\n",
    "        distance = 8.178*10**-3*u.Mpc\n",
    "        \n",
    "        pixel_res = abs(header['cdelt1'])*np.pi/180*distance*10**6/u.Mpc*u.pc # cdelt in deg, goes to res in pc\n",
    "        \n",
    "        #sky = SkyCoord('00h47m33.9s', '-25d17m26.8s', frame='icrs')\n",
    "        sky = SkyCoord(l=float(glon)*u.deg, b=float(glat)*u.deg, frame='galactic')\n",
    "        #center = SkyCoord(l=359.94487501*u.degree,b=-00.04391769*u.degree, frame='galactic')\n",
    "        p1,p2 = int(wcs.world_to_pixel(sky)[0]),int(wcs.world_to_pixel(sky)[1]) #Ra,dec\n",
    "        \n",
    "        while(True):\n",
    "            Circle_R += .01\n",
    "            #pixels=[(p1,p2)]\n",
    "            pixels=[(p2,p1)]#Goes lat then long for the cont data\n",
    "            #print(p1,p2)\n",
    "            #print(np.shape(Cont_Data[p2-50:p2+50]))\n",
    "            #print(np.shape(Cont_Data[50,p1-50:p1+50]))\n",
    "            for lmii in range(np.shape(Cont_Data[p2-50:p2+50])[0]):\n",
    "                for lmjj in range(np.shape(Cont_Data[p2-50+lmii,p1-50:p1+50])[0]):\n",
    "                    #Find pixels within the circle around the center (excude the center since its there already)\n",
    "                    #print(np.sqrt((lmii-50)**2+(lmjj-50)**2)*pixel_res,lmjj)\n",
    "                    if np.sqrt((lmii-50)**2+(lmjj-50)**2)*pixel_res.value < Circle_R and lmjj!=50:\n",
    "                        pixels.append((lmjj-50+p2,lmii-50+p1))#Goes lat then long\n",
    "                        \n",
    "            \n",
    "            \n",
    "            sum_flux=0\n",
    "            for lmkk in range(len(pixels)):\n",
    "                sum_flux += (Cont_Data[pixels[lmkk]])\n",
    "            #print(p1,p2,glat,glon,np.shape(Cont_Data),pixels,Cont_Data[pixels[0]],Flux,sum_flux,Circle_R)\n",
    "            if sum_flux>Flux/2:\n",
    "                HWHM_rad.append(Circle_R)#Pc\n",
    "                break\n",
    "                \n",
    "    return HWHM_rad,CDs_New,glons_New,glats_New,IDs_New\n",
    "\n",
    "#Return masked data around clusters or one pc around clusters\n",
    "def Mask_Clusters_NGC(HWHM,wcs,header,unmasked_data,ras,decs,One_Pc=False,One_Pc_Size=1,HWHM_Fac=1):\n",
    "    \n",
    "    Masked_Data=copy.deepcopy(unmasked_data)\n",
    "    for lmi in range(len(HWHM)):\n",
    "        ra = ras[lmi]\n",
    "        dec = decs[lmi]\n",
    "                \n",
    "        Circle_R = HWHM[lmi]*HWHM_Fac\n",
    "        if(One_Pc):\n",
    "            \n",
    "            Circle_R=One_Pc_Size\n",
    "        distance = 3.5*u.Mpc\n",
    "        \n",
    "        pixel_res = abs(header['cdelt1'])*np.pi/180*distance*10**6/u.Mpc*u.pc # cdelt in deg, goes to res in pc\n",
    "        \n",
    "        #sky = SkyCoord('00h47m33.9s', '-25d17m26.8s', frame='icrs')\n",
    "        sky = SkyCoord(str(ra),str(dec), frame='icrs')\n",
    "        #center = SkyCoord(l=359.94487501*u.degree,b=-00.04391769*u.degree, frame='galactic')\n",
    "        p1,p2 = int(wcs.world_to_pixel(sky)[0]),int(wcs.world_to_pixel(sky)[1]) #Ra,dec\n",
    "        \n",
    "\n",
    "\n",
    "        #pixels=[(p1,p2)]\n",
    "        pixels=[(p2,p1)]#Goes lat then long for the cont data\n",
    "        #print(p1,p2)\n",
    "        #print(np.shape(Cont_Data[p2-50:p2+50]))\n",
    "        #print(np.shape(Cont_Data[50,p1-50:p1+50]))\n",
    "        for lmii in range(np.shape(unmasked_data[0,p2-50:p2+50])[0]):\n",
    "            for lmjj in range(np.shape(unmasked_data[0,p2-50+lmii,p1-50:p1+50])[0]):\n",
    "                #Find pixels within the circle around the center (excude the center since its there already)\n",
    "                #print(np.sqrt((lmii-50)**2+(lmjj-50)**2)*pixel_res,lmjj)\n",
    "                \n",
    "                if np.sqrt((lmii-50)**2+(lmjj-50)**2)*pixel_res.value < Circle_R and lmjj!=50:\n",
    "                    pixels.append((lmjj-50+p2,lmii-50+p1))#Goes lat then long\n",
    "        \n",
    "        for lmi in range(len(unmasked_data)):\n",
    "            \n",
    "            for lmj in range(len(pixels)):\n",
    "                #print(Masked_Data[lmi,pixels[lmj][0],pixels[lmj][1]],lmi,pixels,np.shape(Masked_Data))\n",
    "                Masked_Data[lmi,pixels[lmj][0],pixels[lmj][1]]=np.nan\n",
    "                #print(Masked_Data[lmi,pixels[lmj][0],pixels[lmj][1]],lmi,pixels,np.shape(Masked_Data))\n",
    "     \n",
    "    return Masked_Data\n",
    "            \n",
    "#Make_Plot(\"Tes\",\"Test2\",Q.moment0().hdu.data,0,0,Q.wcs[:][:][0],2,2,1,True)\n",
    "#Make_Plot(\"Tes\",\"Test2\",Q.moment0().hdu.data,0,0,Q.wcs[:][:][0],2,2,2,True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6a56e1-c557-4130-bf98-a6cd31653b96",
   "metadata": {},
   "source": [
    "# Part 1: Updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613671ca-35e4-47b3-8c66-83c06f99b073",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#!py -m pip uninstall astropy\n",
    "#!py -m pip install git+https://github.com/astropy/astropy\n",
    "!pip install --upgrade pyspeckit \n",
    "'''!git clone https://github.com/jdhenshaw/scousepy\n",
    "    \n",
    "!cd scousepy\n",
    "!python setup.py install'''\n",
    "'''\n",
    "\n",
    "\n",
    "!py -m pip install git+https://github.com/radio-astro-tools/spectral-cube.git\n",
    "!py -m pip install reproject\n",
    "!py -m pip install git+https://github.com/radio-astro-tools/spectral-cube.git \n",
    "!py -m pip install pyspeckit\n",
    "!py -m pip install regions\n",
    "!py -m pip install astrodendro\n",
    "!py -m pip  install wcsaxes \n",
    "!py -m pip  install ipympl\n",
    "!py -m pip install dask\n",
    "!py -m pip install radio_beam\n",
    "!py -m pip install casa_formats_io\n",
    "#try:\n",
    "#    !pip install casa_formats_io --no-binary :all:\n",
    "#except:\n",
    "#    !pip install casa_formats_io --no-cache --no-binary :all:\n",
    "\n",
    "!py -m pip  install spectral_cube \n",
    "!py -m pip  install typing \n",
    "!py -m pip install mypy\n",
    "!py -m pip  install typing_extensions \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb485da6-5fef-46d6-8ec0-a17cea616799",
   "metadata": {},
   "source": [
    "# Part 2: Reprojection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7238f0b-9afd-439c-8a8d-3c3a28e95c33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#Just Using CO 3-2 right now\n",
    "files = ['HCOp_J1-0.cube.fits']\n",
    "#files=[\"Pre-Smoothed.fits\"]\n",
    "      \n",
    "#FOV = [400,800]#pc\n",
    "FOV = [70,360]#pc\n",
    "\n",
    "Min_res=4.3*u.pc#Smallest resolution\n",
    "\n",
    "\n",
    "iterations = 5\n",
    "Line_Name = '_NGC_HCOp_J1_0_'\n",
    "ovs = 3 #over sample factor for beam\n",
    "min_vel = 3.3#km/s\n",
    "#Beam_Sizes = np.linspace(Smallest_beam,Smallest_beam*iterations, np.diff(Smallest_beam,Smallest_beam*iterations)/iterations)\n",
    "iter_factor = 1/5\n",
    "for kl in range(iterations):\n",
    "    Prime_Beam = Min_res*((kl*iter_factor+1))#Beam_Sizes[kl]\n",
    "    \n",
    "    #Need to break it up into 30-wide vel slices to do the reprojection (ram-draw too high)\n",
    "    \n",
    "    for i in range(0,300):\n",
    "        print(kl,i)\n",
    "        Cube_Name = str(Prime_Beam.value)+\"pc_beam_\"+str(i)+Line_Name+str(FOV[0])+\"x\"+str(FOV[1])+'pc.fits'\n",
    "        sc = SpectralCube.read(files[0])  \n",
    "\n",
    "        if(i*30>len(sc)):\n",
    "            print(\"End Loop at\",i)\n",
    "            break\n",
    "\n",
    "        sc = sc[i*30:i*30+30,250:np.shape(sc)[1]-250,250:np.shape(sc)[2]-250]# Make a subcube\n",
    "        #sc = sc[i*30:i*30+30,250:400,50:400]# Make a subcube\n",
    "        #Put in the right system\n",
    "        sc_kms = sc.with_spectral_unit(u.km/u.s,velocity_convention=\"radio\") # Change units from Hz to km/s\n",
    "        del sc\n",
    "        try:\n",
    "            sc = sc_kms.spectral_slab(0. *u.km / u.s, 501. *u.km / u.s)  # Crop out velocities we don't care about    \n",
    "            del sc_kms\n",
    "            sc.allow_huge_operations=True    \n",
    "            HI = sc.header\n",
    "            Nres=Prime_Beam\n",
    "            dist=3.5*10**6\n",
    "            res=  Nres/(dist)*180/np.pi*u.deg/u.pc#deg corresponding to ~3 pc\n",
    "            beam = radio_beam.Beam(major=res, minor=res, pa=0*u.deg)\n",
    "            sc.allow_huge_operations=True\n",
    "\n",
    "\n",
    "\n",
    "            gal=\"NGC253\"\n",
    "\n",
    "\n",
    "\n",
    "            #Now that we have a circular beam, this can be done easily:\n",
    "            #use some trig to make a rectangle at 33 deg, and allow pixels inside it.\n",
    "            if(gal == 'NGC253'):\n",
    "\n",
    "                cdelt_x = u.Quantity(str(np.abs(sc.header['cdelt1']))+sc.header['cunit1'])\n",
    "                cdelt_y = u.Quantity(str(np.abs(sc.header['cdelt2']))+sc.header['cunit2'])\n",
    "                #center = SkyCoord('00h47m33.134s' ,'-25d17m19.68s',frame='icrs')\n",
    "                center = SkyCoord('00h47m33.14s' ,'-25d17m17.52s',frame='icrs')\n",
    "\n",
    "                center_ra_pix,center_dec_pix = [int(sc.wcs[:][:][0].world_to_pixel(center)[0]),int(sc.wcs[:][:][0].world_to_pixel(center)[1])]\n",
    "                PixFov = [int(FOV[0]/(cdelt_x/u.deg*np.pi/180*3.5*10**6))/2,int(FOV[1]/(cdelt_y/u.deg*np.pi/180*3.5*10**6))/2]\n",
    "                print(center_ra_pix,center_dec_pix)\n",
    "                pixels = np.zeros(np.shape(sc))           \n",
    "                for lmi in range(np.shape(sc)[0]):\n",
    "                    for lmj in range(np.shape(sc)[1]):\n",
    "                        for lmk in range(np.shape(sc)[2]):\n",
    "                            hypo = np.sqrt(((lmj-center_dec_pix)**2) + (lmk-center_ra_pix)**2)\n",
    "\n",
    "                            if (lmj-center_dec_pix!=0):\n",
    "                                ang = np.arctan(abs(lmk-center_ra_pix)/abs(lmj-center_dec_pix))#Find angle to the center\n",
    "                            else:\n",
    "                                ang = np.pi/2\n",
    "                            if(lmk>center_ra_pix and lmj>center_dec_pix):\n",
    "                                ang*=-1\n",
    "                                #print(\"A\",lmk,lmj,ang)\n",
    "                            elif(lmk<center_ra_pix and lmj<center_dec_pix):\n",
    "                                ang*=-1\n",
    "                                #print(\"B\",lmk,lmj,ang)\n",
    "                            elif(lmk>center_ra_pix and lmj<center_dec_pix):\n",
    "                                if ang >57*np.pi/180:\n",
    "                                    #print(\"C\",lmk,lmj,ang)\n",
    "\n",
    "                                    ang= -33*np.pi/180+147*np.pi/180-ang#coming from the opposite end of the ra axis now, but projecting still to 33 deg from north.\n",
    "\n",
    "                                    #print(ang,hypo*np.cos(abs((33*np.pi/180)+ang)),hypo*np.sin(abs((33*np.pi/180)+ang)))\n",
    "                                else:\n",
    "                                    #print(ang,hypo*np.cos(abs((33*np.pi/180)+ang)),hypo*np.sin(abs((33*np.pi/180)+ang)))\n",
    "                                    #print(\"D\",lmk,lmj,ang)\n",
    "                                    pass\n",
    "\n",
    "\n",
    "                            up_pixels = abs(hypo*np.cos(abs((33*np.pi/180)+ang)))#Should not be over the fov in the upwards direction (relative to 0 degrees)\n",
    "                            side_pixels = abs(hypo*np.sin(abs((33*np.pi/180)+ang)))#Should not be over the fov in the side-side direction (relative to 0 degrees)\n",
    "\n",
    "                            if(up_pixels<PixFov[0] and side_pixels<PixFov[1]):\n",
    "                                pixels[lmi][lmj][lmk] = 1#good\n",
    "                        #print(up_pixels,side_pixels ,PixFov)\n",
    "                        #print(    center_ra_pix,    center_dec_pix,PixFov,side_pixels,up_pixels,ang,lmi,ggg,fff,pixels[lmi][ggg][fff])\n",
    "                #print(pixels)\n",
    "                bp = np.where(pixels!=1)\n",
    "                #Mask teh pixels outside the fov\n",
    "                scCopy = sc.hdu\n",
    "                #sc.hdu.data[bp]=9999#np.nan\n",
    "                scCopy.data[bp]=np.nan\n",
    "                sc = SpectralCube.read(scCopy)\n",
    "                del scCopy\n",
    "\n",
    "\n",
    "            #Get right size\n",
    "\n",
    "            sc.allow_huge_operations=True\n",
    "            datn = sc.hdu.data\n",
    "            sx,sy,ex,ey=0,0,0,0\n",
    "            for lmi in range(np.shape(datn[0,:,:])[0]):\n",
    "\n",
    "                if(ey!=0 and sx!=0 and ex!=0 and sy!=0):\n",
    "                    print(\"F\",lmi)\n",
    "                    break\n",
    "                for lmj in range(np.shape(datn[0,:,:])[1]):\n",
    "\n",
    "                    if(sx==0):            \n",
    "                        if(np.nanmean(datn[0,lmi,:])>0 or np.nanmean(datn[0,lmi,:])<0):\n",
    "                            sx=lmi\n",
    "\n",
    "\n",
    "                    if(sy==0):\n",
    "                        if(np.nanmean(datn[0,:,lmj])>0 or np.nanmean(datn[0,:,lmj])<0):\n",
    "                            sy=lmj\n",
    "\n",
    "                    if(ex==0):\n",
    "                        if(np.nanmean(datn[0,np.shape(datn[0,:,:])[0]-lmi-1,:])>0 or np.nanmean(datn[0,np.shape(datn[0,:,:])[0]-lmi-1,:])<0):\n",
    "                            ex=np.shape(datn[0,:,:])[0]-lmi-1\n",
    "\n",
    "                    if(ey==0):\n",
    "                        if(np.nanmean(datn[0,:,np.shape(datn[0,:,:])[1]-lmj-1])>0 or np.nanmean(datn[0,:,np.shape(datn[0,:,:])[1]-lmj-1])<0):\n",
    "                            ey=np.shape(datn[0,:,:])[1]-lmj-1\n",
    "\n",
    "                    if(ey!=0 and ex!=0 and sx!=0 and sy!=0):\n",
    "                        break\n",
    "            print(sx,ex,sy,ey)\n",
    "            scP = sc[:,sx:ex,sy:ey]\n",
    "            scP_Hdu=scP.hdu\n",
    "            zeros=((scP_Hdu.data[:,:,:]==0))\n",
    "            bp = np.where(zeros)\n",
    "            scP_Hdu.data[bp]=np.nan\n",
    "            sc = SpectralCube.read(scP_Hdu)\n",
    "\n",
    "            sc = sc.convolve_to(beam)#Smoothe to circular beam at 3 pc by 3 pc\n",
    "            del scP_Hdu\n",
    "            del zeros\n",
    "            del scP\n",
    "            del datn\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            reheader = sc.header\n",
    "\n",
    "\n",
    "\n",
    "            ## Find the number of expected pixels for the new resolution and the location of the left/right, up/down sides \n",
    "            if sc.header['cdelt1']>0:\n",
    "                pix_x    = (res/ovs).to(u.degree).value\n",
    "                origin_x = sc.longitude_extrema[1].to(u.degree).value if gal=='GC' else sc.longitude_extrema[0].to(u.degree).value\n",
    "\n",
    "            else:\n",
    "                pix_x    = -1.*(res/ovs).to(u.degree).value\n",
    "                origin_x = (sc.longitude_extrema[0]).to(u.degree).value if gal=='GC' else (sc.longitude_extrema[1]).to(u.degree).value\n",
    "\n",
    "            if sc.header['cdelt2']>0:\n",
    "                pix_y    = (res/ovs).to(u.degree).value\n",
    "                origin_y = sc.latitude_extrema[0].to(u.degree).value\n",
    "            else:\n",
    "                pix_y    = -1.*(res/ovs).to(u.degree).value\n",
    "                origin_y = sc.latitude_extrema[1].to(u.degree).value\n",
    "\n",
    "            if gal=='NGC253':\n",
    "                npix_x   = int(np.ceil(np.diff(sc.longitude_extrema, n=1)[0]/np.abs(pix_x)).value)\n",
    "                npix_y   = int(np.ceil(np.diff(sc.latitude_extrema, n=1)[0]/np.abs(pix_y)).value)\n",
    "\n",
    "            elif gal=='GC':\n",
    "                npix_x   = int(np.ceil((sc.longitude_extrema[0]-(sc.longitude_extrema[1]-360*u.degree))/np.abs(pix_x)).value)\n",
    "                npix_y   = int(np.ceil(np.diff(sc.latitude_extrema, n=1)[0]/np.abs(pix_y)).value)\n",
    "\n",
    "            #Correct the header to the expected pixels for the new res\n",
    "\n",
    "            reheader['cdelt1'] = pix_x\n",
    "            reheader['cdelt2'] = pix_y\n",
    "\n",
    "            reheader['naxis1'] = npix_x\n",
    "            reheader['naxis2'] = npix_y\n",
    "\n",
    "            reheader['crval1'] = origin_x\n",
    "            reheader['crval2'] = origin_y\n",
    "\n",
    "            reheader['crpix1'] = 0\n",
    "            reheader['crpix2'] = 0\n",
    "            try:\n",
    "                del reheader['lonpole']\n",
    "                del reheader['latpole']\n",
    "                del reheader['wcsaxes']#Dont need these anymore, maybe?\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # regrid cube to target pixel size\n",
    "            sc_K_kms = sc.reproject(reheader, order='bilinear', use_memmap=True, filled=True)\n",
    "\n",
    "            new = SpectralCube(data=sc_K_kms.hdu.data,wcs = WCS(sc_K_kms.header),header=sc_K_kms.header)\n",
    "            new.allow_huge_operations=True\n",
    "            new = new*sc_K_kms[0][0][0].unit\n",
    "            #do this because scs dont like being modified\n",
    "            del sc_K_kms\n",
    "            sc_K_kms = new\n",
    "            del new\n",
    "\n",
    "            print(np.nanmax(sc_K_kms),np.shape(sc_K_kms))#These should be a non zero float and the shape of the cube (30,~1000,~1000)\n",
    "            del sc\n",
    "            vel = np.arange(0,501,min_vel)*u.km/u.s\n",
    "            NGC_CO_J3_2 = sc_K_kms\n",
    "            del sc_K_kms\n",
    "            NGC_CO_J3_2.allow_huge_operations=True\n",
    "\n",
    "            #do this again to crop the extra pixels off\n",
    "            sc=NGC_CO_J3_2\n",
    "            datn = sc.hdu.data\n",
    "            sx,sy,ex,ey=0,0,0,0\n",
    "            for lmi in range(np.shape(datn[0,:,:])[0]):\n",
    "\n",
    "                if(ey!=0 and sx!=0 and ex!=0 and sy!=0):\n",
    "                    print(\"F\",lmi)\n",
    "                    break\n",
    "                for lmj in range(np.shape(datn[0,:,:])[1]):\n",
    "\n",
    "                    if(sx==0):            \n",
    "                        if(np.nanmean(datn[0,lmi,:])>0 or np.nanmean(datn[0,lmi,:])<0):\n",
    "                            sx=lmi\n",
    "\n",
    "\n",
    "                    if(sy==0):\n",
    "                        if(np.nanmean(datn[0,:,lmj])>0 or np.nanmean(datn[0,:,lmj])<0):\n",
    "                            sy=lmj\n",
    "\n",
    "                    if(ex==0):\n",
    "                        if(np.nanmean(datn[0,np.shape(datn[0,:,:])[0]-lmi-1,:])>0 or np.nanmean(datn[0,np.shape(datn[0,:,:])[0]-lmi-1,:])<0):\n",
    "                            ex=np.shape(datn[0,:,:])[0]-lmi-1\n",
    "\n",
    "                    if(ey==0):\n",
    "                        if(np.nanmean(datn[0,:,np.shape(datn[0,:,:])[1]-lmj-1])>0 or np.nanmean(datn[0,:,np.shape(datn[0,:,:])[1]-lmj-1])<0):\n",
    "                            ey=np.shape(datn[0,:,:])[1]-lmj-1\n",
    "\n",
    "                    if(ey!=0 and ex!=0 and sx!=0 and sy!=0):\n",
    "                        break\n",
    "            print(sx,ex,sy,ey)\n",
    "            scP = sc[:,sx:ex,sy:ey]\n",
    "            scP_Hdu=scP.hdu\n",
    "            zeros=((scP_Hdu.data[:,:,:]==0))\n",
    "            bp = np.where(zeros)\n",
    "            scP_Hdu.data[bp]=np.nan\n",
    "            sc = SpectralCube.read(scP_Hdu)\n",
    "\n",
    "            sc = sc.convolve_to(beam)#Smoothe to circular beam at 3 pc by 3 pc\n",
    "            del scP_Hdu\n",
    "            del zeros\n",
    "            del scP\n",
    "            del datn\n",
    "\n",
    "            #Write the intermediary cubes that will then be spliced together\n",
    "            sc.write(Cube_Name,overwrite=True)      \n",
    "            del NGC_CO_J3_2\n",
    "            del sc\n",
    "            gc.collect()######################################################################\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(kl,i)\n",
    "            print(\"Failed\")\n",
    "            print(\"-\"*60)\n",
    "            traceback.print_exc(file=sys.stdout)\n",
    "\n",
    "\n",
    "\n",
    "print(\"done\")         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83df140e-5e86-42b8-a1b4-fd88aae933f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Splice CO\n",
    "\n",
    "iterations = 5\n",
    "iter_factor = 1/5\n",
    "Line_Name = '_NGC_HCOp_J1_0_'\n",
    "ovs = 3 #over sample factor for beam\n",
    "min_vel = 3.3#km/s\n",
    "FOV = [70,360]#pc\n",
    "Min_res=4.3*u.pc#Smallest resolution\n",
    "\n",
    "for kl in range(iterations):\n",
    "      \n",
    "    Prime_Beam = Min_res*((kl*iter_factor+1))#\n",
    "    print(Prime_Beam)\n",
    "    \n",
    "    for km in range(iterations):\n",
    "        vel_prime = min_vel*((km*iter_factor+1))\n",
    "        vel = np.arange(0,501,vel_prime)*u.km/u.s \n",
    "        \n",
    "        \n",
    "        for i in range(0,9):\n",
    "            try:\n",
    "                Cube_Name_Load = str(Prime_Beam.value)+\"pc_beam_\"+str(i)+Line_Name+str(FOV[0])+\"x\"+str(FOV[1])+'pc.fits'\n",
    "                Cube_Name_Save = str(Prime_Beam.value)+\"pc_beam_\"+Line_Name+str(FOV[0])+\"x\"+str(FOV[1])+'pc_'+str(vel_prime)+'_vel_res.fits'\n",
    "\n",
    "                sc=SpectralCube.read((Cube_Name_Load)) \n",
    "                print(np.shape(sc),Cube_Name_Load)\n",
    "                print(sc.mask,type(sc.mask))\n",
    "\n",
    "                if i==0:\n",
    "                    reheader = sc.header\n",
    "                    rewcs = sc.wcs\n",
    "\n",
    "\n",
    "                print(type(sc))\n",
    "                if i ==0:\n",
    "                    scW=SpectralCube.read((Cube_Name_Load))      \n",
    "                    mask = scW.mask.include() #Need to create a mask because it doesn't get splcied\n",
    "                else:\n",
    "\n",
    "\n",
    "                    if i ==1:\n",
    "                        scW = np.concatenate((scW[:].hdu.data,sc[:].hdu.data),dtype = type(sc))\n",
    "                        print(type(scW))\n",
    "                        mask = np.concatenate((mask[:],sc[:].mask.include()),dtype = type(sc[:].mask.include()))\n",
    "                    else:\n",
    "                        scW = np.concatenate((scW[:],sc.hdu.data[:]),dtype = type(sc))\n",
    "                        mask = np.concatenate((mask[:],sc[:].mask.include()),dtype = type(sc[:].mask.include()))\n",
    "\n",
    "\n",
    "                print(np.shape(scW))\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(kl,km,i)\n",
    "                print(\"Failed\")\n",
    "                print(\"-\"*60)\n",
    "                traceback.print_exc(file=sys.stdout)\n",
    "        def duh(lol):\n",
    "            gp = np.where(lol!=np.nan)\n",
    "            lol[gp]=True\n",
    "            return lol #Anywhere that has data will be unmasked\n",
    "        reheader[\"NAXIS3\"] = len(scW)\n",
    "        Full_Mask = LazyMask(function = duh,data = mask, wcs = rewcs)\n",
    "        scWsc = SpectralCube(data = scW,wcs = rewcs, header = reheader, mask = Full_Mask)#The spliced cube\n",
    "\n",
    "        scWsc.allow_huge_operations=True\n",
    "        scWsc = scWsc*sc[0][0][0].unit#Add unit back in\n",
    "        del sc\n",
    "        fwhm_factor = np.sqrt(8*np.log(2))\n",
    "\n",
    "        scWsc.allow_huge_operations=True\n",
    "\n",
    "\n",
    "        #scWsc = scWsc.spectral_smooth(Gaussian1DKernel(4/fwhm_factor))\n",
    "        #scWsc = scWsc.spectral_smooth(Gaussian1DKernel(4/fwhm_factor))\n",
    "        vel = np.arange(0,501,vel_prime)*u.km/u.s    \n",
    "\n",
    "        G_width = np.sqrt(abs(scWsc.header[\"CDELT3\"]**2-vel_prime**2))\n",
    "        scWsc = scWsc.spectral_smooth(Gaussian1DKernel(G_width/fwhm_factor))#Preserves information from the pixels lost in downsampling\n",
    "\n",
    "        scWsc = scWsc.spectral_interpolate(spectral_grid=vel) # Match velocities to -250 251 range \n",
    "\n",
    "\n",
    "\n",
    "        scWsc.write(Cube_Name_Save,overwrite=True)\n",
    "        #scWsc.write(\"NGC_Spliced_Reprojected_Whole_CO_32.fits\",overwrite=True)\n",
    "\n",
    "\n",
    "print(\"done\")         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969874cc-9408-411f-9673-400b0a4b0b3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Fix reprojected repeated pixels\n",
    "\n",
    "iterations = 5\n",
    "iter_factor = 1/5\n",
    "Line_Name = '_NGC_HCOp_J1_0_'\n",
    "ovs = 3 #over sample factor for beam\n",
    "min_vel = 3.3#km/s\n",
    "FOV = [70,360]#pc\n",
    "Min_res=4.3*u.pc#Smallest resolution\n",
    "\n",
    "for kl in range(iterations):\n",
    "      \n",
    "    Prime_Beam = Min_res*((kl*iter_factor+1))#\n",
    "    print(Prime_Beam)\n",
    "    \n",
    "    \n",
    "    for km in range(iterations):\n",
    "        vel_prime = min_vel*((km*iter_factor+1))\n",
    "        vel = np.arange(0,501,vel_prime)*u.km/u.s \n",
    "        \n",
    "        Cube_Name_Load = str(Prime_Beam.value)+\"pc_beam_\"+Line_Name+str(FOV[0])+\"x\"+str(FOV[1])+'pc_'+str(vel_prime)+'_vel_res.fits'\n",
    "    \n",
    "    \n",
    "        Cube_Name_Save = \"Cropped_\"+str(Prime_Beam.value)+\"pc_beam_\"+Line_Name+str(FOV[0])+\"x\"+str(FOV[1])+'pc_'+str(vel_prime)+'_vel_res.fits'\n",
    "        \n",
    "\n",
    "\n",
    "        sc = SpectralCube.read(Cube_Name_Load).with_spectral_unit(u.km/u.s,velocity_convention=\"radio\")\n",
    "        sp=0\n",
    "        for lmi in range(len(sc)):\n",
    "            #Check to see if the slice has been repeated by the interpolation function\n",
    "            if(np.round(np.nanmean(sc[lmi].hdu.data),5)==np.round(np.nanmean(sc[lmi+1].hdu.data),5)):\n",
    "\n",
    "                sp = lmi+1\n",
    "            else:\n",
    "                print(\"A\")\n",
    "                print(lmi,np.nanmean(sc[lmi].hdu.data),np.nanmean(sc[lmi+1].hdu.data))\n",
    "                break\n",
    "        l = len(sc)-1\n",
    "        ep=l\n",
    "        for lmi in range(l):\n",
    "\n",
    "            if(np.round(np.nanmean(sc[l-lmi].hdu.data),5)==np.round(np.nanmean(sc[l-lmi-1].hdu.data),5)):\n",
    "                ep = l-lmi-1\n",
    "\n",
    "            else:\n",
    "                print(\"B\",lmi)\n",
    "                break\n",
    "\n",
    "        print(sp,ep)#These are the start and stop slices where the actual unique data resides\n",
    "\n",
    "        sc.allow_huge_operations=True\n",
    "        sc = sc[sp:ep]\n",
    "\n",
    "        sc.write((Cube_Name_Save),overwrite=True)\n",
    "        print(\"Done\",km,kl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fa9391-1bee-41f6-bf20-05ec2087087b",
   "metadata": {},
   "source": [
    "# Part 4: Dendograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9feabc2d-dec5-4c4a-8be9-eb4a82064a6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c789f13e-78f4-4db4-8f7c-0d5274ba131c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d766b9-3be8-4cef-afdd-349a277ad9a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#All Abs\n",
    "\n",
    "Abs_Level = Abs_Levels[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pathCont = 'Continuum_Reproject.fits'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for kl in range(iterations):\n",
    "      \n",
    "    Prime_Beam = Min_res*((kl*iter_factor+1))#\n",
    "    print(Prime_Beam)\n",
    "    \n",
    "    \n",
    "    for km in range(iterations):\n",
    "        vel_prime = min_vel*((km*iter_factor+1))\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        try:\n",
    "            Names=list(np.load(\"Names_New_All_Kinds.npy\",allow_pickle=True))\n",
    "        except Exception as e:\n",
    "\n",
    "            print(e)\n",
    "            print(\"initialized names\")\n",
    "            Names = list(np.empty((20,iterations,iterations,iterations,iterations),dtype=object))\n",
    "                        \n",
    "\n",
    "        #Continuum image\n",
    "        scCont = spectral_cube.Projection.from_hdu(fits.open(pathCont)[0])\n",
    "        #Put this up here for the column density map\n",
    "        metadata = {}\n",
    "        metadata[\"distance\"] = 3.5*u.Mpc\n",
    "        arc_per_pix_yc =  abs(scCont.hdu.header[\"CDELT1\"]*3600.0 * u.arcsec)/u.pix\n",
    "        arc_per_pix_xc =  abs(scCont.hdu.header[\"CDELT2\"]*3600.0 * u.arcsec)/u.pix\n",
    "        beam_majorc =  scCont.hdu.header[\"BMAJ\"]*3600.0 * u.arcsec\n",
    "        beam_minorc =  scCont.hdu.header[\"BMIN\"]*3600.0 * u.arcsec\n",
    "        beam_area_ratioc = beam_minorc*beam_majorc/arc_per_pix_yc/arc_per_pix_xc*1.13309#beam_area_ratioc = beam_minorc*beam_majorc/arc_per_pix_yc/arc_per_pix_xc#This is for FWHM, use *(2*np.sqrt(2*np.log(2)))**2#For gaussian beam\n",
    "        metadata['beam_area_ratioc']=beam_area_ratioc\n",
    "        pc_per_pixelc = abs(scCont.hdu.header[\"CDELT1\"])/180*np.pi*metadata['distance']/u.Mpc\n",
    "        print(pc_per_pixelc,\"MPC per pix\")\n",
    "\n",
    "        #Make subcube\n",
    "\n",
    "\n",
    "\n",
    "        Cube_Name_Load = \"Cropped_\"+str(Prime_Beam.value)+\"pc_beam_\"+Line_Name+str(FOV[0])+\"x\"+str(FOV[1])+'pc_'+str(vel_prime)+'_vel_res.fits'\n",
    "        path = Cube_Name_Load\n",
    "        \n",
    "        Qp = SpectralCube.read(path).with_spectral_unit(u.km/u.s,velocity_convention=\"radio\") \n",
    "        Qp.allow_huge_operations=True\n",
    "\n",
    "        Q = Qp.to(u.K)#Jy to Kelvin\n",
    "\n",
    "        sc = Q.unmasked_copy()\n",
    "\n",
    "\n",
    "\n",
    "        scW = sc.wcs[:][:][0]\n",
    "        dat = sc.hdu.data[int(len(sc)*((1-Ram_Limiter)/2)):int(len(sc)*(Ram_Limiter + (1-Ram_Limiter)/2)),:,:]\n",
    "        scn = sc[int(len(sc)*((1-Ram_Limiter)/2)):int(len(sc)*(Ram_Limiter + (1-Ram_Limiter)/2)),:,:]\n",
    "        scF = scn\n",
    "        datn = dat\n",
    "\n",
    "\n",
    "        #m=.115\n",
    "\n",
    "        #print(m,\"Presumed Noise (K)\")\n",
    "\n",
    "        #Continuum image\n",
    "        scCont = spectral_cube.Projection.from_hdu(fits.open(pathCont)[0])\n",
    "        #Do the same thing to the continuum image\n",
    "        scCont.allow_huge_operations=True\n",
    "        scContW = scCont.reproject(scF.moment0().header)\n",
    "        #m=.115\n",
    "\n",
    "\n",
    "        scW = sc.wcs[:][:][0]\n",
    "\n",
    "        cen_p1 = SkyCoord('00h47m33.9s', '-25d17m26.8s', frame='icrs')\n",
    "        cen_p2 = SkyCoord('00h47m32.6s', '-25d17m10.2s', frame='icrs')\n",
    "\n",
    "\n",
    "        #Do the same thing to the continuum image\n",
    "        scCont.allow_huge_operations=True\n",
    "        scContW = scCont.reproject(scF.moment0().header)\n",
    "        Continuum_Data  =scContW.hdu.data\n",
    "        scWCS = scF.wcs[:][:][0]\n",
    "\n",
    "        moment_0_sub  = scF.to(u.K).moment(order=0,how='slice')            # Calculate the Moment 0 map \n",
    "\n",
    "\n",
    "\n",
    "        ######Moment 0 for both\n",
    "        ######and cont\n",
    "        Make_Plot((LineN+\" Moment 0\"),\"Moment 0 (K km/s)\",moment_0_sub.hdu.data,0,np.nanmax(moment_0_sub.hdu.data),moment_0_sub.wcs,1,1,1,True)\n",
    "\n",
    "\n",
    "        cSD = (Flux_to_Mass(scContW.hdu.data*u.Jy/u.beam/beam_area_ratioc*u.pix**2*u.beam)/(pc_per_pixelc*10**6*3.086*10**18*u.cm)**2)*(1.989*10**30*u.kg/u.M_sun)*Num_per_kg/u.kg #Flux goes to luminosity for a gaussian beam and goes to column density for square pixels, mass goes to kg to number\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        rm=moment_0_sub.hdu.data/cSD\n",
    "        rmU = rm*u.K*u.km/u.s#Just put back in the units\n",
    "        rmU = np.array(rmU /(u.K*u.km/u.s)/u.cm**2*10**22,dtype='float64')#Now remove them all\n",
    "\n",
    "        ######ratio\n",
    "\n",
    "        bp = np.where(cSD<=7*10**22/u.cm**2)\n",
    "        bp2 = np.where( moment_0_sub.hdu.data < .22)\n",
    "        Continuum_Data[bp] = np.nan\n",
    "        cSD[bp]=np.nan\n",
    "        rmU[bp]=np.nan\n",
    "        rmU[bp2]=np.nan\n",
    "\n",
    "        Non_nan=((datn[0,:,:]>0)  | (datn[0,:,:]<0 ))\n",
    "\n",
    "        m = (np.nanstd(datn[0,:,:],where= Non_nan)) #Noise K\n",
    "        if(Abs_Level==\"All\"):\n",
    "            pass\n",
    "        if(Abs_Level==\"None\"):\n",
    "            datn[np.where(datn<0)]=np.nan\n",
    "        if(Abs_Level==\"None (m)\"):\n",
    "            datn[np.where(datn<-m)]=np.nan\n",
    "        if(Abs_Level==\"None All Channels\"):\n",
    "            for lmi in range(len(datn)):\n",
    "                bpP = np.where(datn[lmi]<-m)\n",
    "                for lmj in range(len(datn)):\n",
    "                    datn[lmj][bpP]=np.nan\n",
    "        if(Abs_Level==\"No Clusters\"):\n",
    "            IDs,RAs,Decs,HWHM  =    np.genfromtxt(\"NGC_Clusters_\"+\"IDs\"+\"\",dtype=type(\"12h23.14s\")),np.genfromtxt(\"NGC_Clusters_\"+\"RAs\"+\"\",dtype=type(\"12h23.14s\")),np.genfromtxt(\"NGC_Clusters_\"+\"Decs\"+\"\",dtype=type(\"12h23.14s\")),np.genfromtxt(\"NGC_Clusters_\"+\"HWHM\"+\"\")\n",
    "\n",
    "            datn=  Mask_Clusters_NGC(HWHM,scWCS,scF.hdu.header,datn,RAs,Decs,One_Pc=False,One_Pc_Size=1,HWHM_Fac=3)\n",
    "\n",
    "        print(m,\"Unmatched Noise (K)\", \"Abs = \",Abs_Level)\n",
    "\n",
    "\n",
    "        Make_Plot(\"Column Density\",\"(#/cm^2)\",cSD,float(np.nanmin(cSD*u.cm**2)),float(np.nanmax(cSD*u.cm**2)),scCont.wcs,1,1,1,True)\n",
    "        Make_Plot((LineN+\" Moment 0/Column Density\"),\"Moment 0 over Column Density of the Continuum (K km/s/(#/cm^2))\",rmU,np.nanmean(rmU)*.5,abs(np.nanmean(rmU))*8,scCont.wcs,1,1,1,True)\n",
    "\n",
    "        print(np.nanmin(rmU))\n",
    "\n",
    "\n",
    "\n",
    "        header = scF.hdu.header\n",
    "        print()\n",
    "        #make metadata for the dendrogram\n",
    "\n",
    "        try:\n",
    "            freq = header[\"RESTFREQ\"]*u.Hz#\n",
    "            metadata['wavelength']=299792458*u.m/header[\"RESTFREQ\"]#\n",
    "            print(1,freq,metadata['wavelength'])\n",
    "        except:\n",
    "            freq = header[\"RESTFRQ\"]*u.Hz#\n",
    "            metadata['wavelength']=299792458*u.m/header[\"RESTFRQ\"]#\n",
    "        metadata['data_unit'] =scF[0][0][0].unit# header['BUNIT']\n",
    "        metadata['arc_per_pix_y'] =  abs(header[\"CDELT1\"]*3600.0 * u.arcsec)/u.pix\n",
    "        metadata['arc_per_pix_x'] =  abs(header[\"CDELT2\"]*3600.0 * u.arcsec)/u.pix\n",
    "\n",
    "\n",
    "        metadata['beam_major'] =  header[\"BMAJ\"]*3600.0 * u.arcsec\n",
    "        metadata['beam_minor'] =  header[\"BMIN\"]*3600.0 * u.arcsec\n",
    "        beam_area_ratio = metadata['beam_minor']*metadata['beam_major']/metadata['arc_per_pix_y']/metadata['arc_per_pix_x']*1.13309#beam_area_ratio = metadata['beam_minor']*metadata['beam_major']/metadata['arc_per_pix_y']/metadata['arc_per_pix_x']#This is for FWHM, use *(2*np.sqrt(2*np.log(2)))**2#For gaussian beam\n",
    "        metadata['beam_area_ratio']=beam_area_ratio\n",
    "        metadata['spatial_scale'] = np.sqrt(abs(header[\"CDELT1\"])*u.degree**2*abs(header[\"CDELT2\"]))\n",
    "        area_res = abs(header[\"CDELT1\"])*abs(header[\"CDELT2\"])*(np.pi/180*3.5)**2#mpc^2/pix^2\n",
    "        print(area_res,type(area_res))\n",
    "\n",
    "        print(metadata['beam_minor'],metadata['beam_major'])\n",
    "        print(beam_area_ratio)\n",
    "        #metadata[\"wcs\"] = wcs\n",
    "        metadata[\"velocity_scale\"] = abs(header[\"CDELT3\"])*u.km/u.s#u.km/u.s\n",
    "\n",
    "        metadata[\"vaxis\"]=0\n",
    "        metadata[\"wcsu\"]=scF.wcs\n",
    "\n",
    "\n",
    "        for k3 in range(iterations):\n",
    "\n",
    "            beam_req = Min_beam_req*(k3+1)\n",
    "            \n",
    "            for k4 in range(iterations):\n",
    "                print(kl,km,k3,k4)\n",
    "                try:\n",
    "\n",
    "                    pix_thresh_factor = k4+1\n",
    "\n",
    "                    Cube_Name_Save = Name+\"_Cropped_\"+str(Prime_Beam.value)+\"pc_beam_\"+Line_Name+str(FOV[0])+\"x\"+str(FOV[1])+'pc_'+str(vel_prime)+'_vel_res_'+str(beam_req)+\"_beam_size_req_\"+str(pix_thresh_factor)+'_times_beam_pixels.fits'\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    Names[Num][kl][km][k3][k4] = Cube_Name_Save\n",
    "                    \n",
    "                    NameS = (Cube_Name_Save+\"Sigmas\")\n",
    "                    NameR = (Cube_Name_Save+\"Radii\")\n",
    "                    NameCol = (Cube_Name_Save+\"_Column\")\n",
    "                    NameLum = (Cube_Name_Save+\"_Luminosities\")\n",
    "\n",
    "                    NameFlux = (Cube_Name_Save+\"Flux_Dense\")\n",
    "                    NameRFF = (Cube_Name_Save+\"Rad_For_Flux\")\n",
    "                    \n",
    "                    print(Cube_Name_Save)\n",
    "                    \n",
    "                    np.save(\"Names_New_All_Kinds\",Names)\n",
    "\n",
    "                    \n",
    "                   \n",
    "\n",
    "\n",
    "                    d = astrodendro.Dendrogram.compute(datn,min_delta=m,min_value=m*5,min_npix=beam_area_ratio.value*pix_thresh_factor) #The main culprit\n",
    "                    #d = astrodendro.Dendrogram.compute(datn,min_delta=m,min_value=m*5,min_npix=beam_area_ratio.value) #The main culprit\n",
    "\n",
    "                    vel,RA,Dec = scF.world[:,0,0]\n",
    "                    Rads,Sigmas,CD,Lumin,SIDS,MOM0FLUX,Distances,V_err = Dendro_Arrays(d,datn,vel,Continuum_Data,metadata,beam_size=Prime_Beam.value,beam_req=beam_req)\n",
    "                    \n",
    "\n",
    "                    ##Analyze dendograms\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    fig = plt.figure(1,figsize=(40,40))\n",
    "\n",
    "\n",
    "                    axAlpha = pylab.subplot(5, 5, 7)\n",
    "                    axBeta = pylab.subplot(5, 5, 8)\n",
    "                    axGamma = pylab.subplot(5, 5, 9)\n",
    "                    axDelta = pylab.subplot(5, 5, 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    p1=d.plotter()\n",
    "                    p1.plot_tree(axAlpha)\n",
    "                    axAlpha.set_xlabel(\"Structure\")\n",
    "                    axAlpha.set_ylabel(\"Flux (K)\")\n",
    "                    axAlpha.set_title(\"Whole data set\")\n",
    "\n",
    "\n",
    "\n",
    "                    #Plot contours for the top ten clusters\n",
    "\n",
    "\n",
    "                    #scCropped =scF.moment0().hdu.data\n",
    "                    scCropped =scF.moment0().hdu.data\n",
    "                    scCropped[np.where(scF.moment0().hdu.data<.22)]=np.nan\n",
    "                    print(np.nanmean(np.nanstd(scF.moment0().hdu.data))*1)\n",
    "                    scCropped[bp]=np.nan\n",
    "                    axDelta = pylab.subplot(5,5,8,projection=scF.moment0().wcs)\n",
    "                    #axBeta.imshow(scCropped.moment0().hdu.data, origin='lower', interpolation='nearest', cmap=plt.cm.Blues,norm=colors.LogNorm(vmin=5))\n",
    "                    imBeta = axDelta.imshow(scCropped, origin='lower', interpolation='nearest', cmap=plt.cm.Blues,vmin=0,vmax = np.nanmax(scCropped)*.7 )\n",
    "\n",
    "\n",
    "\n",
    "                    ColumnCon= np.concatenate((CD[0],CD[1]))\n",
    "                    SIDScon = np.concatenate((SIDS[0],SIDS[1]))\n",
    "                    nth =0# sorted(CD[0])[len(CD[0])-20]\n",
    "\n",
    "                    G1 = True\n",
    "\n",
    "                    RA = axDelta.coords[0]                                                                  # \n",
    "                    Dec = axDelta.coords[1]\n",
    "\n",
    "                    RA.set_ticks(size=-3)                                                                                      \n",
    "                    Dec.set_ticks(size=-3) \n",
    "                    RA.set_ticklabel(exclude_overlapping=True) \n",
    "                    Dec.set_ticklabel(exclude_overlapping=True)                                                                                     \n",
    "                    pylab.xlabel('Right Ascension',fontsize=20,labelpad=1)                               \n",
    "                    pylab.ylabel('Declination',fontsize=20,labelpad=1)\n",
    "                    axDelta.tick_params(axis = 'both', which = 'major', labelsize = 15)    \n",
    "                    cb=pylab.colorbar(imBeta,fraction=0.016,pad=0.04)                                     \n",
    "                    cb.set_label(label=\"Moment 0 K km/s\",fontsize=10,rotation=270,labelpad=20) \n",
    "                    cb.ax.tick_params(which = 'major', labelsize = 10)   \n",
    "                    pylab.annotate(s=LineN,fontsize=10,xy=(.01,1.05),xycoords=\"axes fraction\",c=\"black\")  \n",
    "                    pylab.annotate(s=\"Highest Density\",fontsize=10,xy=(.31,1.05),xycoords=\"axes fraction\",c=\"red\")  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    pc_per_pixel = abs(header[\"CDELT1\"])/180*np.pi*metadata['distance']/u.Mpc\n",
    "\n",
    "                    sig_per_pixel=np.nan#metadata['spectral_resolution']/u.pix\n",
    "\n",
    "\n",
    "                    #Finds Size, Linewidth, Luminosity, and Column Density of a structure for each structure and returns them in [[][]] arrays [Leaves][Branches]\n",
    "\n",
    "\n",
    "                    from scipy.optimize import curve_fit\n",
    "                    from scipy.optimize import leastsq\n",
    "\n",
    "                    def func(R,a,b):\n",
    "                        return a*R**(b)\n",
    "                    try:\n",
    "                        popt, pcov = curve_fit(func, Rads[0]*10**6,Sigmas[0])\n",
    "                    except:\n",
    "                        popt, pcov = [np.nan,np.nan],[[np.nan,np.nan],[np.nan,np.nan]]\n",
    "                    try:\n",
    "                        poptB, pcovB = curve_fit(func,  Rads[1]*10**6,Sigmas[1])\n",
    "                    except:\n",
    "                        poptB, pcovB = [np.nan,np.nan],[[np.nan,np.nan],[np.nan,np.nan]]\n",
    "\n",
    "                    \n",
    "\n",
    "                    Rcon = np.concatenate((Rads[0],Rads[1]))\n",
    "\n",
    "                        \n",
    "                    Scon = np.concatenate((Sigmas[0],Sigmas[1]))\n",
    "                    Scon2 = np.concatenate((Sigmas[2],Sigmas[3]))\n",
    "                    print(np.shape(Rcon))\n",
    "                    \n",
    "                    poptCon, pcovCon = curve_fit(func, Rcon*10**6, Scon)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    xs=np.linspace(np.nanmin(Rcon*10**6),np.nanmax(Rcon*10**6),50)\n",
    "\n",
    "                    ysL,ysB,ysCon=func(xs,popt[0],popt[1]),func(xs,poptB[0],poptB[1]),func(xs,poptCon[0],poptCon[1])\n",
    "\n",
    "\n",
    "                    LuminCon = np.concatenate((Lumin[0],Lumin[1]))\n",
    "                    ColumnCon= np.concatenate((CD[0],CD[1]))\n",
    "\n",
    "                    MOM0FLUXcon = np.concatenate((MOM0FLUX[0],MOM0FLUX[1]))\n",
    "                    DistancesCon= np.concatenate((Distances[0],Distances[1]))\n",
    "                    print(Distances)\n",
    "\n",
    "                    #Radius Luminosity fit\n",
    "                    #Good pixels are places where the luminosity and therefore column density are above zero\n",
    "                    gp = np.where(LuminCon>0)\n",
    "                    print(np.shape(Rcon),np.shape(LuminCon))\n",
    "                    lgp = LuminCon[gp]\n",
    "                    radgp = Rcon[gp]*10**6\n",
    "\n",
    "                    gp2 = np.where(ColumnCon>0)\n",
    "                    cgp = ColumnCon[gp2]\n",
    "                    rgp=Scon[gp2]**2/Rcon[gp2]/10**6\n",
    "                    dgp=DistancesCon[gp2]\n",
    "                    radgpFORRAT = Rcon[gp2]*10**6\n",
    "                    siggpFORRAT = Scon[gp2]\n",
    "                    lumFORRAT = LuminCon[gp2]\n",
    "                    mom0FORRAT = MOM0FLUXcon[gp2]\n",
    "\n",
    "                    #print(np.shape(Rcon[gp]*10**6),np.shape(LuminCon[gp]))\n",
    "                    RLpopt,RLpcov = curve_fit(func, np.array(radgp,dtype='float64'),np.array(lgp,dtype='float64'),maxfev=999999,p0 = np.array([10**27,1],dtype='float64'),ftol = 10**-10)\n",
    "\n",
    "                    xsRL=np.linspace(np.nanmin(radgp),np.nanmax(radgp),50)\n",
    "                    ysRL = func(xsRL,RLpopt[0],RLpopt[1])\n",
    "                    #Column density to Size-linewidth\n",
    "                    CDpopt,CDpcov = curve_fit(func, np.array(cgp,dtype='float64') ,np.array(rgp,dtype='float64'),maxfev=9999099,p0 = np.array([10,.01],dtype='float64'),ftol = 10**-10)\n",
    "\n",
    "                    Dist_popt,Dist_pcov = curve_fit(func, np.array(DistancesCon,dtype='float64') ,np.array(Scon,dtype='float64'),maxfev=9999099,ftol = 10**-10)\n",
    "                    Dist_popt2,Dist_pcov2 = curve_fit(func, np.array(dgp,dtype='float64') ,np.array(rgp,dtype='float64'),maxfev=9999099,ftol = 10**-10)\n",
    "\n",
    "                    xsDist=np.linspace(np.nanmin(DistancesCon),np.nanmax(DistancesCon),50)\n",
    "                    xsDist2=np.linspace(np.nanmin(dgp),np.nanmax(dgp),50)\n",
    "                    ysDist=func(xsDist,Dist_popt[0],Dist_popt[1])\n",
    "                    ysDist2=func(xsDist2,Dist_popt2[0],Dist_popt2[1])\n",
    "\n",
    "\n",
    "                    axdis = pylab.subplot(5, 5, 12)\n",
    "                    axdis2 = pylab.subplot(5, 5, 13)\n",
    "                    axdis.scatter(DistancesCon,Scon)\n",
    "                    axdis2.scatter(dgp,rgp)\n",
    "                    axdis.plot(xsDist,ysDist)\n",
    "                    axdis2.plot(xsDist2,ysDist2)\n",
    "                    axdis2.set_yscale('log')\n",
    "                    axdis2.set_xscale('log')\n",
    "                    axdis.set_yscale('log')\n",
    "                    axdis.set_xscale('log')\n",
    "\n",
    "                    xsCD=np.linspace(np.nanmin(cgp),np.nanmax(cgp),50)\n",
    "                    ysCD = func(xsCD,CDpopt[0],CDpopt[1])\n",
    "\n",
    "\n",
    "                    print(poptCon,pcovCon,\"Size Linewidth All_structures:\")\n",
    "                    print(\"a = \",poptCon[0],\"+-\",np.sqrt(pcovCon[0][0]))\n",
    "                    print(\"b = \",poptCon[1],\"+-\",np.sqrt(pcovCon[1][1]))\n",
    "\n",
    "\n",
    "                    print(RLpopt,RLpcov,\"Radius to Luminosity:\")\n",
    "                    print(\"c = \",RLpopt[0],\"+-\",np.sqrt(RLpcov[0][0]))\n",
    "                    print(\"d = \",RLpopt[1],\"+-\",np.sqrt(RLpcov[1][1]))\n",
    "\n",
    "\n",
    "\n",
    "                    print(CDpopt,CDpcov,\"Column Density to linewidth^2/size:\")\n",
    "                    print(\"e = \",CDpopt[0],\"+-\",np.sqrt(CDpcov[0][0]))\n",
    "                    print(\"f = \",CDpopt[1],\"+-\",np.sqrt(CDpcov[1][1]))\n",
    "\n",
    "\n",
    "\n",
    "                    ax2 = pylab.subplot(5, 5, 1)\n",
    "                    ax3 = pylab.subplot(5, 5, 2)\n",
    "                    ax4 = pylab.subplot(5, 5, 3)\n",
    "\n",
    "                    xpcon = ax2.scatter(Rcon*10**6,Scon,label=\"All_structures\",s=30,alpha=.7)\n",
    "\n",
    "\n",
    "                    p = ax2.plot(xs,ysCon)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    st=\"WDS: a=\"+ str(np.format_float_scientific(poptCon[0],1))+\"+-\"+str(np.format_float_scientific(np.sqrt(pcovCon[0][0]),1))+\" b=\"+str(np.format_float_scientific(poptCon[1],1))+\"+-\"+str(np.format_float_scientific(np.sqrt(pcovCon[1][1]),2))\n",
    "                    ax2.annotate(s=st,fontsize=10,xy=(0.01,0.01),xycoords=\"axes fraction\")\n",
    "\n",
    "                    ax2.annotate(s=r'$\\sigma$ = $a*R^b$',fontsize=10,xy=(0.01,0.10),xycoords=\"axes fraction\")\n",
    "                    ax2.set_yscale('log')\n",
    "                    ax2.set_xscale('log')\n",
    "                    ax2.set_ylim(np.nanmin(Scon),np.nanmax(Scon))\n",
    "                    ax2.set_xlabel(\"Size (pc)\",fontsize=12)\n",
    "                    ax2.set_ylabel(\"Sigma (km/s)\",fontsize=12)\n",
    "                    ax2.legend(prop={'size': 12},loc=\"upper right\")\n",
    "                    ax2.annotate(s=LineN,fontsize=10,xy=(0.01,0.89),xycoords=\"axes fraction\")\n",
    "\n",
    "                    #gp = np.where(FRs>0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    xspL = ax4.scatter(radgpFORRAT,siggpFORRAT,label=\"All_structures\",s=30)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    ax4.set_yscale('log')\n",
    "                    ax4.set_xscale('log')\n",
    "\n",
    "                    ax4.set_xlabel(\"Radius (pc)\",fontsize=12)\n",
    "                    ax4.set_ylabel(\"sig (km/s)\",fontsize=12)\n",
    "                    ax4.legend(prop={'size': 12},loc=\"upper right\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    xspF = ax3.scatter(radgpFORRAT,rgp,label=\"All_structures\",s=30)\n",
    "\n",
    "                    ax3.annotate(s=st,fontsize=12,xy=(0.01,0.04),xycoords=\"axes fraction\")\n",
    "                    ax3.set_yscale('log')\n",
    "                    ax3.set_xscale('log')\n",
    "                    ax3.set_ylim(np.nanmin(rgp),np.nanmax(rgp))\n",
    "                    ax3.set_xlabel(\"Rad (pc)\",fontsize=12)\n",
    "                    ax3.set_ylabel(\"Linewidth Ratio (km^2/s^2/pc)\",fontsize=12)\n",
    "                    ax3.legend(prop={'size': 12})\n",
    "\n",
    "                    gp3 = np.where(lumFORRAT>0)\n",
    "                    lumFORRAT = lumFORRAT[gp3]\n",
    "                    rgpFORRAT = rgp[gp3]\n",
    "                    mom0FORRAT = mom0FORRAT[gp3]\n",
    "\n",
    "\n",
    "\n",
    "                    ax5 = pylab.subplot(5, 5, 4)\n",
    "                    ax6 = pylab.subplot(5, 5, 5)\n",
    "                    ax7 = pylab.subplot(5, 5, 6)\n",
    "\n",
    "\n",
    "\n",
    "                    xpconhh = ax5.scatter(radgpFORRAT,cgp,label=\"All_structures\",s=30,alpha=.7)\n",
    "                    ax5.set_yscale('log')\n",
    "                    ax5.set_xscale('log')\n",
    "                    ax5.set_xlabel(\"Size (pc)\",fontsize=12)\n",
    "                    ax5.set_ylabel(\"Column Density (#/cm^2 > 7e22)\",fontsize=12)\n",
    "                    ax5.legend(prop={'size': 12},loc=\"upper right\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    xspF2 = ax6.scatter(cgp,rgp,label=\"All_structures\",s=30,alpha=.7)\n",
    "                    pF2 = ax6.plot(xsCD,ysCD)\n",
    "\n",
    "                    ax6.set_yscale('log')\n",
    "                    ax6.set_xscale('log')\n",
    "                    ax6.set_ylim(np.nanmin(rgp),np.nanmax(rgp))\n",
    "                    ax6.set_xlabel(\"Column Density (#/cm^2 > 7e22)\",fontsize=12)\n",
    "                    ax6.set_ylabel(\"Linewidth Ratio (km^2/s^2/pc)\",fontsize=12)\n",
    "                    ax6.legend(prop={'size': 12},loc=\"upper right\")\n",
    "                    ax6.annotate(s=LineN,fontsize=10,xy=(0.01,0.89),xycoords=\"axes fraction\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    xspLu2 = ax7.scatter(radgp,lgp,label=\"All_structure Whole Data Set\",s=30,alpha=.7)\n",
    "                    pFLLu2 = ax7.plot(xsRL,ysRL)\n",
    "\n",
    "                    st = \"WDS, c = \"+ str(np.format_float_scientific(RLpopt[0],3))+\"+-\"+str(np.format_float_scientific(np.sqrt(RLpcov[0][0]),3))+\" d = \"+str(np.format_float_scientific(RLpopt[1],3))+\"+-\"+str(np.format_float_scientific(np.sqrt(RLpcov[1][1]),3))\n",
    "                    ax7.annotate(s='L = $c*R^d$',fontsize=12,xy=(0.01,0.13),xycoords=\"axes fraction\")\n",
    "                    ax7.annotate(s=st,fontsize=12,xy=(0.01,0.04),xycoords=\"axes fraction\")\n",
    "\n",
    "                    ax7.set_yscale('log')\n",
    "                    ax7.set_xscale('log')\n",
    "                    ax7.set_ylim(np.nanmin(lgp),np.nanmax(lgp))\n",
    "                    ax7.set_xlabel(\"Radius (pc)\",fontsize=9)\n",
    "                    ax7.set_ylabel(\"Luminosity (erg)\",fontsize=9)\n",
    "                    ax7.legend(prop={'size': 12},loc=\"upper right\")\n",
    "                    ax7.annotate(s=LineN,fontsize=10,xy=(0.01,0.89),xycoords=\"axes fraction\")\n",
    "\n",
    "\n",
    "                    axLam = pylab.subplot(5, 5, 11)\n",
    "                    lum_rat = axLam.scatter(lumFORRAT/radgpFORRAT**2,rgpFORRAT,label=\"All_structure  \",s=30,alpha=.7)\n",
    "                    #Off by factors for area, simply using r^2\n",
    "\n",
    "                    axLam.set_yscale('log')\n",
    "                    axLam.set_xscale('log')\n",
    "                    axLam.set_xlabel(\"Lum/R^2 (erg/pc^2)\",fontsize=9)\n",
    "                    axLam.set_ylabel(\"Linewidth Ratio (km/s)^2/pc\",fontsize=9)\n",
    "                    axLam.legend(prop={'size': 12},loc=\"upper right\")\n",
    "                    axLam.annotate(s=LineN,fontsize=10,xy=(0.01,0.89),xycoords=\"axes fraction\")\n",
    "\n",
    "\n",
    "\n",
    "                    axDelta = pylab.subplot(5, 5, 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    gp4=np.where(MOM0FLUXcon>0)\n",
    "                    mom0FORFlux=MOM0FLUXcon[gp4]\n",
    "                    radgpFORFlux=Rcon[gp4]*10**6\n",
    "                    rgpFORFlux=Scon[gp4]**2/Rcon[gp4]/10**6\n",
    "\n",
    "                    mom0_rat = axDelta.scatter(mom0FORFlux/radgpFORFlux**2,rgpFORFlux,label=\"All_structure  \",s=30,alpha=.7)\n",
    "                    #Off by factors for area, simply using r^2\n",
    "\n",
    "                    axDelta.set_yscale('log')\n",
    "                    axDelta.set_xscale('log')\n",
    "                    axDelta.set_xlabel(\"Mom0 Flux/pc^2 (K km/s / R^2)\",fontsize=9)\n",
    "                    axDelta.set_ylabel(\"Linewidth Ratio (km/s)^2/pc\",fontsize=9)\n",
    "                    axDelta.legend(prop={'size': 12},loc=\"upper right\")\n",
    "                    axDelta.annotate(s=LineN,fontsize=10,xy=(0.01,0.89),xycoords=\"axes fraction\")\n",
    "\n",
    "\n",
    "                    pylab.show()\n",
    "\n",
    "\n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    v1 = d.viewer()\n",
    "                    v1.show()\n",
    "\n",
    "                    #Must use text because np load is broken\n",
    "                    if(Abs_Level==\"All\"):\n",
    "                        Suffix=''\n",
    "                    if(Abs_Level==\"None\"):\n",
    "                        Suffix='_NA'\n",
    "                    if(Abs_Level==\"No Clusters\"):\n",
    "                        Suffix='_No_Clusters'\n",
    "                    if(Abs_Level==\"None (m)\"):\n",
    "                        Suffix='None_m'\n",
    "                    if(Abs_Level==\"None All Channels\"):\n",
    "                        Suffix='None_All_Channels'\n",
    "                        \n",
    "                    \n",
    "                    \n",
    "\n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameCol+\"_Leaves\"+Suffix), CD[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameCol+\"_Branches\"+Suffix), CD[1],fmt='%s')\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameLum+\"_Leaves\"+Suffix), Lumin[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameLum+\"_Branches\"+Suffix), Lumin[1],fmt='%s')\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameS+\"_Leaves\"+Suffix), Sigmas[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameS+\"_Branches\"+Suffix), Sigmas[1],fmt='%s')\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameR+\"_Leaves\"+Suffix), Rads[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameR+\"_Branches\"+Suffix), Rads[1],fmt='%s')\n",
    "\n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameFlux+\"_Leaves\"+Suffix), MOM0FLUX[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameFlux+\"_Branches\"+Suffix), MOM0FLUX[1],fmt='%s')\n",
    "\n",
    "\n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,Cube_Name_Save+\"Distances_Leaves\"+Suffix), Distances[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,Cube_Name_Save+\"Distances_Branches\"+Suffix), Distances[1],fmt='%s')\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,Cube_Name_Save+\"V_err_Leaves\"+Suffix), V_err[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,Cube_Name_Save+\"V_err_Branches\"+Suffix), V_err[1],fmt='%s')\n",
    "\n",
    "                    SIDS=np.concatenate((SIDS[0],SIDS[1]))\n",
    "\n",
    "                    print(SIDS[len(SIDS)-3:len(SIDS)-1])\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    print(kl,km,k3,k4)\n",
    "                    print(\"Failed\")\n",
    "                    print(\"-\"*60)\n",
    "                    traceback.print_exc(file=sys.stdout)\n",
    "                    \n",
    "                    if(Abs_Level==\"All\"):\n",
    "                        Suffix=''\n",
    "                    if(Abs_Level==\"None\"):\n",
    "                        Suffix='_NA'\n",
    "                    if(Abs_Level==\"No Clusters\"):\n",
    "                        Suffix='_No_Clusters'\n",
    "                    if(Abs_Level==\"None (m)\"):\n",
    "                        Suffix='None_m'\n",
    "                    if(Abs_Level==\"None All Channels\"):\n",
    "                        Suffix='None_All_Channels'\n",
    "                    nans = [[np.nan,np.nan],[np.nan,np.nan]]\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameCol+\"_Leaves\"+Suffix), nans[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameCol+\"_Branches\"+Suffix), nans[1],fmt='%s')\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameLum+\"_Leaves\"+Suffix), nans[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameLum+\"_Branches\"+Suffix), nans[1],fmt='%s')\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameS+\"_Leaves\"+Suffix), nans[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameS+\"_Branches\"+Suffix), nans[1],fmt='%s')\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameR+\"_Leaves\"+Suffix), nans[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameR+\"_Branches\"+Suffix), nans[1],fmt='%s')\n",
    "\n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameFlux+\"_Leaves\"+Suffix), nans[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameFlux+\"_Branches\"+Suffix), nans[1],fmt='%s')\n",
    "\n",
    "\n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,Cube_Name_Save+\"Distances_Leaves\"+Suffix), nans[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,Cube_Name_Save+\"Distances_Branches\"+Suffix), nans[1],fmt='%s')\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,Cube_Name_Save+\"V_err_Leaves\"+Suffix), nans[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,Cube_Name_Save+\"V_err_Branches\"+Suffix), nans[1],fmt='%s')\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd47c44a-ad9e-45d3-89d1-3f8cf753f180",
   "metadata": {},
   "outputs": [],
   "source": [
    "#No Abs\n",
    "\n",
    "Abs_Level = Abs_Levels[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pathCont = 'Continuum_Reproject.fits'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for kl in range(iterations):\n",
    "      \n",
    "    Prime_Beam = Min_res*((kl*iter_factor+1))#\n",
    "    print(Prime_Beam)\n",
    "    \n",
    "    \n",
    "    for km in range(iterations):\n",
    "        vel_prime = min_vel*((km*iter_factor+1))\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        try:\n",
    "            Names=list(np.load(\"Names_New_All_Kinds.npy\",allow_pickle=True))\n",
    "        except Exception as e:\n",
    "\n",
    "            print(e)\n",
    "            print(\"initialized names\")\n",
    "            Names = list(np.empty((20,iterations,iterations,iterations,iterations),dtype=object))\n",
    "                        \n",
    "\n",
    "        #Continuum image\n",
    "        scCont = spectral_cube.Projection.from_hdu(fits.open(pathCont)[0])\n",
    "        #Put this up here for the column density map\n",
    "        metadata = {}\n",
    "        metadata[\"distance\"] = 3.5*u.Mpc\n",
    "        arc_per_pix_yc =  abs(scCont.hdu.header[\"CDELT1\"]*3600.0 * u.arcsec)/u.pix\n",
    "        arc_per_pix_xc =  abs(scCont.hdu.header[\"CDELT2\"]*3600.0 * u.arcsec)/u.pix\n",
    "        beam_majorc =  scCont.hdu.header[\"BMAJ\"]*3600.0 * u.arcsec\n",
    "        beam_minorc =  scCont.hdu.header[\"BMIN\"]*3600.0 * u.arcsec\n",
    "        beam_area_ratioc = beam_minorc*beam_majorc/arc_per_pix_yc/arc_per_pix_xc*1.13309#beam_area_ratioc = beam_minorc*beam_majorc/arc_per_pix_yc/arc_per_pix_xc#This is for FWHM, use *(2*np.sqrt(2*np.log(2)))**2#For gaussian beam\n",
    "        metadata['beam_area_ratioc']=beam_area_ratioc\n",
    "        pc_per_pixelc = abs(scCont.hdu.header[\"CDELT1\"])/180*np.pi*metadata['distance']/u.Mpc\n",
    "        print(pc_per_pixelc,\"MPC per pix\")\n",
    "\n",
    "        #Make subcube\n",
    "\n",
    "\n",
    "\n",
    "        Cube_Name_Load = \"Cropped_\"+str(Prime_Beam.value)+\"pc_beam_\"+Line_Name+str(FOV[0])+\"x\"+str(FOV[1])+'pc_'+str(vel_prime)+'_vel_res.fits'\n",
    "        path = Cube_Name_Load\n",
    "        \n",
    "        Qp = SpectralCube.read(path).with_spectral_unit(u.km/u.s,velocity_convention=\"radio\") \n",
    "        Qp.allow_huge_operations=True\n",
    "\n",
    "        Q = Qp.to(u.K)#Jy to Kelvin\n",
    "\n",
    "        sc = Q.unmasked_copy()\n",
    "\n",
    "\n",
    "\n",
    "        scW = sc.wcs[:][:][0]\n",
    "        dat = sc.hdu.data[int(len(sc)*((1-Ram_Limiter)/2)):int(len(sc)*(Ram_Limiter + (1-Ram_Limiter)/2)),:,:]\n",
    "        scn = sc[int(len(sc)*((1-Ram_Limiter)/2)):int(len(sc)*(Ram_Limiter + (1-Ram_Limiter)/2)),:,:]\n",
    "        scF = scn\n",
    "        datn = dat\n",
    "\n",
    "\n",
    "        #m=.115\n",
    "\n",
    "        #print(m,\"Presumed Noise (K)\")\n",
    "\n",
    "        #Continuum image\n",
    "        scCont = spectral_cube.Projection.from_hdu(fits.open(pathCont)[0])\n",
    "        #Do the same thing to the continuum image\n",
    "        scCont.allow_huge_operations=True\n",
    "        scContW = scCont.reproject(scF.moment0().header)\n",
    "        #m=.115\n",
    "\n",
    "\n",
    "        scW = sc.wcs[:][:][0]\n",
    "\n",
    "        cen_p1 = SkyCoord('00h47m33.9s', '-25d17m26.8s', frame='icrs')\n",
    "        cen_p2 = SkyCoord('00h47m32.6s', '-25d17m10.2s', frame='icrs')\n",
    "\n",
    "\n",
    "        #Do the same thing to the continuum image\n",
    "        scCont.allow_huge_operations=True\n",
    "        scContW = scCont.reproject(scF.moment0().header)\n",
    "        Continuum_Data  =scContW.hdu.data\n",
    "        scWCS = scF.wcs[:][:][0]\n",
    "\n",
    "        moment_0_sub  = scF.to(u.K).moment(order=0,how='slice')            # Calculate the Moment 0 map \n",
    "\n",
    "\n",
    "\n",
    "        ######Moment 0 for both\n",
    "        ######and cont\n",
    "        Make_Plot((LineN+\" Moment 0\"),\"Moment 0 (K km/s)\",moment_0_sub.hdu.data,0,np.nanmax(moment_0_sub.hdu.data),moment_0_sub.wcs,1,1,1,True)\n",
    "\n",
    "\n",
    "        cSD = (Flux_to_Mass(scContW.hdu.data*u.Jy/u.beam/beam_area_ratioc*u.pix**2*u.beam)/(pc_per_pixelc*10**6*3.086*10**18*u.cm)**2)*(1.989*10**30*u.kg/u.M_sun)*Num_per_kg/u.kg #Flux goes to luminosity for a gaussian beam and goes to column density for square pixels, mass goes to kg to number\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        rm=moment_0_sub.hdu.data/cSD\n",
    "        rmU = rm*u.K*u.km/u.s#Just put back in the units\n",
    "        rmU = np.array(rmU /(u.K*u.km/u.s)/u.cm**2*10**22,dtype='float64')#Now remove them all\n",
    "\n",
    "        ######ratio\n",
    "\n",
    "        bp = np.where(cSD<=7*10**22/u.cm**2)\n",
    "        bp2 = np.where( moment_0_sub.hdu.data < .22)\n",
    "        Continuum_Data[bp] = np.nan\n",
    "        cSD[bp]=np.nan\n",
    "        rmU[bp]=np.nan\n",
    "        rmU[bp2]=np.nan\n",
    "\n",
    "        Non_nan=((datn[0,:,:]>0)  | (datn[0,:,:]<0 ))\n",
    "\n",
    "        m = (np.nanstd(datn[0,:,:],where= Non_nan)) #Noise K\n",
    "        if(Abs_Level==\"All\"):\n",
    "            pass\n",
    "        if(Abs_Level==\"None\"):\n",
    "            datn[np.where(datn<0)]=np.nan\n",
    "        if(Abs_Level==\"None (m)\"):\n",
    "            datn[np.where(datn<-m)]=np.nan\n",
    "        if(Abs_Level==\"None All Channels\"):\n",
    "            for lmi in range(len(datn)):\n",
    "                bpP = np.where(datn[lmi]<-m)\n",
    "                for lmj in range(len(datn)):\n",
    "                    datn[lmj][bpP]=np.nan\n",
    "        if(Abs_Level==\"No Clusters\"):\n",
    "            IDs,RAs,Decs,HWHM  =    np.genfromtxt(\"NGC_Clusters_\"+\"IDs\"+\"\",dtype=type(\"12h23.14s\")),np.genfromtxt(\"NGC_Clusters_\"+\"RAs\"+\"\",dtype=type(\"12h23.14s\")),np.genfromtxt(\"NGC_Clusters_\"+\"Decs\"+\"\",dtype=type(\"12h23.14s\")),np.genfromtxt(\"NGC_Clusters_\"+\"HWHM\"+\"\")\n",
    "\n",
    "            datn=  Mask_Clusters_NGC(HWHM,scWCS,scF.hdu.header,datn,RAs,Decs,One_Pc=False,One_Pc_Size=1,HWHM_Fac=3)\n",
    "\n",
    "        print(m,\"Unmatched Noise (K)\", \"Abs = \",Abs_Level)\n",
    "\n",
    "\n",
    "        Make_Plot(\"Column Density\",\"(#/cm^2)\",cSD,float(np.nanmin(cSD*u.cm**2)),float(np.nanmax(cSD*u.cm**2)),scCont.wcs,1,1,1,True)\n",
    "        Make_Plot((LineN+\" Moment 0/Column Density\"),\"Moment 0 over Column Density of the Continuum (K km/s/(#/cm^2))\",rmU,np.nanmean(rmU)*.5,abs(np.nanmean(rmU))*8,scCont.wcs,1,1,1,True)\n",
    "\n",
    "        print(np.nanmin(rmU))\n",
    "\n",
    "\n",
    "\n",
    "        header = scF.hdu.header\n",
    "        print()\n",
    "        #make metadata for the dendrogram\n",
    "\n",
    "        try:\n",
    "            freq = header[\"RESTFREQ\"]*u.Hz#\n",
    "            metadata['wavelength']=299792458*u.m/header[\"RESTFREQ\"]#\n",
    "            print(1,freq,metadata['wavelength'])\n",
    "        except:\n",
    "            freq = header[\"RESTFRQ\"]*u.Hz#\n",
    "            metadata['wavelength']=299792458*u.m/header[\"RESTFRQ\"]#\n",
    "        metadata['data_unit'] =scF[0][0][0].unit# header['BUNIT']\n",
    "        metadata['arc_per_pix_y'] =  abs(header[\"CDELT1\"]*3600.0 * u.arcsec)/u.pix\n",
    "        metadata['arc_per_pix_x'] =  abs(header[\"CDELT2\"]*3600.0 * u.arcsec)/u.pix\n",
    "\n",
    "\n",
    "        metadata['beam_major'] =  header[\"BMAJ\"]*3600.0 * u.arcsec\n",
    "        metadata['beam_minor'] =  header[\"BMIN\"]*3600.0 * u.arcsec\n",
    "        beam_area_ratio = metadata['beam_minor']*metadata['beam_major']/metadata['arc_per_pix_y']/metadata['arc_per_pix_x']*1.13309#beam_area_ratio = metadata['beam_minor']*metadata['beam_major']/metadata['arc_per_pix_y']/metadata['arc_per_pix_x']#This is for FWHM, use *(2*np.sqrt(2*np.log(2)))**2#For gaussian beam\n",
    "        metadata['beam_area_ratio']=beam_area_ratio\n",
    "        metadata['spatial_scale'] = np.sqrt(abs(header[\"CDELT1\"])*u.degree**2*abs(header[\"CDELT2\"]))\n",
    "        area_res = abs(header[\"CDELT1\"])*abs(header[\"CDELT2\"])*(np.pi/180*3.5)**2#mpc^2/pix^2\n",
    "        print(area_res,type(area_res))\n",
    "\n",
    "        print(metadata['beam_minor'],metadata['beam_major'])\n",
    "        print(beam_area_ratio)\n",
    "        #metadata[\"wcs\"] = wcs\n",
    "        metadata[\"velocity_scale\"] = abs(header[\"CDELT3\"])*u.km/u.s#u.km/u.s\n",
    "\n",
    "        metadata[\"vaxis\"]=0\n",
    "        metadata[\"wcsu\"]=scF.wcs\n",
    "\n",
    "\n",
    "        for k3 in range(iterations):\n",
    "\n",
    "            beam_req = Min_beam_req*(k3+1)\n",
    "            \n",
    "            for k4 in range(iterations):\n",
    "                print(kl,km,k3,k4)\n",
    "                try:\n",
    "\n",
    "                    pix_thresh_factor = k4+1\n",
    "\n",
    "                    Cube_Name_Save = Name+\"_Cropped_\"+str(Prime_Beam.value)+\"pc_beam_\"+Line_Name+str(FOV[0])+\"x\"+str(FOV[1])+'pc_'+str(vel_prime)+'_vel_res_'+str(beam_req)+\"_beam_size_req_\"+str(pix_thresh_factor)+'_times_beam_pixels.fits'\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    Names[Num][kl][km][k3][k4] = Cube_Name_Save\n",
    "                    \n",
    "                    NameS = (Cube_Name_Save+\"Sigmas\")\n",
    "                    NameR = (Cube_Name_Save+\"Radii\")\n",
    "                    NameCol = (Cube_Name_Save+\"_Column\")\n",
    "                    NameLum = (Cube_Name_Save+\"_Luminosities\")\n",
    "\n",
    "                    NameFlux = (Cube_Name_Save+\"Flux_Dense\")\n",
    "                    NameRFF = (Cube_Name_Save+\"Rad_For_Flux\")\n",
    "                    \n",
    "                    print(Cube_Name_Save)\n",
    "                    \n",
    "                    np.save(\"Names_New_All_Kinds\",Names)\n",
    "\n",
    "                    \n",
    "                   \n",
    "\n",
    "\n",
    "                    d = astrodendro.Dendrogram.compute(datn,min_delta=m,min_value=m*5,min_npix=beam_area_ratio.value*pix_thresh_factor) #The main culprit\n",
    "                    #d = astrodendro.Dendrogram.compute(datn,min_delta=m,min_value=m*5,min_npix=beam_area_ratio.value) #The main culprit\n",
    "\n",
    "                    vel,RA,Dec = scF.world[:,0,0]\n",
    "                    Rads,Sigmas,CD,Lumin,SIDS,MOM0FLUX,Distances,V_err = Dendro_Arrays(d,datn,vel,Continuum_Data,metadata,beam_size=Prime_Beam.value,beam_req=beam_req)\n",
    "                    \n",
    "\n",
    "                    ##Analyze dendograms\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    fig = plt.figure(1,figsize=(40,40))\n",
    "\n",
    "\n",
    "                    axAlpha = pylab.subplot(5, 5, 7)\n",
    "                    axBeta = pylab.subplot(5, 5, 8)\n",
    "                    axGamma = pylab.subplot(5, 5, 9)\n",
    "                    axDelta = pylab.subplot(5, 5, 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    p1=d.plotter()\n",
    "                    p1.plot_tree(axAlpha)\n",
    "                    axAlpha.set_xlabel(\"Structure\")\n",
    "                    axAlpha.set_ylabel(\"Flux (K)\")\n",
    "                    axAlpha.set_title(\"Whole data set\")\n",
    "\n",
    "\n",
    "\n",
    "                    #Plot contours for the top ten clusters\n",
    "\n",
    "\n",
    "                    #scCropped =scF.moment0().hdu.data\n",
    "                    scCropped =scF.moment0().hdu.data\n",
    "                    scCropped[np.where(scF.moment0().hdu.data<.22)]=np.nan\n",
    "                    print(np.nanmean(np.nanstd(scF.moment0().hdu.data))*1)\n",
    "                    scCropped[bp]=np.nan\n",
    "                    axDelta = pylab.subplot(5,5,8,projection=scF.moment0().wcs)\n",
    "                    #axBeta.imshow(scCropped.moment0().hdu.data, origin='lower', interpolation='nearest', cmap=plt.cm.Blues,norm=colors.LogNorm(vmin=5))\n",
    "                    imBeta = axDelta.imshow(scCropped, origin='lower', interpolation='nearest', cmap=plt.cm.Blues,vmin=0,vmax = np.nanmax(scCropped)*.7 )\n",
    "\n",
    "\n",
    "\n",
    "                    ColumnCon= np.concatenate((CD[0],CD[1]))\n",
    "                    SIDScon = np.concatenate((SIDS[0],SIDS[1]))\n",
    "                    nth =0# sorted(CD[0])[len(CD[0])-20]\n",
    "\n",
    "                    G1 = True\n",
    "\n",
    "                    RA = axDelta.coords[0]                                                                  # \n",
    "                    Dec = axDelta.coords[1]\n",
    "\n",
    "                    RA.set_ticks(size=-3)                                                                                      \n",
    "                    Dec.set_ticks(size=-3) \n",
    "                    RA.set_ticklabel(exclude_overlapping=True) \n",
    "                    Dec.set_ticklabel(exclude_overlapping=True)                                                                                     \n",
    "                    pylab.xlabel('Right Ascension',fontsize=20,labelpad=1)                               \n",
    "                    pylab.ylabel('Declination',fontsize=20,labelpad=1)\n",
    "                    axDelta.tick_params(axis = 'both', which = 'major', labelsize = 15)    \n",
    "                    cb=pylab.colorbar(imBeta,fraction=0.016,pad=0.04)                                     \n",
    "                    cb.set_label(label=\"Moment 0 K km/s\",fontsize=10,rotation=270,labelpad=20) \n",
    "                    cb.ax.tick_params(which = 'major', labelsize = 10)   \n",
    "                    pylab.annotate(s=LineN,fontsize=10,xy=(.01,1.05),xycoords=\"axes fraction\",c=\"black\")  \n",
    "                    pylab.annotate(s=\"Highest Density\",fontsize=10,xy=(.31,1.05),xycoords=\"axes fraction\",c=\"red\")  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    pc_per_pixel = abs(header[\"CDELT1\"])/180*np.pi*metadata['distance']/u.Mpc\n",
    "\n",
    "                    sig_per_pixel=np.nan#metadata['spectral_resolution']/u.pix\n",
    "\n",
    "\n",
    "                    #Finds Size, Linewidth, Luminosity, and Column Density of a structure for each structure and returns them in [[][]] arrays [Leaves][Branches]\n",
    "\n",
    "\n",
    "                    from scipy.optimize import curve_fit\n",
    "                    from scipy.optimize import leastsq\n",
    "\n",
    "                    def func(R,a,b):\n",
    "                        return a*R**(b)\n",
    "                    try:\n",
    "                        popt, pcov = curve_fit(func, Rads[0]*10**6,Sigmas[0])\n",
    "                    except:\n",
    "                        popt, pcov = [np.nan,np.nan],[[np.nan,np.nan],[np.nan,np.nan]]\n",
    "                    try:\n",
    "                        poptB, pcovB = curve_fit(func,  Rads[1]*10**6,Sigmas[1])\n",
    "                    except:\n",
    "                        poptB, pcovB = [np.nan,np.nan],[[np.nan,np.nan],[np.nan,np.nan]]\n",
    "\n",
    "                    \n",
    "\n",
    "                    Rcon = np.concatenate((Rads[0],Rads[1]))\n",
    "\n",
    "                        \n",
    "                    Scon = np.concatenate((Sigmas[0],Sigmas[1]))\n",
    "                    Scon2 = np.concatenate((Sigmas[2],Sigmas[3]))\n",
    "                    print(np.shape(Rcon))\n",
    "                    \n",
    "                    poptCon, pcovCon = curve_fit(func, Rcon*10**6, Scon)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    xs=np.linspace(np.nanmin(Rcon*10**6),np.nanmax(Rcon*10**6),50)\n",
    "\n",
    "                    ysL,ysB,ysCon=func(xs,popt[0],popt[1]),func(xs,poptB[0],poptB[1]),func(xs,poptCon[0],poptCon[1])\n",
    "\n",
    "\n",
    "                    LuminCon = np.concatenate((Lumin[0],Lumin[1]))\n",
    "                    ColumnCon= np.concatenate((CD[0],CD[1]))\n",
    "\n",
    "                    MOM0FLUXcon = np.concatenate((MOM0FLUX[0],MOM0FLUX[1]))\n",
    "                    DistancesCon= np.concatenate((Distances[0],Distances[1]))\n",
    "                    print(Distances)\n",
    "\n",
    "                    #Radius Luminosity fit\n",
    "                    #Good pixels are places where the luminosity and therefore column density are above zero\n",
    "                    gp = np.where(LuminCon>0)\n",
    "                    print(np.shape(Rcon),np.shape(LuminCon))\n",
    "                    lgp = LuminCon[gp]\n",
    "                    radgp = Rcon[gp]*10**6\n",
    "\n",
    "                    gp2 = np.where(ColumnCon>0)\n",
    "                    cgp = ColumnCon[gp2]\n",
    "                    rgp=Scon[gp2]**2/Rcon[gp2]/10**6\n",
    "                    dgp=DistancesCon[gp2]\n",
    "                    radgpFORRAT = Rcon[gp2]*10**6\n",
    "                    siggpFORRAT = Scon[gp2]\n",
    "                    lumFORRAT = LuminCon[gp2]\n",
    "                    mom0FORRAT = MOM0FLUXcon[gp2]\n",
    "\n",
    "                    #print(np.shape(Rcon[gp]*10**6),np.shape(LuminCon[gp]))\n",
    "                    RLpopt,RLpcov = curve_fit(func, np.array(radgp,dtype='float64'),np.array(lgp,dtype='float64'),maxfev=999999,p0 = np.array([10**27,1],dtype='float64'),ftol = 10**-10)\n",
    "\n",
    "                    xsRL=np.linspace(np.nanmin(radgp),np.nanmax(radgp),50)\n",
    "                    ysRL = func(xsRL,RLpopt[0],RLpopt[1])\n",
    "                    #Column density to Size-linewidth\n",
    "                    CDpopt,CDpcov = curve_fit(func, np.array(cgp,dtype='float64') ,np.array(rgp,dtype='float64'),maxfev=9999099,p0 = np.array([10,.01],dtype='float64'),ftol = 10**-10)\n",
    "\n",
    "                    Dist_popt,Dist_pcov = curve_fit(func, np.array(DistancesCon,dtype='float64') ,np.array(Scon,dtype='float64'),maxfev=9999099,ftol = 10**-10)\n",
    "                    Dist_popt2,Dist_pcov2 = curve_fit(func, np.array(dgp,dtype='float64') ,np.array(rgp,dtype='float64'),maxfev=9999099,ftol = 10**-10)\n",
    "\n",
    "                    xsDist=np.linspace(np.nanmin(DistancesCon),np.nanmax(DistancesCon),50)\n",
    "                    xsDist2=np.linspace(np.nanmin(dgp),np.nanmax(dgp),50)\n",
    "                    ysDist=func(xsDist,Dist_popt[0],Dist_popt[1])\n",
    "                    ysDist2=func(xsDist2,Dist_popt2[0],Dist_popt2[1])\n",
    "\n",
    "\n",
    "                    axdis = pylab.subplot(5, 5, 12)\n",
    "                    axdis2 = pylab.subplot(5, 5, 13)\n",
    "                    axdis.scatter(DistancesCon,Scon)\n",
    "                    axdis2.scatter(dgp,rgp)\n",
    "                    axdis.plot(xsDist,ysDist)\n",
    "                    axdis2.plot(xsDist2,ysDist2)\n",
    "                    axdis2.set_yscale('log')\n",
    "                    axdis2.set_xscale('log')\n",
    "                    axdis.set_yscale('log')\n",
    "                    axdis.set_xscale('log')\n",
    "\n",
    "                    xsCD=np.linspace(np.nanmin(cgp),np.nanmax(cgp),50)\n",
    "                    ysCD = func(xsCD,CDpopt[0],CDpopt[1])\n",
    "\n",
    "\n",
    "                    print(poptCon,pcovCon,\"Size Linewidth All_structures:\")\n",
    "                    print(\"a = \",poptCon[0],\"+-\",np.sqrt(pcovCon[0][0]))\n",
    "                    print(\"b = \",poptCon[1],\"+-\",np.sqrt(pcovCon[1][1]))\n",
    "\n",
    "\n",
    "                    print(RLpopt,RLpcov,\"Radius to Luminosity:\")\n",
    "                    print(\"c = \",RLpopt[0],\"+-\",np.sqrt(RLpcov[0][0]))\n",
    "                    print(\"d = \",RLpopt[1],\"+-\",np.sqrt(RLpcov[1][1]))\n",
    "\n",
    "\n",
    "\n",
    "                    print(CDpopt,CDpcov,\"Column Density to linewidth^2/size:\")\n",
    "                    print(\"e = \",CDpopt[0],\"+-\",np.sqrt(CDpcov[0][0]))\n",
    "                    print(\"f = \",CDpopt[1],\"+-\",np.sqrt(CDpcov[1][1]))\n",
    "\n",
    "\n",
    "\n",
    "                    ax2 = pylab.subplot(5, 5, 1)\n",
    "                    ax3 = pylab.subplot(5, 5, 2)\n",
    "                    ax4 = pylab.subplot(5, 5, 3)\n",
    "\n",
    "                    xpcon = ax2.scatter(Rcon*10**6,Scon,label=\"All_structures\",s=30,alpha=.7)\n",
    "\n",
    "\n",
    "                    p = ax2.plot(xs,ysCon)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    st=\"WDS: a=\"+ str(np.format_float_scientific(poptCon[0],1))+\"+-\"+str(np.format_float_scientific(np.sqrt(pcovCon[0][0]),1))+\" b=\"+str(np.format_float_scientific(poptCon[1],1))+\"+-\"+str(np.format_float_scientific(np.sqrt(pcovCon[1][1]),2))\n",
    "                    ax2.annotate(s=st,fontsize=10,xy=(0.01,0.01),xycoords=\"axes fraction\")\n",
    "\n",
    "                    ax2.annotate(s=r'$\\sigma$ = $a*R^b$',fontsize=10,xy=(0.01,0.10),xycoords=\"axes fraction\")\n",
    "                    ax2.set_yscale('log')\n",
    "                    ax2.set_xscale('log')\n",
    "                    ax2.set_ylim(np.nanmin(Scon),np.nanmax(Scon))\n",
    "                    ax2.set_xlabel(\"Size (pc)\",fontsize=12)\n",
    "                    ax2.set_ylabel(\"Sigma (km/s)\",fontsize=12)\n",
    "                    ax2.legend(prop={'size': 12},loc=\"upper right\")\n",
    "                    ax2.annotate(s=LineN,fontsize=10,xy=(0.01,0.89),xycoords=\"axes fraction\")\n",
    "\n",
    "                    #gp = np.where(FRs>0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    xspL = ax4.scatter(radgpFORRAT,siggpFORRAT,label=\"All_structures\",s=30)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    ax4.set_yscale('log')\n",
    "                    ax4.set_xscale('log')\n",
    "\n",
    "                    ax4.set_xlabel(\"Radius (pc)\",fontsize=12)\n",
    "                    ax4.set_ylabel(\"sig (km/s)\",fontsize=12)\n",
    "                    ax4.legend(prop={'size': 12},loc=\"upper right\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    xspF = ax3.scatter(radgpFORRAT,rgp,label=\"All_structures\",s=30)\n",
    "\n",
    "                    ax3.annotate(s=st,fontsize=12,xy=(0.01,0.04),xycoords=\"axes fraction\")\n",
    "                    ax3.set_yscale('log')\n",
    "                    ax3.set_xscale('log')\n",
    "                    ax3.set_ylim(np.nanmin(rgp),np.nanmax(rgp))\n",
    "                    ax3.set_xlabel(\"Rad (pc)\",fontsize=12)\n",
    "                    ax3.set_ylabel(\"Linewidth Ratio (km^2/s^2/pc)\",fontsize=12)\n",
    "                    ax3.legend(prop={'size': 12})\n",
    "\n",
    "                    gp3 = np.where(lumFORRAT>0)\n",
    "                    lumFORRAT = lumFORRAT[gp3]\n",
    "                    rgpFORRAT = rgp[gp3]\n",
    "                    mom0FORRAT = mom0FORRAT[gp3]\n",
    "\n",
    "\n",
    "\n",
    "                    ax5 = pylab.subplot(5, 5, 4)\n",
    "                    ax6 = pylab.subplot(5, 5, 5)\n",
    "                    ax7 = pylab.subplot(5, 5, 6)\n",
    "\n",
    "\n",
    "\n",
    "                    xpconhh = ax5.scatter(radgpFORRAT,cgp,label=\"All_structures\",s=30,alpha=.7)\n",
    "                    ax5.set_yscale('log')\n",
    "                    ax5.set_xscale('log')\n",
    "                    ax5.set_xlabel(\"Size (pc)\",fontsize=12)\n",
    "                    ax5.set_ylabel(\"Column Density (#/cm^2 > 7e22)\",fontsize=12)\n",
    "                    ax5.legend(prop={'size': 12},loc=\"upper right\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    xspF2 = ax6.scatter(cgp,rgp,label=\"All_structures\",s=30,alpha=.7)\n",
    "                    pF2 = ax6.plot(xsCD,ysCD)\n",
    "\n",
    "                    ax6.set_yscale('log')\n",
    "                    ax6.set_xscale('log')\n",
    "                    ax6.set_ylim(np.nanmin(rgp),np.nanmax(rgp))\n",
    "                    ax6.set_xlabel(\"Column Density (#/cm^2 > 7e22)\",fontsize=12)\n",
    "                    ax6.set_ylabel(\"Linewidth Ratio (km^2/s^2/pc)\",fontsize=12)\n",
    "                    ax6.legend(prop={'size': 12},loc=\"upper right\")\n",
    "                    ax6.annotate(s=LineN,fontsize=10,xy=(0.01,0.89),xycoords=\"axes fraction\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    xspLu2 = ax7.scatter(radgp,lgp,label=\"All_structure Whole Data Set\",s=30,alpha=.7)\n",
    "                    pFLLu2 = ax7.plot(xsRL,ysRL)\n",
    "\n",
    "                    st = \"WDS, c = \"+ str(np.format_float_scientific(RLpopt[0],3))+\"+-\"+str(np.format_float_scientific(np.sqrt(RLpcov[0][0]),3))+\" d = \"+str(np.format_float_scientific(RLpopt[1],3))+\"+-\"+str(np.format_float_scientific(np.sqrt(RLpcov[1][1]),3))\n",
    "                    ax7.annotate(s='L = $c*R^d$',fontsize=12,xy=(0.01,0.13),xycoords=\"axes fraction\")\n",
    "                    ax7.annotate(s=st,fontsize=12,xy=(0.01,0.04),xycoords=\"axes fraction\")\n",
    "\n",
    "                    ax7.set_yscale('log')\n",
    "                    ax7.set_xscale('log')\n",
    "                    ax7.set_ylim(np.nanmin(lgp),np.nanmax(lgp))\n",
    "                    ax7.set_xlabel(\"Radius (pc)\",fontsize=9)\n",
    "                    ax7.set_ylabel(\"Luminosity (erg)\",fontsize=9)\n",
    "                    ax7.legend(prop={'size': 12},loc=\"upper right\")\n",
    "                    ax7.annotate(s=LineN,fontsize=10,xy=(0.01,0.89),xycoords=\"axes fraction\")\n",
    "\n",
    "\n",
    "                    axLam = pylab.subplot(5, 5, 11)\n",
    "                    lum_rat = axLam.scatter(lumFORRAT/radgpFORRAT**2,rgpFORRAT,label=\"All_structure  \",s=30,alpha=.7)\n",
    "                    #Off by factors for area, simply using r^2\n",
    "\n",
    "                    axLam.set_yscale('log')\n",
    "                    axLam.set_xscale('log')\n",
    "                    axLam.set_xlabel(\"Lum/R^2 (erg/pc^2)\",fontsize=9)\n",
    "                    axLam.set_ylabel(\"Linewidth Ratio (km/s)^2/pc\",fontsize=9)\n",
    "                    axLam.legend(prop={'size': 12},loc=\"upper right\")\n",
    "                    axLam.annotate(s=LineN,fontsize=10,xy=(0.01,0.89),xycoords=\"axes fraction\")\n",
    "\n",
    "\n",
    "\n",
    "                    axDelta = pylab.subplot(5, 5, 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    gp4=np.where(MOM0FLUXcon>0)\n",
    "                    mom0FORFlux=MOM0FLUXcon[gp4]\n",
    "                    radgpFORFlux=Rcon[gp4]*10**6\n",
    "                    rgpFORFlux=Scon[gp4]**2/Rcon[gp4]/10**6\n",
    "\n",
    "                    mom0_rat = axDelta.scatter(mom0FORFlux/radgpFORFlux**2,rgpFORFlux,label=\"All_structure  \",s=30,alpha=.7)\n",
    "                    #Off by factors for area, simply using r^2\n",
    "\n",
    "                    axDelta.set_yscale('log')\n",
    "                    axDelta.set_xscale('log')\n",
    "                    axDelta.set_xlabel(\"Mom0 Flux/pc^2 (K km/s / R^2)\",fontsize=9)\n",
    "                    axDelta.set_ylabel(\"Linewidth Ratio (km/s)^2/pc\",fontsize=9)\n",
    "                    axDelta.legend(prop={'size': 12},loc=\"upper right\")\n",
    "                    axDelta.annotate(s=LineN,fontsize=10,xy=(0.01,0.89),xycoords=\"axes fraction\")\n",
    "\n",
    "\n",
    "                    pylab.show()\n",
    "\n",
    "\n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    v1 = d.viewer()\n",
    "                    v1.show()\n",
    "\n",
    "                    #Must use text because np load is broken\n",
    "                    if(Abs_Level==\"All\"):\n",
    "                        Suffix=''\n",
    "                    if(Abs_Level==\"None\"):\n",
    "                        Suffix='_NA'\n",
    "                    if(Abs_Level==\"No Clusters\"):\n",
    "                        Suffix='_No_Clusters'\n",
    "                    if(Abs_Level==\"None (m)\"):\n",
    "                        Suffix='None_m'\n",
    "                    if(Abs_Level==\"None All Channels\"):\n",
    "                        Suffix='None_All_Channels'\n",
    "                        \n",
    "                    \n",
    "                    \n",
    "\n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameCol+\"_Leaves\"+Suffix), CD[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameCol+\"_Branches\"+Suffix), CD[1],fmt='%s')\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameLum+\"_Leaves\"+Suffix), Lumin[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameLum+\"_Branches\"+Suffix), Lumin[1],fmt='%s')\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameS+\"_Leaves\"+Suffix), Sigmas[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameS+\"_Branches\"+Suffix), Sigmas[1],fmt='%s')\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameR+\"_Leaves\"+Suffix), Rads[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameR+\"_Branches\"+Suffix), Rads[1],fmt='%s')\n",
    "\n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameFlux+\"_Leaves\"+Suffix), MOM0FLUX[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameFlux+\"_Branches\"+Suffix), MOM0FLUX[1],fmt='%s')\n",
    "\n",
    "\n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,Cube_Name_Save+\"Distances_Leaves\"+Suffix), Distances[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,Cube_Name_Save+\"Distances_Branches\"+Suffix), Distances[1],fmt='%s')\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,Cube_Name_Save+\"V_err_Leaves\"+Suffix), V_err[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,Cube_Name_Save+\"V_err_Branches\"+Suffix), V_err[1],fmt='%s')\n",
    "\n",
    "                    SIDS=np.concatenate((SIDS[0],SIDS[1]))\n",
    "\n",
    "                    print(SIDS[len(SIDS)-3:len(SIDS)-1])\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    print(kl,km,k3,k4)\n",
    "                    print(\"Failed\")\n",
    "                    print(\"-\"*60)\n",
    "                    traceback.print_exc(file=sys.stdout)\n",
    "                    \n",
    "                    if(Abs_Level==\"All\"):\n",
    "                        Suffix=''\n",
    "                    if(Abs_Level==\"None\"):\n",
    "                        Suffix='_NA'\n",
    "                    if(Abs_Level==\"No Clusters\"):\n",
    "                        Suffix='_No_Clusters'\n",
    "                    if(Abs_Level==\"None (m)\"):\n",
    "                        Suffix='None_m'\n",
    "                    if(Abs_Level==\"None All Channels\"):\n",
    "                        Suffix='None_All_Channels'\n",
    "                    nans = [[np.nan,np.nan],[np.nan,np.nan]]\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameCol+\"_Leaves\"+Suffix), nans[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameCol+\"_Branches\"+Suffix), nans[1],fmt='%s')\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameLum+\"_Leaves\"+Suffix), nans[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameLum+\"_Branches\"+Suffix), nans[1],fmt='%s')\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameS+\"_Leaves\"+Suffix), nans[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameS+\"_Branches\"+Suffix), nans[1],fmt='%s')\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameR+\"_Leaves\"+Suffix), nans[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameR+\"_Branches\"+Suffix), nans[1],fmt='%s')\n",
    "\n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameFlux+\"_Leaves\"+Suffix), nans[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameFlux+\"_Branches\"+Suffix), nans[1],fmt='%s')\n",
    "\n",
    "\n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,Cube_Name_Save+\"Distances_Leaves\"+Suffix), nans[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,Cube_Name_Save+\"Distances_Branches\"+Suffix), nans[1],fmt='%s')\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,Cube_Name_Save+\"V_err_Leaves\"+Suffix), nans[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,Cube_Name_Save+\"V_err_Branches\"+Suffix), nans[1],fmt='%s')\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac127f2-478c-41c3-b6a8-f34e91d8e77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#No clusters\n",
    "\n",
    "Abs_Level = Abs_Levels[2]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pathCont = 'Continuum_Reproject.fits'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for kl in range(iterations):\n",
    "      \n",
    "    Prime_Beam = Min_res*((kl*iter_factor+1))#\n",
    "    print(Prime_Beam)\n",
    "    \n",
    "    \n",
    "    for km in range(iterations):\n",
    "        vel_prime = min_vel*((km*iter_factor+1))\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        try:\n",
    "            Names=list(np.load(\"Names_New_All_Kinds.npy\",allow_pickle=True))\n",
    "        except Exception as e:\n",
    "\n",
    "            print(e)\n",
    "            print(\"initialized names\")\n",
    "            Names = list(np.empty((20,iterations,iterations,iterations,iterations),dtype=object))\n",
    "                        \n",
    "\n",
    "        #Continuum image\n",
    "        scCont = spectral_cube.Projection.from_hdu(fits.open(pathCont)[0])\n",
    "        #Put this up here for the column density map\n",
    "        metadata = {}\n",
    "        metadata[\"distance\"] = 3.5*u.Mpc\n",
    "        arc_per_pix_yc =  abs(scCont.hdu.header[\"CDELT1\"]*3600.0 * u.arcsec)/u.pix\n",
    "        arc_per_pix_xc =  abs(scCont.hdu.header[\"CDELT2\"]*3600.0 * u.arcsec)/u.pix\n",
    "        beam_majorc =  scCont.hdu.header[\"BMAJ\"]*3600.0 * u.arcsec\n",
    "        beam_minorc =  scCont.hdu.header[\"BMIN\"]*3600.0 * u.arcsec\n",
    "        beam_area_ratioc = beam_minorc*beam_majorc/arc_per_pix_yc/arc_per_pix_xc*1.13309#beam_area_ratioc = beam_minorc*beam_majorc/arc_per_pix_yc/arc_per_pix_xc#This is for FWHM, use *(2*np.sqrt(2*np.log(2)))**2#For gaussian beam\n",
    "        metadata['beam_area_ratioc']=beam_area_ratioc\n",
    "        pc_per_pixelc = abs(scCont.hdu.header[\"CDELT1\"])/180*np.pi*metadata['distance']/u.Mpc\n",
    "        print(pc_per_pixelc,\"MPC per pix\")\n",
    "\n",
    "        #Make subcube\n",
    "\n",
    "\n",
    "\n",
    "        Cube_Name_Load = \"Cropped_\"+str(Prime_Beam.value)+\"pc_beam_\"+Line_Name+str(FOV[0])+\"x\"+str(FOV[1])+'pc_'+str(vel_prime)+'_vel_res.fits'\n",
    "        path = Cube_Name_Load\n",
    "        \n",
    "        Qp = SpectralCube.read(path).with_spectral_unit(u.km/u.s,velocity_convention=\"radio\") \n",
    "        Qp.allow_huge_operations=True\n",
    "\n",
    "        Q = Qp.to(u.K)#Jy to Kelvin\n",
    "\n",
    "        sc = Q.unmasked_copy()\n",
    "\n",
    "\n",
    "\n",
    "        scW = sc.wcs[:][:][0]\n",
    "        dat = sc.hdu.data[int(len(sc)*((1-Ram_Limiter)/2)):int(len(sc)*(Ram_Limiter + (1-Ram_Limiter)/2)),:,:]\n",
    "        scn = sc[int(len(sc)*((1-Ram_Limiter)/2)):int(len(sc)*(Ram_Limiter + (1-Ram_Limiter)/2)),:,:]\n",
    "        scF = scn\n",
    "        datn = dat\n",
    "\n",
    "\n",
    "        #m=.115\n",
    "\n",
    "        #print(m,\"Presumed Noise (K)\")\n",
    "\n",
    "        #Continuum image\n",
    "        scCont = spectral_cube.Projection.from_hdu(fits.open(pathCont)[0])\n",
    "        #Do the same thing to the continuum image\n",
    "        scCont.allow_huge_operations=True\n",
    "        scContW = scCont.reproject(scF.moment0().header)\n",
    "        #m=.115\n",
    "\n",
    "\n",
    "        scW = sc.wcs[:][:][0]\n",
    "\n",
    "        cen_p1 = SkyCoord('00h47m33.9s', '-25d17m26.8s', frame='icrs')\n",
    "        cen_p2 = SkyCoord('00h47m32.6s', '-25d17m10.2s', frame='icrs')\n",
    "\n",
    "\n",
    "        #Do the same thing to the continuum image\n",
    "        scCont.allow_huge_operations=True\n",
    "        scContW = scCont.reproject(scF.moment0().header)\n",
    "        Continuum_Data  =scContW.hdu.data\n",
    "        scWCS = scF.wcs[:][:][0]\n",
    "\n",
    "        moment_0_sub  = scF.to(u.K).moment(order=0,how='slice')            # Calculate the Moment 0 map \n",
    "\n",
    "\n",
    "\n",
    "        ######Moment 0 for both\n",
    "        ######and cont\n",
    "        Make_Plot((LineN+\" Moment 0\"),\"Moment 0 (K km/s)\",moment_0_sub.hdu.data,0,np.nanmax(moment_0_sub.hdu.data),moment_0_sub.wcs,1,1,1,True)\n",
    "\n",
    "\n",
    "        cSD = (Flux_to_Mass(scContW.hdu.data*u.Jy/u.beam/beam_area_ratioc*u.pix**2*u.beam)/(pc_per_pixelc*10**6*3.086*10**18*u.cm)**2)*(1.989*10**30*u.kg/u.M_sun)*Num_per_kg/u.kg #Flux goes to luminosity for a gaussian beam and goes to column density for square pixels, mass goes to kg to number\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        rm=moment_0_sub.hdu.data/cSD\n",
    "        rmU = rm*u.K*u.km/u.s#Just put back in the units\n",
    "        rmU = np.array(rmU /(u.K*u.km/u.s)/u.cm**2*10**22,dtype='float64')#Now remove them all\n",
    "\n",
    "        ######ratio\n",
    "\n",
    "        bp = np.where(cSD<=7*10**22/u.cm**2)\n",
    "        bp2 = np.where( moment_0_sub.hdu.data < .22)\n",
    "        Continuum_Data[bp] = np.nan\n",
    "        cSD[bp]=np.nan\n",
    "        rmU[bp]=np.nan\n",
    "        rmU[bp2]=np.nan\n",
    "\n",
    "        Non_nan=((datn[0,:,:]>0)  | (datn[0,:,:]<0 ))\n",
    "\n",
    "        m = (np.nanstd(datn[0,:,:],where= Non_nan)) #Noise K\n",
    "        if(Abs_Level==\"All\"):\n",
    "            pass\n",
    "        if(Abs_Level==\"None\"):\n",
    "            datn[np.where(datn<0)]=np.nan\n",
    "        if(Abs_Level==\"None (m)\"):\n",
    "            datn[np.where(datn<-m)]=np.nan\n",
    "        if(Abs_Level==\"None All Channels\"):\n",
    "            for lmi in range(len(datn)):\n",
    "                bpP = np.where(datn[lmi]<-m)\n",
    "                for lmj in range(len(datn)):\n",
    "                    datn[lmj][bpP]=np.nan\n",
    "        if(Abs_Level==\"No Clusters\"):\n",
    "            IDs,RAs,Decs,HWHM  =    np.genfromtxt(\"NGC_Clusters_\"+\"IDs\"+\"\",dtype=type(\"12h23.14s\")),np.genfromtxt(\"NGC_Clusters_\"+\"RAs\"+\"\",dtype=type(\"12h23.14s\")),np.genfromtxt(\"NGC_Clusters_\"+\"Decs\"+\"\",dtype=type(\"12h23.14s\")),np.genfromtxt(\"NGC_Clusters_\"+\"HWHM\"+\"\")\n",
    "\n",
    "            datn=  Mask_Clusters_NGC(HWHM,scWCS,scF.hdu.header,datn,RAs,Decs,One_Pc=False,One_Pc_Size=1,HWHM_Fac=3)\n",
    "\n",
    "        print(m,\"Unmatched Noise (K)\", \"Abs = \",Abs_Level)\n",
    "\n",
    "\n",
    "        Make_Plot(\"Column Density\",\"(#/cm^2)\",cSD,float(np.nanmin(cSD*u.cm**2)),float(np.nanmax(cSD*u.cm**2)),scCont.wcs,1,1,1,True)\n",
    "        Make_Plot((LineN+\" Moment 0/Column Density\"),\"Moment 0 over Column Density of the Continuum (K km/s/(#/cm^2))\",rmU,np.nanmean(rmU)*.5,abs(np.nanmean(rmU))*8,scCont.wcs,1,1,1,True)\n",
    "\n",
    "        print(np.nanmin(rmU))\n",
    "\n",
    "\n",
    "\n",
    "        header = scF.hdu.header\n",
    "        print()\n",
    "        #make metadata for the dendrogram\n",
    "\n",
    "        try:\n",
    "            freq = header[\"RESTFREQ\"]*u.Hz#\n",
    "            metadata['wavelength']=299792458*u.m/header[\"RESTFREQ\"]#\n",
    "            print(1,freq,metadata['wavelength'])\n",
    "        except:\n",
    "            freq = header[\"RESTFRQ\"]*u.Hz#\n",
    "            metadata['wavelength']=299792458*u.m/header[\"RESTFRQ\"]#\n",
    "        metadata['data_unit'] =scF[0][0][0].unit# header['BUNIT']\n",
    "        metadata['arc_per_pix_y'] =  abs(header[\"CDELT1\"]*3600.0 * u.arcsec)/u.pix\n",
    "        metadata['arc_per_pix_x'] =  abs(header[\"CDELT2\"]*3600.0 * u.arcsec)/u.pix\n",
    "\n",
    "\n",
    "        metadata['beam_major'] =  header[\"BMAJ\"]*3600.0 * u.arcsec\n",
    "        metadata['beam_minor'] =  header[\"BMIN\"]*3600.0 * u.arcsec\n",
    "        beam_area_ratio = metadata['beam_minor']*metadata['beam_major']/metadata['arc_per_pix_y']/metadata['arc_per_pix_x']*1.13309#beam_area_ratio = metadata['beam_minor']*metadata['beam_major']/metadata['arc_per_pix_y']/metadata['arc_per_pix_x']#This is for FWHM, use *(2*np.sqrt(2*np.log(2)))**2#For gaussian beam\n",
    "        metadata['beam_area_ratio']=beam_area_ratio\n",
    "        metadata['spatial_scale'] = np.sqrt(abs(header[\"CDELT1\"])*u.degree**2*abs(header[\"CDELT2\"]))\n",
    "        area_res = abs(header[\"CDELT1\"])*abs(header[\"CDELT2\"])*(np.pi/180*3.5)**2#mpc^2/pix^2\n",
    "        print(area_res,type(area_res))\n",
    "\n",
    "        print(metadata['beam_minor'],metadata['beam_major'])\n",
    "        print(beam_area_ratio)\n",
    "        #metadata[\"wcs\"] = wcs\n",
    "        metadata[\"velocity_scale\"] = abs(header[\"CDELT3\"])*u.km/u.s#u.km/u.s\n",
    "\n",
    "        metadata[\"vaxis\"]=0\n",
    "        metadata[\"wcsu\"]=scF.wcs\n",
    "\n",
    "\n",
    "        for k3 in range(iterations):\n",
    "\n",
    "            beam_req = Min_beam_req*(k3+1)\n",
    "            \n",
    "            for k4 in range(iterations):\n",
    "                print(kl,km,k3,k4)\n",
    "                try:\n",
    "\n",
    "                    pix_thresh_factor = k4+1\n",
    "\n",
    "                    Cube_Name_Save = Name+\"_Cropped_\"+str(Prime_Beam.value)+\"pc_beam_\"+Line_Name+str(FOV[0])+\"x\"+str(FOV[1])+'pc_'+str(vel_prime)+'_vel_res_'+str(beam_req)+\"_beam_size_req_\"+str(pix_thresh_factor)+'_times_beam_pixels.fits'\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    Names[Num][kl][km][k3][k4] = Cube_Name_Save\n",
    "                    \n",
    "                    NameS = (Cube_Name_Save+\"Sigmas\")\n",
    "                    NameR = (Cube_Name_Save+\"Radii\")\n",
    "                    NameCol = (Cube_Name_Save+\"_Column\")\n",
    "                    NameLum = (Cube_Name_Save+\"_Luminosities\")\n",
    "\n",
    "                    NameFlux = (Cube_Name_Save+\"Flux_Dense\")\n",
    "                    NameRFF = (Cube_Name_Save+\"Rad_For_Flux\")\n",
    "                    \n",
    "                    print(Cube_Name_Save)\n",
    "                    \n",
    "                    np.save(\"Names_New_All_Kinds\",Names)\n",
    "\n",
    "                    \n",
    "                   \n",
    "\n",
    "\n",
    "                    d = astrodendro.Dendrogram.compute(datn,min_delta=m,min_value=m*5,min_npix=beam_area_ratio.value*pix_thresh_factor) #The main culprit\n",
    "                    #d = astrodendro.Dendrogram.compute(datn,min_delta=m,min_value=m*5,min_npix=beam_area_ratio.value) #The main culprit\n",
    "\n",
    "                    vel,RA,Dec = scF.world[:,0,0]\n",
    "                    Rads,Sigmas,CD,Lumin,SIDS,MOM0FLUX,Distances,V_err = Dendro_Arrays(d,datn,vel,Continuum_Data,metadata,beam_size=Prime_Beam.value,beam_req=beam_req)\n",
    "                    \n",
    "\n",
    "                    ##Analyze dendograms\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    fig = plt.figure(1,figsize=(40,40))\n",
    "\n",
    "\n",
    "                    axAlpha = pylab.subplot(5, 5, 7)\n",
    "                    axBeta = pylab.subplot(5, 5, 8)\n",
    "                    axGamma = pylab.subplot(5, 5, 9)\n",
    "                    axDelta = pylab.subplot(5, 5, 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    p1=d.plotter()\n",
    "                    p1.plot_tree(axAlpha)\n",
    "                    axAlpha.set_xlabel(\"Structure\")\n",
    "                    axAlpha.set_ylabel(\"Flux (K)\")\n",
    "                    axAlpha.set_title(\"Whole data set\")\n",
    "\n",
    "\n",
    "\n",
    "                    #Plot contours for the top ten clusters\n",
    "\n",
    "\n",
    "                    #scCropped =scF.moment0().hdu.data\n",
    "                    scCropped =scF.moment0().hdu.data\n",
    "                    scCropped[np.where(scF.moment0().hdu.data<.22)]=np.nan\n",
    "                    print(np.nanmean(np.nanstd(scF.moment0().hdu.data))*1)\n",
    "                    scCropped[bp]=np.nan\n",
    "                    axDelta = pylab.subplot(5,5,8,projection=scF.moment0().wcs)\n",
    "                    #axBeta.imshow(scCropped.moment0().hdu.data, origin='lower', interpolation='nearest', cmap=plt.cm.Blues,norm=colors.LogNorm(vmin=5))\n",
    "                    imBeta = axDelta.imshow(scCropped, origin='lower', interpolation='nearest', cmap=plt.cm.Blues,vmin=0,vmax = np.nanmax(scCropped)*.7 )\n",
    "\n",
    "\n",
    "\n",
    "                    ColumnCon= np.concatenate((CD[0],CD[1]))\n",
    "                    SIDScon = np.concatenate((SIDS[0],SIDS[1]))\n",
    "                    nth =0# sorted(CD[0])[len(CD[0])-20]\n",
    "\n",
    "                    G1 = True\n",
    "\n",
    "                    RA = axDelta.coords[0]                                                                  # \n",
    "                    Dec = axDelta.coords[1]\n",
    "\n",
    "                    RA.set_ticks(size=-3)                                                                                      \n",
    "                    Dec.set_ticks(size=-3) \n",
    "                    RA.set_ticklabel(exclude_overlapping=True) \n",
    "                    Dec.set_ticklabel(exclude_overlapping=True)                                                                                     \n",
    "                    pylab.xlabel('Right Ascension',fontsize=20,labelpad=1)                               \n",
    "                    pylab.ylabel('Declination',fontsize=20,labelpad=1)\n",
    "                    axDelta.tick_params(axis = 'both', which = 'major', labelsize = 15)    \n",
    "                    cb=pylab.colorbar(imBeta,fraction=0.016,pad=0.04)                                     \n",
    "                    cb.set_label(label=\"Moment 0 K km/s\",fontsize=10,rotation=270,labelpad=20) \n",
    "                    cb.ax.tick_params(which = 'major', labelsize = 10)   \n",
    "                    pylab.annotate(s=LineN,fontsize=10,xy=(.01,1.05),xycoords=\"axes fraction\",c=\"black\")  \n",
    "                    pylab.annotate(s=\"Highest Density\",fontsize=10,xy=(.31,1.05),xycoords=\"axes fraction\",c=\"red\")  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    pc_per_pixel = abs(header[\"CDELT1\"])/180*np.pi*metadata['distance']/u.Mpc\n",
    "\n",
    "                    sig_per_pixel=np.nan#metadata['spectral_resolution']/u.pix\n",
    "\n",
    "\n",
    "                    #Finds Size, Linewidth, Luminosity, and Column Density of a structure for each structure and returns them in [[][]] arrays [Leaves][Branches]\n",
    "\n",
    "\n",
    "                    from scipy.optimize import curve_fit\n",
    "                    from scipy.optimize import leastsq\n",
    "\n",
    "                    def func(R,a,b):\n",
    "                        return a*R**(b)\n",
    "                    try:\n",
    "                        popt, pcov = curve_fit(func, Rads[0]*10**6,Sigmas[0])\n",
    "                    except:\n",
    "                        popt, pcov = [np.nan,np.nan],[[np.nan,np.nan],[np.nan,np.nan]]\n",
    "                    try:\n",
    "                        poptB, pcovB = curve_fit(func,  Rads[1]*10**6,Sigmas[1])\n",
    "                    except:\n",
    "                        poptB, pcovB = [np.nan,np.nan],[[np.nan,np.nan],[np.nan,np.nan]]\n",
    "\n",
    "                    \n",
    "\n",
    "                    Rcon = np.concatenate((Rads[0],Rads[1]))\n",
    "\n",
    "                        \n",
    "                    Scon = np.concatenate((Sigmas[0],Sigmas[1]))\n",
    "                    Scon2 = np.concatenate((Sigmas[2],Sigmas[3]))\n",
    "                    print(np.shape(Rcon))\n",
    "                    \n",
    "                    poptCon, pcovCon = curve_fit(func, Rcon*10**6, Scon)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    xs=np.linspace(np.nanmin(Rcon*10**6),np.nanmax(Rcon*10**6),50)\n",
    "\n",
    "                    ysL,ysB,ysCon=func(xs,popt[0],popt[1]),func(xs,poptB[0],poptB[1]),func(xs,poptCon[0],poptCon[1])\n",
    "\n",
    "\n",
    "                    LuminCon = np.concatenate((Lumin[0],Lumin[1]))\n",
    "                    ColumnCon= np.concatenate((CD[0],CD[1]))\n",
    "\n",
    "                    MOM0FLUXcon = np.concatenate((MOM0FLUX[0],MOM0FLUX[1]))\n",
    "                    DistancesCon= np.concatenate((Distances[0],Distances[1]))\n",
    "                    print(Distances)\n",
    "\n",
    "                    #Radius Luminosity fit\n",
    "                    #Good pixels are places where the luminosity and therefore column density are above zero\n",
    "                    gp = np.where(LuminCon>0)\n",
    "                    print(np.shape(Rcon),np.shape(LuminCon))\n",
    "                    lgp = LuminCon[gp]\n",
    "                    radgp = Rcon[gp]*10**6\n",
    "\n",
    "                    gp2 = np.where(ColumnCon>0)\n",
    "                    cgp = ColumnCon[gp2]\n",
    "                    rgp=Scon[gp2]**2/Rcon[gp2]/10**6\n",
    "                    dgp=DistancesCon[gp2]\n",
    "                    radgpFORRAT = Rcon[gp2]*10**6\n",
    "                    siggpFORRAT = Scon[gp2]\n",
    "                    lumFORRAT = LuminCon[gp2]\n",
    "                    mom0FORRAT = MOM0FLUXcon[gp2]\n",
    "\n",
    "                    #print(np.shape(Rcon[gp]*10**6),np.shape(LuminCon[gp]))\n",
    "                    RLpopt,RLpcov = curve_fit(func, np.array(radgp,dtype='float64'),np.array(lgp,dtype='float64'),maxfev=999999,p0 = np.array([10**27,1],dtype='float64'),ftol = 10**-10)\n",
    "\n",
    "                    xsRL=np.linspace(np.nanmin(radgp),np.nanmax(radgp),50)\n",
    "                    ysRL = func(xsRL,RLpopt[0],RLpopt[1])\n",
    "                    #Column density to Size-linewidth\n",
    "                    CDpopt,CDpcov = curve_fit(func, np.array(cgp,dtype='float64') ,np.array(rgp,dtype='float64'),maxfev=9999099,p0 = np.array([10,.01],dtype='float64'),ftol = 10**-10)\n",
    "\n",
    "                    Dist_popt,Dist_pcov = curve_fit(func, np.array(DistancesCon,dtype='float64') ,np.array(Scon,dtype='float64'),maxfev=9999099,ftol = 10**-10)\n",
    "                    Dist_popt2,Dist_pcov2 = curve_fit(func, np.array(dgp,dtype='float64') ,np.array(rgp,dtype='float64'),maxfev=9999099,ftol = 10**-10)\n",
    "\n",
    "                    xsDist=np.linspace(np.nanmin(DistancesCon),np.nanmax(DistancesCon),50)\n",
    "                    xsDist2=np.linspace(np.nanmin(dgp),np.nanmax(dgp),50)\n",
    "                    ysDist=func(xsDist,Dist_popt[0],Dist_popt[1])\n",
    "                    ysDist2=func(xsDist2,Dist_popt2[0],Dist_popt2[1])\n",
    "\n",
    "\n",
    "                    axdis = pylab.subplot(5, 5, 12)\n",
    "                    axdis2 = pylab.subplot(5, 5, 13)\n",
    "                    axdis.scatter(DistancesCon,Scon)\n",
    "                    axdis2.scatter(dgp,rgp)\n",
    "                    axdis.plot(xsDist,ysDist)\n",
    "                    axdis2.plot(xsDist2,ysDist2)\n",
    "                    axdis2.set_yscale('log')\n",
    "                    axdis2.set_xscale('log')\n",
    "                    axdis.set_yscale('log')\n",
    "                    axdis.set_xscale('log')\n",
    "\n",
    "                    xsCD=np.linspace(np.nanmin(cgp),np.nanmax(cgp),50)\n",
    "                    ysCD = func(xsCD,CDpopt[0],CDpopt[1])\n",
    "\n",
    "\n",
    "                    print(poptCon,pcovCon,\"Size Linewidth All_structures:\")\n",
    "                    print(\"a = \",poptCon[0],\"+-\",np.sqrt(pcovCon[0][0]))\n",
    "                    print(\"b = \",poptCon[1],\"+-\",np.sqrt(pcovCon[1][1]))\n",
    "\n",
    "\n",
    "                    print(RLpopt,RLpcov,\"Radius to Luminosity:\")\n",
    "                    print(\"c = \",RLpopt[0],\"+-\",np.sqrt(RLpcov[0][0]))\n",
    "                    print(\"d = \",RLpopt[1],\"+-\",np.sqrt(RLpcov[1][1]))\n",
    "\n",
    "\n",
    "\n",
    "                    print(CDpopt,CDpcov,\"Column Density to linewidth^2/size:\")\n",
    "                    print(\"e = \",CDpopt[0],\"+-\",np.sqrt(CDpcov[0][0]))\n",
    "                    print(\"f = \",CDpopt[1],\"+-\",np.sqrt(CDpcov[1][1]))\n",
    "\n",
    "\n",
    "\n",
    "                    ax2 = pylab.subplot(5, 5, 1)\n",
    "                    ax3 = pylab.subplot(5, 5, 2)\n",
    "                    ax4 = pylab.subplot(5, 5, 3)\n",
    "\n",
    "                    xpcon = ax2.scatter(Rcon*10**6,Scon,label=\"All_structures\",s=30,alpha=.7)\n",
    "\n",
    "\n",
    "                    p = ax2.plot(xs,ysCon)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    st=\"WDS: a=\"+ str(np.format_float_scientific(poptCon[0],1))+\"+-\"+str(np.format_float_scientific(np.sqrt(pcovCon[0][0]),1))+\" b=\"+str(np.format_float_scientific(poptCon[1],1))+\"+-\"+str(np.format_float_scientific(np.sqrt(pcovCon[1][1]),2))\n",
    "                    ax2.annotate(s=st,fontsize=10,xy=(0.01,0.01),xycoords=\"axes fraction\")\n",
    "\n",
    "                    ax2.annotate(s=r'$\\sigma$ = $a*R^b$',fontsize=10,xy=(0.01,0.10),xycoords=\"axes fraction\")\n",
    "                    ax2.set_yscale('log')\n",
    "                    ax2.set_xscale('log')\n",
    "                    ax2.set_ylim(np.nanmin(Scon),np.nanmax(Scon))\n",
    "                    ax2.set_xlabel(\"Size (pc)\",fontsize=12)\n",
    "                    ax2.set_ylabel(\"Sigma (km/s)\",fontsize=12)\n",
    "                    ax2.legend(prop={'size': 12},loc=\"upper right\")\n",
    "                    ax2.annotate(s=LineN,fontsize=10,xy=(0.01,0.89),xycoords=\"axes fraction\")\n",
    "\n",
    "                    #gp = np.where(FRs>0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    xspL = ax4.scatter(radgpFORRAT,siggpFORRAT,label=\"All_structures\",s=30)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    ax4.set_yscale('log')\n",
    "                    ax4.set_xscale('log')\n",
    "\n",
    "                    ax4.set_xlabel(\"Radius (pc)\",fontsize=12)\n",
    "                    ax4.set_ylabel(\"sig (km/s)\",fontsize=12)\n",
    "                    ax4.legend(prop={'size': 12},loc=\"upper right\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    xspF = ax3.scatter(radgpFORRAT,rgp,label=\"All_structures\",s=30)\n",
    "\n",
    "                    ax3.annotate(s=st,fontsize=12,xy=(0.01,0.04),xycoords=\"axes fraction\")\n",
    "                    ax3.set_yscale('log')\n",
    "                    ax3.set_xscale('log')\n",
    "                    ax3.set_ylim(np.nanmin(rgp),np.nanmax(rgp))\n",
    "                    ax3.set_xlabel(\"Rad (pc)\",fontsize=12)\n",
    "                    ax3.set_ylabel(\"Linewidth Ratio (km^2/s^2/pc)\",fontsize=12)\n",
    "                    ax3.legend(prop={'size': 12})\n",
    "\n",
    "                    gp3 = np.where(lumFORRAT>0)\n",
    "                    lumFORRAT = lumFORRAT[gp3]\n",
    "                    rgpFORRAT = rgp[gp3]\n",
    "                    mom0FORRAT = mom0FORRAT[gp3]\n",
    "\n",
    "\n",
    "\n",
    "                    ax5 = pylab.subplot(5, 5, 4)\n",
    "                    ax6 = pylab.subplot(5, 5, 5)\n",
    "                    ax7 = pylab.subplot(5, 5, 6)\n",
    "\n",
    "\n",
    "\n",
    "                    xpconhh = ax5.scatter(radgpFORRAT,cgp,label=\"All_structures\",s=30,alpha=.7)\n",
    "                    ax5.set_yscale('log')\n",
    "                    ax5.set_xscale('log')\n",
    "                    ax5.set_xlabel(\"Size (pc)\",fontsize=12)\n",
    "                    ax5.set_ylabel(\"Column Density (#/cm^2 > 7e22)\",fontsize=12)\n",
    "                    ax5.legend(prop={'size': 12},loc=\"upper right\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    xspF2 = ax6.scatter(cgp,rgp,label=\"All_structures\",s=30,alpha=.7)\n",
    "                    pF2 = ax6.plot(xsCD,ysCD)\n",
    "\n",
    "                    ax6.set_yscale('log')\n",
    "                    ax6.set_xscale('log')\n",
    "                    ax6.set_ylim(np.nanmin(rgp),np.nanmax(rgp))\n",
    "                    ax6.set_xlabel(\"Column Density (#/cm^2 > 7e22)\",fontsize=12)\n",
    "                    ax6.set_ylabel(\"Linewidth Ratio (km^2/s^2/pc)\",fontsize=12)\n",
    "                    ax6.legend(prop={'size': 12},loc=\"upper right\")\n",
    "                    ax6.annotate(s=LineN,fontsize=10,xy=(0.01,0.89),xycoords=\"axes fraction\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    xspLu2 = ax7.scatter(radgp,lgp,label=\"All_structure Whole Data Set\",s=30,alpha=.7)\n",
    "                    pFLLu2 = ax7.plot(xsRL,ysRL)\n",
    "\n",
    "                    st = \"WDS, c = \"+ str(np.format_float_scientific(RLpopt[0],3))+\"+-\"+str(np.format_float_scientific(np.sqrt(RLpcov[0][0]),3))+\" d = \"+str(np.format_float_scientific(RLpopt[1],3))+\"+-\"+str(np.format_float_scientific(np.sqrt(RLpcov[1][1]),3))\n",
    "                    ax7.annotate(s='L = $c*R^d$',fontsize=12,xy=(0.01,0.13),xycoords=\"axes fraction\")\n",
    "                    ax7.annotate(s=st,fontsize=12,xy=(0.01,0.04),xycoords=\"axes fraction\")\n",
    "\n",
    "                    ax7.set_yscale('log')\n",
    "                    ax7.set_xscale('log')\n",
    "                    ax7.set_ylim(np.nanmin(lgp),np.nanmax(lgp))\n",
    "                    ax7.set_xlabel(\"Radius (pc)\",fontsize=9)\n",
    "                    ax7.set_ylabel(\"Luminosity (erg)\",fontsize=9)\n",
    "                    ax7.legend(prop={'size': 12},loc=\"upper right\")\n",
    "                    ax7.annotate(s=LineN,fontsize=10,xy=(0.01,0.89),xycoords=\"axes fraction\")\n",
    "\n",
    "\n",
    "                    axLam = pylab.subplot(5, 5, 11)\n",
    "                    lum_rat = axLam.scatter(lumFORRAT/radgpFORRAT**2,rgpFORRAT,label=\"All_structure  \",s=30,alpha=.7)\n",
    "                    #Off by factors for area, simply using r^2\n",
    "\n",
    "                    axLam.set_yscale('log')\n",
    "                    axLam.set_xscale('log')\n",
    "                    axLam.set_xlabel(\"Lum/R^2 (erg/pc^2)\",fontsize=9)\n",
    "                    axLam.set_ylabel(\"Linewidth Ratio (km/s)^2/pc\",fontsize=9)\n",
    "                    axLam.legend(prop={'size': 12},loc=\"upper right\")\n",
    "                    axLam.annotate(s=LineN,fontsize=10,xy=(0.01,0.89),xycoords=\"axes fraction\")\n",
    "\n",
    "\n",
    "\n",
    "                    axDelta = pylab.subplot(5, 5, 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    gp4=np.where(MOM0FLUXcon>0)\n",
    "                    mom0FORFlux=MOM0FLUXcon[gp4]\n",
    "                    radgpFORFlux=Rcon[gp4]*10**6\n",
    "                    rgpFORFlux=Scon[gp4]**2/Rcon[gp4]/10**6\n",
    "\n",
    "                    mom0_rat = axDelta.scatter(mom0FORFlux/radgpFORFlux**2,rgpFORFlux,label=\"All_structure  \",s=30,alpha=.7)\n",
    "                    #Off by factors for area, simply using r^2\n",
    "\n",
    "                    axDelta.set_yscale('log')\n",
    "                    axDelta.set_xscale('log')\n",
    "                    axDelta.set_xlabel(\"Mom0 Flux/pc^2 (K km/s / R^2)\",fontsize=9)\n",
    "                    axDelta.set_ylabel(\"Linewidth Ratio (km/s)^2/pc\",fontsize=9)\n",
    "                    axDelta.legend(prop={'size': 12},loc=\"upper right\")\n",
    "                    axDelta.annotate(s=LineN,fontsize=10,xy=(0.01,0.89),xycoords=\"axes fraction\")\n",
    "\n",
    "\n",
    "                    pylab.show()\n",
    "\n",
    "\n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    v1 = d.viewer()\n",
    "                    v1.show()\n",
    "\n",
    "                    #Must use text because np load is broken\n",
    "                    if(Abs_Level==\"All\"):\n",
    "                        Suffix=''\n",
    "                    if(Abs_Level==\"None\"):\n",
    "                        Suffix='_NA'\n",
    "                    if(Abs_Level==\"No Clusters\"):\n",
    "                        Suffix='_No_Clusters'\n",
    "                    if(Abs_Level==\"None (m)\"):\n",
    "                        Suffix='None_m'\n",
    "                    if(Abs_Level==\"None All Channels\"):\n",
    "                        Suffix='None_All_Channels'\n",
    "                        \n",
    "                    \n",
    "                    \n",
    "\n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameCol+\"_Leaves\"+Suffix), CD[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameCol+\"_Branches\"+Suffix), CD[1],fmt='%s')\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameLum+\"_Leaves\"+Suffix), Lumin[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameLum+\"_Branches\"+Suffix), Lumin[1],fmt='%s')\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameS+\"_Leaves\"+Suffix), Sigmas[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameS+\"_Branches\"+Suffix), Sigmas[1],fmt='%s')\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameR+\"_Leaves\"+Suffix), Rads[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameR+\"_Branches\"+Suffix), Rads[1],fmt='%s')\n",
    "\n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameFlux+\"_Leaves\"+Suffix), MOM0FLUX[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameFlux+\"_Branches\"+Suffix), MOM0FLUX[1],fmt='%s')\n",
    "\n",
    "\n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,Cube_Name_Save+\"Distances_Leaves\"+Suffix), Distances[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,Cube_Name_Save+\"Distances_Branches\"+Suffix), Distances[1],fmt='%s')\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,Cube_Name_Save+\"V_err_Leaves\"+Suffix), V_err[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,Cube_Name_Save+\"V_err_Branches\"+Suffix), V_err[1],fmt='%s')\n",
    "\n",
    "                    SIDS=np.concatenate((SIDS[0],SIDS[1]))\n",
    "\n",
    "                    print(SIDS[len(SIDS)-3:len(SIDS)-1])\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    print(kl,km,k3,k4)\n",
    "                    print(\"Failed\")\n",
    "                    print(\"-\"*60)\n",
    "                    traceback.print_exc(file=sys.stdout)\n",
    "                    \n",
    "                    if(Abs_Level==\"All\"):\n",
    "                        Suffix=''\n",
    "                    if(Abs_Level==\"None\"):\n",
    "                        Suffix='_NA'\n",
    "                    if(Abs_Level==\"No Clusters\"):\n",
    "                        Suffix='_No_Clusters'\n",
    "                    if(Abs_Level==\"None (m)\"):\n",
    "                        Suffix='None_m'\n",
    "                    if(Abs_Level==\"None All Channels\"):\n",
    "                        Suffix='None_All_Channels'\n",
    "                    nans = [[np.nan,np.nan],[np.nan,np.nan]]\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameCol+\"_Leaves\"+Suffix), nans[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameCol+\"_Branches\"+Suffix), nans[1],fmt='%s')\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameLum+\"_Leaves\"+Suffix), nans[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameLum+\"_Branches\"+Suffix), nans[1],fmt='%s')\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameS+\"_Leaves\"+Suffix), nans[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameS+\"_Branches\"+Suffix), nans[1],fmt='%s')\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameR+\"_Leaves\"+Suffix), nans[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameR+\"_Branches\"+Suffix), nans[1],fmt='%s')\n",
    "\n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameFlux+\"_Leaves\"+Suffix), nans[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameFlux+\"_Branches\"+Suffix), nans[1],fmt='%s')\n",
    "\n",
    "\n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,Cube_Name_Save+\"Distances_Leaves\"+Suffix), nans[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,Cube_Name_Save+\"Distances_Branches\"+Suffix), nans[1],fmt='%s')\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,Cube_Name_Save+\"V_err_Leaves\"+Suffix), nans[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,Cube_Name_Save+\"V_err_Branches\"+Suffix), nans[1],fmt='%s')\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b0d3a6-910e-491d-bfe1-9e0435873549",
   "metadata": {},
   "outputs": [],
   "source": [
    "#None (m)\n",
    "\n",
    "Abs_Level = Abs_Levels[3]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pathCont = 'Continuum_Reproject.fits'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for kl in range(iterations):\n",
    "      \n",
    "    Prime_Beam = Min_res*((kl*iter_factor+1))#\n",
    "    print(Prime_Beam)\n",
    "    \n",
    "    \n",
    "    for km in range(iterations):\n",
    "        vel_prime = min_vel*((km*iter_factor+1))\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        try:\n",
    "            Names=list(np.load(\"Names_New_All_Kinds.npy\",allow_pickle=True))\n",
    "        except Exception as e:\n",
    "\n",
    "            print(e)\n",
    "            print(\"initialized names\")\n",
    "            Names = list(np.empty((20,iterations,iterations,iterations,iterations),dtype=object))\n",
    "                        \n",
    "\n",
    "        #Continuum image\n",
    "        scCont = spectral_cube.Projection.from_hdu(fits.open(pathCont)[0])\n",
    "        #Put this up here for the column density map\n",
    "        metadata = {}\n",
    "        metadata[\"distance\"] = 3.5*u.Mpc\n",
    "        arc_per_pix_yc =  abs(scCont.hdu.header[\"CDELT1\"]*3600.0 * u.arcsec)/u.pix\n",
    "        arc_per_pix_xc =  abs(scCont.hdu.header[\"CDELT2\"]*3600.0 * u.arcsec)/u.pix\n",
    "        beam_majorc =  scCont.hdu.header[\"BMAJ\"]*3600.0 * u.arcsec\n",
    "        beam_minorc =  scCont.hdu.header[\"BMIN\"]*3600.0 * u.arcsec\n",
    "        beam_area_ratioc = beam_minorc*beam_majorc/arc_per_pix_yc/arc_per_pix_xc*1.13309#beam_area_ratioc = beam_minorc*beam_majorc/arc_per_pix_yc/arc_per_pix_xc#This is for FWHM, use *(2*np.sqrt(2*np.log(2)))**2#For gaussian beam\n",
    "        metadata['beam_area_ratioc']=beam_area_ratioc\n",
    "        pc_per_pixelc = abs(scCont.hdu.header[\"CDELT1\"])/180*np.pi*metadata['distance']/u.Mpc\n",
    "        print(pc_per_pixelc,\"MPC per pix\")\n",
    "\n",
    "        #Make subcube\n",
    "\n",
    "\n",
    "\n",
    "        Cube_Name_Load = \"Cropped_\"+str(Prime_Beam.value)+\"pc_beam_\"+Line_Name+str(FOV[0])+\"x\"+str(FOV[1])+'pc_'+str(vel_prime)+'_vel_res.fits'\n",
    "        path = Cube_Name_Load\n",
    "        \n",
    "        Qp = SpectralCube.read(path).with_spectral_unit(u.km/u.s,velocity_convention=\"radio\") \n",
    "        Qp.allow_huge_operations=True\n",
    "\n",
    "        Q = Qp.to(u.K)#Jy to Kelvin\n",
    "\n",
    "        sc = Q.unmasked_copy()\n",
    "\n",
    "\n",
    "\n",
    "        scW = sc.wcs[:][:][0]\n",
    "        dat = sc.hdu.data[int(len(sc)*((1-Ram_Limiter)/2)):int(len(sc)*(Ram_Limiter + (1-Ram_Limiter)/2)),:,:]\n",
    "        scn = sc[int(len(sc)*((1-Ram_Limiter)/2)):int(len(sc)*(Ram_Limiter + (1-Ram_Limiter)/2)),:,:]\n",
    "        scF = scn\n",
    "        datn = dat\n",
    "\n",
    "\n",
    "        #m=.115\n",
    "\n",
    "        #print(m,\"Presumed Noise (K)\")\n",
    "\n",
    "        #Continuum image\n",
    "        scCont = spectral_cube.Projection.from_hdu(fits.open(pathCont)[0])\n",
    "        #Do the same thing to the continuum image\n",
    "        scCont.allow_huge_operations=True\n",
    "        scContW = scCont.reproject(scF.moment0().header)\n",
    "        #m=.115\n",
    "\n",
    "\n",
    "        scW = sc.wcs[:][:][0]\n",
    "\n",
    "        cen_p1 = SkyCoord('00h47m33.9s', '-25d17m26.8s', frame='icrs')\n",
    "        cen_p2 = SkyCoord('00h47m32.6s', '-25d17m10.2s', frame='icrs')\n",
    "\n",
    "\n",
    "        #Do the same thing to the continuum image\n",
    "        scCont.allow_huge_operations=True\n",
    "        scContW = scCont.reproject(scF.moment0().header)\n",
    "        Continuum_Data  =scContW.hdu.data\n",
    "        scWCS = scF.wcs[:][:][0]\n",
    "\n",
    "        moment_0_sub  = scF.to(u.K).moment(order=0,how='slice')            # Calculate the Moment 0 map \n",
    "\n",
    "\n",
    "\n",
    "        ######Moment 0 for both\n",
    "        ######and cont\n",
    "        Make_Plot((LineN+\" Moment 0\"),\"Moment 0 (K km/s)\",moment_0_sub.hdu.data,0,np.nanmax(moment_0_sub.hdu.data),moment_0_sub.wcs,1,1,1,True)\n",
    "\n",
    "\n",
    "        cSD = (Flux_to_Mass(scContW.hdu.data*u.Jy/u.beam/beam_area_ratioc*u.pix**2*u.beam)/(pc_per_pixelc*10**6*3.086*10**18*u.cm)**2)*(1.989*10**30*u.kg/u.M_sun)*Num_per_kg/u.kg #Flux goes to luminosity for a gaussian beam and goes to column density for square pixels, mass goes to kg to number\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        rm=moment_0_sub.hdu.data/cSD\n",
    "        rmU = rm*u.K*u.km/u.s#Just put back in the units\n",
    "        rmU = np.array(rmU /(u.K*u.km/u.s)/u.cm**2*10**22,dtype='float64')#Now remove them all\n",
    "\n",
    "        ######ratio\n",
    "\n",
    "        bp = np.where(cSD<=7*10**22/u.cm**2)\n",
    "        bp2 = np.where( moment_0_sub.hdu.data < .22)\n",
    "        Continuum_Data[bp] = np.nan\n",
    "        cSD[bp]=np.nan\n",
    "        rmU[bp]=np.nan\n",
    "        rmU[bp2]=np.nan\n",
    "\n",
    "        Non_nan=((datn[0,:,:]>0)  | (datn[0,:,:]<0 ))\n",
    "\n",
    "        m = (np.nanstd(datn[0,:,:],where= Non_nan)) #Noise K\n",
    "        if(Abs_Level==\"All\"):\n",
    "            pass\n",
    "        if(Abs_Level==\"None\"):\n",
    "            datn[np.where(datn<0)]=np.nan\n",
    "        if(Abs_Level==\"None (m)\"):\n",
    "            datn[np.where(datn<-m)]=np.nan\n",
    "        if(Abs_Level==\"None All Channels\"):\n",
    "            for lmi in range(len(datn)):\n",
    "                bpP = np.where(datn[lmi]<-m)\n",
    "                for lmj in range(len(datn)):\n",
    "                    datn[lmj][bpP]=np.nan\n",
    "        if(Abs_Level==\"No Clusters\"):\n",
    "            IDs,RAs,Decs,HWHM  =    np.genfromtxt(\"NGC_Clusters_\"+\"IDs\"+\"\",dtype=type(\"12h23.14s\")),np.genfromtxt(\"NGC_Clusters_\"+\"RAs\"+\"\",dtype=type(\"12h23.14s\")),np.genfromtxt(\"NGC_Clusters_\"+\"Decs\"+\"\",dtype=type(\"12h23.14s\")),np.genfromtxt(\"NGC_Clusters_\"+\"HWHM\"+\"\")\n",
    "\n",
    "            datn=  Mask_Clusters_NGC(HWHM,scWCS,scF.hdu.header,datn,RAs,Decs,One_Pc=False,One_Pc_Size=1,HWHM_Fac=3)\n",
    "\n",
    "        print(m,\"Unmatched Noise (K)\", \"Abs = \",Abs_Level)\n",
    "\n",
    "\n",
    "        Make_Plot(\"Column Density\",\"(#/cm^2)\",cSD,float(np.nanmin(cSD*u.cm**2)),float(np.nanmax(cSD*u.cm**2)),scCont.wcs,1,1,1,True)\n",
    "        Make_Plot((LineN+\" Moment 0/Column Density\"),\"Moment 0 over Column Density of the Continuum (K km/s/(#/cm^2))\",rmU,np.nanmean(rmU)*.5,abs(np.nanmean(rmU))*8,scCont.wcs,1,1,1,True)\n",
    "\n",
    "        print(np.nanmin(rmU))\n",
    "\n",
    "\n",
    "\n",
    "        header = scF.hdu.header\n",
    "        print()\n",
    "        #make metadata for the dendrogram\n",
    "\n",
    "        try:\n",
    "            freq = header[\"RESTFREQ\"]*u.Hz#\n",
    "            metadata['wavelength']=299792458*u.m/header[\"RESTFREQ\"]#\n",
    "            print(1,freq,metadata['wavelength'])\n",
    "        except:\n",
    "            freq = header[\"RESTFRQ\"]*u.Hz#\n",
    "            metadata['wavelength']=299792458*u.m/header[\"RESTFRQ\"]#\n",
    "        metadata['data_unit'] =scF[0][0][0].unit# header['BUNIT']\n",
    "        metadata['arc_per_pix_y'] =  abs(header[\"CDELT1\"]*3600.0 * u.arcsec)/u.pix\n",
    "        metadata['arc_per_pix_x'] =  abs(header[\"CDELT2\"]*3600.0 * u.arcsec)/u.pix\n",
    "\n",
    "\n",
    "        metadata['beam_major'] =  header[\"BMAJ\"]*3600.0 * u.arcsec\n",
    "        metadata['beam_minor'] =  header[\"BMIN\"]*3600.0 * u.arcsec\n",
    "        beam_area_ratio = metadata['beam_minor']*metadata['beam_major']/metadata['arc_per_pix_y']/metadata['arc_per_pix_x']*1.13309#beam_area_ratio = metadata['beam_minor']*metadata['beam_major']/metadata['arc_per_pix_y']/metadata['arc_per_pix_x']#This is for FWHM, use *(2*np.sqrt(2*np.log(2)))**2#For gaussian beam\n",
    "        metadata['beam_area_ratio']=beam_area_ratio\n",
    "        metadata['spatial_scale'] = np.sqrt(abs(header[\"CDELT1\"])*u.degree**2*abs(header[\"CDELT2\"]))\n",
    "        area_res = abs(header[\"CDELT1\"])*abs(header[\"CDELT2\"])*(np.pi/180*3.5)**2#mpc^2/pix^2\n",
    "        print(area_res,type(area_res))\n",
    "\n",
    "        print(metadata['beam_minor'],metadata['beam_major'])\n",
    "        print(beam_area_ratio)\n",
    "        #metadata[\"wcs\"] = wcs\n",
    "        metadata[\"velocity_scale\"] = abs(header[\"CDELT3\"])*u.km/u.s#u.km/u.s\n",
    "\n",
    "        metadata[\"vaxis\"]=0\n",
    "        metadata[\"wcsu\"]=scF.wcs\n",
    "\n",
    "\n",
    "        for k3 in range(iterations):\n",
    "\n",
    "            beam_req = Min_beam_req*(k3+1)\n",
    "            \n",
    "            for k4 in range(iterations):\n",
    "                print(kl,km,k3,k4)\n",
    "                try:\n",
    "\n",
    "                    pix_thresh_factor = k4+1\n",
    "\n",
    "                    Cube_Name_Save = Name+\"_Cropped_\"+str(Prime_Beam.value)+\"pc_beam_\"+Line_Name+str(FOV[0])+\"x\"+str(FOV[1])+'pc_'+str(vel_prime)+'_vel_res_'+str(beam_req)+\"_beam_size_req_\"+str(pix_thresh_factor)+'_times_beam_pixels.fits'\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    Names[Num][kl][km][k3][k4] = Cube_Name_Save\n",
    "                    \n",
    "                    NameS = (Cube_Name_Save+\"Sigmas\")\n",
    "                    NameR = (Cube_Name_Save+\"Radii\")\n",
    "                    NameCol = (Cube_Name_Save+\"_Column\")\n",
    "                    NameLum = (Cube_Name_Save+\"_Luminosities\")\n",
    "\n",
    "                    NameFlux = (Cube_Name_Save+\"Flux_Dense\")\n",
    "                    NameRFF = (Cube_Name_Save+\"Rad_For_Flux\")\n",
    "                    \n",
    "                    print(Cube_Name_Save)\n",
    "                    \n",
    "                    np.save(\"Names_New_All_Kinds\",Names)\n",
    "\n",
    "                    \n",
    "                   \n",
    "\n",
    "\n",
    "                    d = astrodendro.Dendrogram.compute(datn,min_delta=m,min_value=m*5,min_npix=beam_area_ratio.value*pix_thresh_factor) #The main culprit\n",
    "                    #d = astrodendro.Dendrogram.compute(datn,min_delta=m,min_value=m*5,min_npix=beam_area_ratio.value) #The main culprit\n",
    "\n",
    "                    vel,RA,Dec = scF.world[:,0,0]\n",
    "                    Rads,Sigmas,CD,Lumin,SIDS,MOM0FLUX,Distances,V_err = Dendro_Arrays(d,datn,vel,Continuum_Data,metadata,beam_size=Prime_Beam.value,beam_req=beam_req)\n",
    "                    \n",
    "\n",
    "                    ##Analyze dendograms\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    fig = plt.figure(1,figsize=(40,40))\n",
    "\n",
    "\n",
    "                    axAlpha = pylab.subplot(5, 5, 7)\n",
    "                    axBeta = pylab.subplot(5, 5, 8)\n",
    "                    axGamma = pylab.subplot(5, 5, 9)\n",
    "                    axDelta = pylab.subplot(5, 5, 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    p1=d.plotter()\n",
    "                    p1.plot_tree(axAlpha)\n",
    "                    axAlpha.set_xlabel(\"Structure\")\n",
    "                    axAlpha.set_ylabel(\"Flux (K)\")\n",
    "                    axAlpha.set_title(\"Whole data set\")\n",
    "\n",
    "\n",
    "\n",
    "                    #Plot contours for the top ten clusters\n",
    "\n",
    "\n",
    "                    #scCropped =scF.moment0().hdu.data\n",
    "                    scCropped =scF.moment0().hdu.data\n",
    "                    scCropped[np.where(scF.moment0().hdu.data<.22)]=np.nan\n",
    "                    print(np.nanmean(np.nanstd(scF.moment0().hdu.data))*1)\n",
    "                    scCropped[bp]=np.nan\n",
    "                    axDelta = pylab.subplot(5,5,8,projection=scF.moment0().wcs)\n",
    "                    #axBeta.imshow(scCropped.moment0().hdu.data, origin='lower', interpolation='nearest', cmap=plt.cm.Blues,norm=colors.LogNorm(vmin=5))\n",
    "                    imBeta = axDelta.imshow(scCropped, origin='lower', interpolation='nearest', cmap=plt.cm.Blues,vmin=0,vmax = np.nanmax(scCropped)*.7 )\n",
    "\n",
    "\n",
    "\n",
    "                    ColumnCon= np.concatenate((CD[0],CD[1]))\n",
    "                    SIDScon = np.concatenate((SIDS[0],SIDS[1]))\n",
    "                    nth =0# sorted(CD[0])[len(CD[0])-20]\n",
    "\n",
    "                    G1 = True\n",
    "\n",
    "                    RA = axDelta.coords[0]                                                                  # \n",
    "                    Dec = axDelta.coords[1]\n",
    "\n",
    "                    RA.set_ticks(size=-3)                                                                                      \n",
    "                    Dec.set_ticks(size=-3) \n",
    "                    RA.set_ticklabel(exclude_overlapping=True) \n",
    "                    Dec.set_ticklabel(exclude_overlapping=True)                                                                                     \n",
    "                    pylab.xlabel('Right Ascension',fontsize=20,labelpad=1)                               \n",
    "                    pylab.ylabel('Declination',fontsize=20,labelpad=1)\n",
    "                    axDelta.tick_params(axis = 'both', which = 'major', labelsize = 15)    \n",
    "                    cb=pylab.colorbar(imBeta,fraction=0.016,pad=0.04)                                     \n",
    "                    cb.set_label(label=\"Moment 0 K km/s\",fontsize=10,rotation=270,labelpad=20) \n",
    "                    cb.ax.tick_params(which = 'major', labelsize = 10)   \n",
    "                    pylab.annotate(s=LineN,fontsize=10,xy=(.01,1.05),xycoords=\"axes fraction\",c=\"black\")  \n",
    "                    pylab.annotate(s=\"Highest Density\",fontsize=10,xy=(.31,1.05),xycoords=\"axes fraction\",c=\"red\")  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    pc_per_pixel = abs(header[\"CDELT1\"])/180*np.pi*metadata['distance']/u.Mpc\n",
    "\n",
    "                    sig_per_pixel=np.nan#metadata['spectral_resolution']/u.pix\n",
    "\n",
    "\n",
    "                    #Finds Size, Linewidth, Luminosity, and Column Density of a structure for each structure and returns them in [[][]] arrays [Leaves][Branches]\n",
    "\n",
    "\n",
    "                    from scipy.optimize import curve_fit\n",
    "                    from scipy.optimize import leastsq\n",
    "\n",
    "                    def func(R,a,b):\n",
    "                        return a*R**(b)\n",
    "                    try:\n",
    "                        popt, pcov = curve_fit(func, Rads[0]*10**6,Sigmas[0])\n",
    "                    except:\n",
    "                        popt, pcov = [np.nan,np.nan],[[np.nan,np.nan],[np.nan,np.nan]]\n",
    "                    try:\n",
    "                        poptB, pcovB = curve_fit(func,  Rads[1]*10**6,Sigmas[1])\n",
    "                    except:\n",
    "                        poptB, pcovB = [np.nan,np.nan],[[np.nan,np.nan],[np.nan,np.nan]]\n",
    "\n",
    "                    \n",
    "\n",
    "                    Rcon = np.concatenate((Rads[0],Rads[1]))\n",
    "\n",
    "                        \n",
    "                    Scon = np.concatenate((Sigmas[0],Sigmas[1]))\n",
    "                    Scon2 = np.concatenate((Sigmas[2],Sigmas[3]))\n",
    "                    print(np.shape(Rcon))\n",
    "                    \n",
    "                    poptCon, pcovCon = curve_fit(func, Rcon*10**6, Scon)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    xs=np.linspace(np.nanmin(Rcon*10**6),np.nanmax(Rcon*10**6),50)\n",
    "\n",
    "                    ysL,ysB,ysCon=func(xs,popt[0],popt[1]),func(xs,poptB[0],poptB[1]),func(xs,poptCon[0],poptCon[1])\n",
    "\n",
    "\n",
    "                    LuminCon = np.concatenate((Lumin[0],Lumin[1]))\n",
    "                    ColumnCon= np.concatenate((CD[0],CD[1]))\n",
    "\n",
    "                    MOM0FLUXcon = np.concatenate((MOM0FLUX[0],MOM0FLUX[1]))\n",
    "                    DistancesCon= np.concatenate((Distances[0],Distances[1]))\n",
    "                    print(Distances)\n",
    "\n",
    "                    #Radius Luminosity fit\n",
    "                    #Good pixels are places where the luminosity and therefore column density are above zero\n",
    "                    gp = np.where(LuminCon>0)\n",
    "                    print(np.shape(Rcon),np.shape(LuminCon))\n",
    "                    lgp = LuminCon[gp]\n",
    "                    radgp = Rcon[gp]*10**6\n",
    "\n",
    "                    gp2 = np.where(ColumnCon>0)\n",
    "                    cgp = ColumnCon[gp2]\n",
    "                    rgp=Scon[gp2]**2/Rcon[gp2]/10**6\n",
    "                    dgp=DistancesCon[gp2]\n",
    "                    radgpFORRAT = Rcon[gp2]*10**6\n",
    "                    siggpFORRAT = Scon[gp2]\n",
    "                    lumFORRAT = LuminCon[gp2]\n",
    "                    mom0FORRAT = MOM0FLUXcon[gp2]\n",
    "\n",
    "                    #print(np.shape(Rcon[gp]*10**6),np.shape(LuminCon[gp]))\n",
    "                    RLpopt,RLpcov = curve_fit(func, np.array(radgp,dtype='float64'),np.array(lgp,dtype='float64'),maxfev=999999,p0 = np.array([10**27,1],dtype='float64'),ftol = 10**-10)\n",
    "\n",
    "                    xsRL=np.linspace(np.nanmin(radgp),np.nanmax(radgp),50)\n",
    "                    ysRL = func(xsRL,RLpopt[0],RLpopt[1])\n",
    "                    #Column density to Size-linewidth\n",
    "                    CDpopt,CDpcov = curve_fit(func, np.array(cgp,dtype='float64') ,np.array(rgp,dtype='float64'),maxfev=9999099,p0 = np.array([10,.01],dtype='float64'),ftol = 10**-10)\n",
    "\n",
    "                    Dist_popt,Dist_pcov = curve_fit(func, np.array(DistancesCon,dtype='float64') ,np.array(Scon,dtype='float64'),maxfev=9999099,ftol = 10**-10)\n",
    "                    Dist_popt2,Dist_pcov2 = curve_fit(func, np.array(dgp,dtype='float64') ,np.array(rgp,dtype='float64'),maxfev=9999099,ftol = 10**-10)\n",
    "\n",
    "                    xsDist=np.linspace(np.nanmin(DistancesCon),np.nanmax(DistancesCon),50)\n",
    "                    xsDist2=np.linspace(np.nanmin(dgp),np.nanmax(dgp),50)\n",
    "                    ysDist=func(xsDist,Dist_popt[0],Dist_popt[1])\n",
    "                    ysDist2=func(xsDist2,Dist_popt2[0],Dist_popt2[1])\n",
    "\n",
    "\n",
    "                    axdis = pylab.subplot(5, 5, 12)\n",
    "                    axdis2 = pylab.subplot(5, 5, 13)\n",
    "                    axdis.scatter(DistancesCon,Scon)\n",
    "                    axdis2.scatter(dgp,rgp)\n",
    "                    axdis.plot(xsDist,ysDist)\n",
    "                    axdis2.plot(xsDist2,ysDist2)\n",
    "                    axdis2.set_yscale('log')\n",
    "                    axdis2.set_xscale('log')\n",
    "                    axdis.set_yscale('log')\n",
    "                    axdis.set_xscale('log')\n",
    "\n",
    "                    xsCD=np.linspace(np.nanmin(cgp),np.nanmax(cgp),50)\n",
    "                    ysCD = func(xsCD,CDpopt[0],CDpopt[1])\n",
    "\n",
    "\n",
    "                    print(poptCon,pcovCon,\"Size Linewidth All_structures:\")\n",
    "                    print(\"a = \",poptCon[0],\"+-\",np.sqrt(pcovCon[0][0]))\n",
    "                    print(\"b = \",poptCon[1],\"+-\",np.sqrt(pcovCon[1][1]))\n",
    "\n",
    "\n",
    "                    print(RLpopt,RLpcov,\"Radius to Luminosity:\")\n",
    "                    print(\"c = \",RLpopt[0],\"+-\",np.sqrt(RLpcov[0][0]))\n",
    "                    print(\"d = \",RLpopt[1],\"+-\",np.sqrt(RLpcov[1][1]))\n",
    "\n",
    "\n",
    "\n",
    "                    print(CDpopt,CDpcov,\"Column Density to linewidth^2/size:\")\n",
    "                    print(\"e = \",CDpopt[0],\"+-\",np.sqrt(CDpcov[0][0]))\n",
    "                    print(\"f = \",CDpopt[1],\"+-\",np.sqrt(CDpcov[1][1]))\n",
    "\n",
    "\n",
    "\n",
    "                    ax2 = pylab.subplot(5, 5, 1)\n",
    "                    ax3 = pylab.subplot(5, 5, 2)\n",
    "                    ax4 = pylab.subplot(5, 5, 3)\n",
    "\n",
    "                    xpcon = ax2.scatter(Rcon*10**6,Scon,label=\"All_structures\",s=30,alpha=.7)\n",
    "\n",
    "\n",
    "                    p = ax2.plot(xs,ysCon)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    st=\"WDS: a=\"+ str(np.format_float_scientific(poptCon[0],1))+\"+-\"+str(np.format_float_scientific(np.sqrt(pcovCon[0][0]),1))+\" b=\"+str(np.format_float_scientific(poptCon[1],1))+\"+-\"+str(np.format_float_scientific(np.sqrt(pcovCon[1][1]),2))\n",
    "                    ax2.annotate(s=st,fontsize=10,xy=(0.01,0.01),xycoords=\"axes fraction\")\n",
    "\n",
    "                    ax2.annotate(s=r'$\\sigma$ = $a*R^b$',fontsize=10,xy=(0.01,0.10),xycoords=\"axes fraction\")\n",
    "                    ax2.set_yscale('log')\n",
    "                    ax2.set_xscale('log')\n",
    "                    ax2.set_ylim(np.nanmin(Scon),np.nanmax(Scon))\n",
    "                    ax2.set_xlabel(\"Size (pc)\",fontsize=12)\n",
    "                    ax2.set_ylabel(\"Sigma (km/s)\",fontsize=12)\n",
    "                    ax2.legend(prop={'size': 12},loc=\"upper right\")\n",
    "                    ax2.annotate(s=LineN,fontsize=10,xy=(0.01,0.89),xycoords=\"axes fraction\")\n",
    "\n",
    "                    #gp = np.where(FRs>0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    xspL = ax4.scatter(radgpFORRAT,siggpFORRAT,label=\"All_structures\",s=30)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    ax4.set_yscale('log')\n",
    "                    ax4.set_xscale('log')\n",
    "\n",
    "                    ax4.set_xlabel(\"Radius (pc)\",fontsize=12)\n",
    "                    ax4.set_ylabel(\"sig (km/s)\",fontsize=12)\n",
    "                    ax4.legend(prop={'size': 12},loc=\"upper right\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    xspF = ax3.scatter(radgpFORRAT,rgp,label=\"All_structures\",s=30)\n",
    "\n",
    "                    ax3.annotate(s=st,fontsize=12,xy=(0.01,0.04),xycoords=\"axes fraction\")\n",
    "                    ax3.set_yscale('log')\n",
    "                    ax3.set_xscale('log')\n",
    "                    ax3.set_ylim(np.nanmin(rgp),np.nanmax(rgp))\n",
    "                    ax3.set_xlabel(\"Rad (pc)\",fontsize=12)\n",
    "                    ax3.set_ylabel(\"Linewidth Ratio (km^2/s^2/pc)\",fontsize=12)\n",
    "                    ax3.legend(prop={'size': 12})\n",
    "\n",
    "                    gp3 = np.where(lumFORRAT>0)\n",
    "                    lumFORRAT = lumFORRAT[gp3]\n",
    "                    rgpFORRAT = rgp[gp3]\n",
    "                    mom0FORRAT = mom0FORRAT[gp3]\n",
    "\n",
    "\n",
    "\n",
    "                    ax5 = pylab.subplot(5, 5, 4)\n",
    "                    ax6 = pylab.subplot(5, 5, 5)\n",
    "                    ax7 = pylab.subplot(5, 5, 6)\n",
    "\n",
    "\n",
    "\n",
    "                    xpconhh = ax5.scatter(radgpFORRAT,cgp,label=\"All_structures\",s=30,alpha=.7)\n",
    "                    ax5.set_yscale('log')\n",
    "                    ax5.set_xscale('log')\n",
    "                    ax5.set_xlabel(\"Size (pc)\",fontsize=12)\n",
    "                    ax5.set_ylabel(\"Column Density (#/cm^2 > 7e22)\",fontsize=12)\n",
    "                    ax5.legend(prop={'size': 12},loc=\"upper right\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    xspF2 = ax6.scatter(cgp,rgp,label=\"All_structures\",s=30,alpha=.7)\n",
    "                    pF2 = ax6.plot(xsCD,ysCD)\n",
    "\n",
    "                    ax6.set_yscale('log')\n",
    "                    ax6.set_xscale('log')\n",
    "                    ax6.set_ylim(np.nanmin(rgp),np.nanmax(rgp))\n",
    "                    ax6.set_xlabel(\"Column Density (#/cm^2 > 7e22)\",fontsize=12)\n",
    "                    ax6.set_ylabel(\"Linewidth Ratio (km^2/s^2/pc)\",fontsize=12)\n",
    "                    ax6.legend(prop={'size': 12},loc=\"upper right\")\n",
    "                    ax6.annotate(s=LineN,fontsize=10,xy=(0.01,0.89),xycoords=\"axes fraction\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    xspLu2 = ax7.scatter(radgp,lgp,label=\"All_structure Whole Data Set\",s=30,alpha=.7)\n",
    "                    pFLLu2 = ax7.plot(xsRL,ysRL)\n",
    "\n",
    "                    st = \"WDS, c = \"+ str(np.format_float_scientific(RLpopt[0],3))+\"+-\"+str(np.format_float_scientific(np.sqrt(RLpcov[0][0]),3))+\" d = \"+str(np.format_float_scientific(RLpopt[1],3))+\"+-\"+str(np.format_float_scientific(np.sqrt(RLpcov[1][1]),3))\n",
    "                    ax7.annotate(s='L = $c*R^d$',fontsize=12,xy=(0.01,0.13),xycoords=\"axes fraction\")\n",
    "                    ax7.annotate(s=st,fontsize=12,xy=(0.01,0.04),xycoords=\"axes fraction\")\n",
    "\n",
    "                    ax7.set_yscale('log')\n",
    "                    ax7.set_xscale('log')\n",
    "                    ax7.set_ylim(np.nanmin(lgp),np.nanmax(lgp))\n",
    "                    ax7.set_xlabel(\"Radius (pc)\",fontsize=9)\n",
    "                    ax7.set_ylabel(\"Luminosity (erg)\",fontsize=9)\n",
    "                    ax7.legend(prop={'size': 12},loc=\"upper right\")\n",
    "                    ax7.annotate(s=LineN,fontsize=10,xy=(0.01,0.89),xycoords=\"axes fraction\")\n",
    "\n",
    "\n",
    "                    axLam = pylab.subplot(5, 5, 11)\n",
    "                    lum_rat = axLam.scatter(lumFORRAT/radgpFORRAT**2,rgpFORRAT,label=\"All_structure  \",s=30,alpha=.7)\n",
    "                    #Off by factors for area, simply using r^2\n",
    "\n",
    "                    axLam.set_yscale('log')\n",
    "                    axLam.set_xscale('log')\n",
    "                    axLam.set_xlabel(\"Lum/R^2 (erg/pc^2)\",fontsize=9)\n",
    "                    axLam.set_ylabel(\"Linewidth Ratio (km/s)^2/pc\",fontsize=9)\n",
    "                    axLam.legend(prop={'size': 12},loc=\"upper right\")\n",
    "                    axLam.annotate(s=LineN,fontsize=10,xy=(0.01,0.89),xycoords=\"axes fraction\")\n",
    "\n",
    "\n",
    "\n",
    "                    axDelta = pylab.subplot(5, 5, 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    gp4=np.where(MOM0FLUXcon>0)\n",
    "                    mom0FORFlux=MOM0FLUXcon[gp4]\n",
    "                    radgpFORFlux=Rcon[gp4]*10**6\n",
    "                    rgpFORFlux=Scon[gp4]**2/Rcon[gp4]/10**6\n",
    "\n",
    "                    mom0_rat = axDelta.scatter(mom0FORFlux/radgpFORFlux**2,rgpFORFlux,label=\"All_structure  \",s=30,alpha=.7)\n",
    "                    #Off by factors for area, simply using r^2\n",
    "\n",
    "                    axDelta.set_yscale('log')\n",
    "                    axDelta.set_xscale('log')\n",
    "                    axDelta.set_xlabel(\"Mom0 Flux/pc^2 (K km/s / R^2)\",fontsize=9)\n",
    "                    axDelta.set_ylabel(\"Linewidth Ratio (km/s)^2/pc\",fontsize=9)\n",
    "                    axDelta.legend(prop={'size': 12},loc=\"upper right\")\n",
    "                    axDelta.annotate(s=LineN,fontsize=10,xy=(0.01,0.89),xycoords=\"axes fraction\")\n",
    "\n",
    "\n",
    "                    pylab.show()\n",
    "\n",
    "\n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    v1 = d.viewer()\n",
    "                    v1.show()\n",
    "\n",
    "                    #Must use text because np load is broken\n",
    "                    if(Abs_Level==\"All\"):\n",
    "                        Suffix=''\n",
    "                    if(Abs_Level==\"None\"):\n",
    "                        Suffix='_NA'\n",
    "                    if(Abs_Level==\"No Clusters\"):\n",
    "                        Suffix='_No_Clusters'\n",
    "                    if(Abs_Level==\"None (m)\"):\n",
    "                        Suffix='None_m'\n",
    "                    if(Abs_Level==\"None All Channels\"):\n",
    "                        Suffix='None_All_Channels'\n",
    "                        \n",
    "                    \n",
    "                    \n",
    "\n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameCol+\"_Leaves\"+Suffix), CD[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameCol+\"_Branches\"+Suffix), CD[1],fmt='%s')\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameLum+\"_Leaves\"+Suffix), Lumin[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameLum+\"_Branches\"+Suffix), Lumin[1],fmt='%s')\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameS+\"_Leaves\"+Suffix), Sigmas[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameS+\"_Branches\"+Suffix), Sigmas[1],fmt='%s')\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameR+\"_Leaves\"+Suffix), Rads[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameR+\"_Branches\"+Suffix), Rads[1],fmt='%s')\n",
    "\n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameFlux+\"_Leaves\"+Suffix), MOM0FLUX[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameFlux+\"_Branches\"+Suffix), MOM0FLUX[1],fmt='%s')\n",
    "\n",
    "\n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,Cube_Name_Save+\"Distances_Leaves\"+Suffix), Distances[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,Cube_Name_Save+\"Distances_Branches\"+Suffix), Distances[1],fmt='%s')\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,Cube_Name_Save+\"V_err_Leaves\"+Suffix), V_err[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,Cube_Name_Save+\"V_err_Branches\"+Suffix), V_err[1],fmt='%s')\n",
    "\n",
    "                    SIDS=np.concatenate((SIDS[0],SIDS[1]))\n",
    "\n",
    "                    print(SIDS[len(SIDS)-3:len(SIDS)-1])\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    print(kl,km,k3,k4)\n",
    "                    print(\"Failed\")\n",
    "                    print(\"-\"*60)\n",
    "                    traceback.print_exc(file=sys.stdout)\n",
    "                    \n",
    "                    if(Abs_Level==\"All\"):\n",
    "                        Suffix=''\n",
    "                    if(Abs_Level==\"None\"):\n",
    "                        Suffix='_NA'\n",
    "                    if(Abs_Level==\"No Clusters\"):\n",
    "                        Suffix='_No_Clusters'\n",
    "                    if(Abs_Level==\"None (m)\"):\n",
    "                        Suffix='None_m'\n",
    "                    if(Abs_Level==\"None All Channels\"):\n",
    "                        Suffix='None_All_Channels'\n",
    "                    nans = [[np.nan,np.nan],[np.nan,np.nan]]\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameCol+\"_Leaves\"+Suffix), nans[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameCol+\"_Branches\"+Suffix), nans[1],fmt='%s')\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameLum+\"_Leaves\"+Suffix), nans[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameLum+\"_Branches\"+Suffix), nans[1],fmt='%s')\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameS+\"_Leaves\"+Suffix), nans[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameS+\"_Branches\"+Suffix), nans[1],fmt='%s')\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameR+\"_Leaves\"+Suffix), nans[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameR+\"_Branches\"+Suffix), nans[1],fmt='%s')\n",
    "\n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameFlux+\"_Leaves\"+Suffix), nans[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameFlux+\"_Branches\"+Suffix), nans[1],fmt='%s')\n",
    "\n",
    "\n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,Cube_Name_Save+\"Distances_Leaves\"+Suffix), nans[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,Cube_Name_Save+\"Distances_Branches\"+Suffix), nans[1],fmt='%s')\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,Cube_Name_Save+\"V_err_Leaves\"+Suffix), nans[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,Cube_Name_Save+\"V_err_Branches\"+Suffix), nans[1],fmt='%s')\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae66dd78-cac9-4abc-ad89-3b22956540cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#No abs all channesl\n",
    "\n",
    "Abs_Level = Abs_Levels[4]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pathCont = 'Continuum_Reproject.fits'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for kl in range(iterations):\n",
    "      \n",
    "    Prime_Beam = Min_res*((kl*iter_factor+1))#\n",
    "    print(Prime_Beam)\n",
    "    \n",
    "    \n",
    "    for km in range(iterations):\n",
    "        vel_prime = min_vel*((km*iter_factor+1))\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        try:\n",
    "            Names=list(np.load(\"Names_New_All_Kinds.npy\",allow_pickle=True))\n",
    "        except Exception as e:\n",
    "\n",
    "            print(e)\n",
    "            print(\"initialized names\")\n",
    "            Names = list(np.empty((20,iterations,iterations,iterations,iterations),dtype=object))\n",
    "                        \n",
    "\n",
    "        #Continuum image\n",
    "        scCont = spectral_cube.Projection.from_hdu(fits.open(pathCont)[0])\n",
    "        #Put this up here for the column density map\n",
    "        metadata = {}\n",
    "        metadata[\"distance\"] = 3.5*u.Mpc\n",
    "        arc_per_pix_yc =  abs(scCont.hdu.header[\"CDELT1\"]*3600.0 * u.arcsec)/u.pix\n",
    "        arc_per_pix_xc =  abs(scCont.hdu.header[\"CDELT2\"]*3600.0 * u.arcsec)/u.pix\n",
    "        beam_majorc =  scCont.hdu.header[\"BMAJ\"]*3600.0 * u.arcsec\n",
    "        beam_minorc =  scCont.hdu.header[\"BMIN\"]*3600.0 * u.arcsec\n",
    "        beam_area_ratioc = beam_minorc*beam_majorc/arc_per_pix_yc/arc_per_pix_xc*1.13309#beam_area_ratioc = beam_minorc*beam_majorc/arc_per_pix_yc/arc_per_pix_xc#This is for FWHM, use *(2*np.sqrt(2*np.log(2)))**2#For gaussian beam\n",
    "        metadata['beam_area_ratioc']=beam_area_ratioc\n",
    "        pc_per_pixelc = abs(scCont.hdu.header[\"CDELT1\"])/180*np.pi*metadata['distance']/u.Mpc\n",
    "        print(pc_per_pixelc,\"MPC per pix\")\n",
    "\n",
    "        #Make subcube\n",
    "\n",
    "\n",
    "\n",
    "        Cube_Name_Load = \"Cropped_\"+str(Prime_Beam.value)+\"pc_beam_\"+Line_Name+str(FOV[0])+\"x\"+str(FOV[1])+'pc_'+str(vel_prime)+'_vel_res.fits'\n",
    "        path = Cube_Name_Load\n",
    "        \n",
    "        Qp = SpectralCube.read(path).with_spectral_unit(u.km/u.s,velocity_convention=\"radio\") \n",
    "        Qp.allow_huge_operations=True\n",
    "\n",
    "        Q = Qp.to(u.K)#Jy to Kelvin\n",
    "\n",
    "        sc = Q.unmasked_copy()\n",
    "\n",
    "\n",
    "\n",
    "        scW = sc.wcs[:][:][0]\n",
    "        dat = sc.hdu.data[int(len(sc)*((1-Ram_Limiter)/2)):int(len(sc)*(Ram_Limiter + (1-Ram_Limiter)/2)),:,:]\n",
    "        scn = sc[int(len(sc)*((1-Ram_Limiter)/2)):int(len(sc)*(Ram_Limiter + (1-Ram_Limiter)/2)),:,:]\n",
    "        scF = scn\n",
    "        datn = dat\n",
    "\n",
    "\n",
    "        #m=.115\n",
    "\n",
    "        #print(m,\"Presumed Noise (K)\")\n",
    "\n",
    "        #Continuum image\n",
    "        scCont = spectral_cube.Projection.from_hdu(fits.open(pathCont)[0])\n",
    "        #Do the same thing to the continuum image\n",
    "        scCont.allow_huge_operations=True\n",
    "        scContW = scCont.reproject(scF.moment0().header)\n",
    "        #m=.115\n",
    "\n",
    "\n",
    "        scW = sc.wcs[:][:][0]\n",
    "\n",
    "        cen_p1 = SkyCoord('00h47m33.9s', '-25d17m26.8s', frame='icrs')\n",
    "        cen_p2 = SkyCoord('00h47m32.6s', '-25d17m10.2s', frame='icrs')\n",
    "\n",
    "\n",
    "        #Do the same thing to the continuum image\n",
    "        scCont.allow_huge_operations=True\n",
    "        scContW = scCont.reproject(scF.moment0().header)\n",
    "        Continuum_Data  =scContW.hdu.data\n",
    "        scWCS = scF.wcs[:][:][0]\n",
    "\n",
    "        moment_0_sub  = scF.to(u.K).moment(order=0,how='slice')            # Calculate the Moment 0 map \n",
    "\n",
    "\n",
    "\n",
    "        ######Moment 0 for both\n",
    "        ######and cont\n",
    "        Make_Plot((LineN+\" Moment 0\"),\"Moment 0 (K km/s)\",moment_0_sub.hdu.data,0,np.nanmax(moment_0_sub.hdu.data),moment_0_sub.wcs,1,1,1,True)\n",
    "\n",
    "\n",
    "        cSD = (Flux_to_Mass(scContW.hdu.data*u.Jy/u.beam/beam_area_ratioc*u.pix**2*u.beam)/(pc_per_pixelc*10**6*3.086*10**18*u.cm)**2)*(1.989*10**30*u.kg/u.M_sun)*Num_per_kg/u.kg #Flux goes to luminosity for a gaussian beam and goes to column density for square pixels, mass goes to kg to number\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        rm=moment_0_sub.hdu.data/cSD\n",
    "        rmU = rm*u.K*u.km/u.s#Just put back in the units\n",
    "        rmU = np.array(rmU /(u.K*u.km/u.s)/u.cm**2*10**22,dtype='float64')#Now remove them all\n",
    "\n",
    "        ######ratio\n",
    "\n",
    "        bp = np.where(cSD<=7*10**22/u.cm**2)\n",
    "        bp2 = np.where( moment_0_sub.hdu.data < .22)\n",
    "        Continuum_Data[bp] = np.nan\n",
    "        cSD[bp]=np.nan\n",
    "        rmU[bp]=np.nan\n",
    "        rmU[bp2]=np.nan\n",
    "\n",
    "        Non_nan=((datn[0,:,:]>0)  | (datn[0,:,:]<0 ))\n",
    "\n",
    "        m = (np.nanstd(datn[0,:,:],where= Non_nan)) #Noise K\n",
    "        if(Abs_Level==\"All\"):\n",
    "            pass\n",
    "        if(Abs_Level==\"None\"):\n",
    "            datn[np.where(datn<0)]=np.nan\n",
    "        if(Abs_Level==\"None (m)\"):\n",
    "            datn[np.where(datn<-m)]=np.nan\n",
    "        if(Abs_Level==\"None All Channels\"):\n",
    "            for lmi in range(len(datn)):\n",
    "                bpP = np.where(datn[lmi]<-m)\n",
    "                for lmj in range(len(datn)):\n",
    "                    datn[lmj][bpP]=np.nan\n",
    "        if(Abs_Level==\"No Clusters\"):\n",
    "            IDs,RAs,Decs,HWHM  =    np.genfromtxt(\"NGC_Clusters_\"+\"IDs\"+\"\",dtype=type(\"12h23.14s\")),np.genfromtxt(\"NGC_Clusters_\"+\"RAs\"+\"\",dtype=type(\"12h23.14s\")),np.genfromtxt(\"NGC_Clusters_\"+\"Decs\"+\"\",dtype=type(\"12h23.14s\")),np.genfromtxt(\"NGC_Clusters_\"+\"HWHM\"+\"\")\n",
    "\n",
    "            datn=  Mask_Clusters_NGC(HWHM,scWCS,scF.hdu.header,datn,RAs,Decs,One_Pc=False,One_Pc_Size=1,HWHM_Fac=3)\n",
    "\n",
    "        print(m,\"Unmatched Noise (K)\", \"Abs = \",Abs_Level)\n",
    "\n",
    "\n",
    "        Make_Plot(\"Column Density\",\"(#/cm^2)\",cSD,float(np.nanmin(cSD*u.cm**2)),float(np.nanmax(cSD*u.cm**2)),scCont.wcs,1,1,1,True)\n",
    "        Make_Plot((LineN+\" Moment 0/Column Density\"),\"Moment 0 over Column Density of the Continuum (K km/s/(#/cm^2))\",rmU,np.nanmean(rmU)*.5,abs(np.nanmean(rmU))*8,scCont.wcs,1,1,1,True)\n",
    "\n",
    "        print(np.nanmin(rmU))\n",
    "\n",
    "\n",
    "\n",
    "        header = scF.hdu.header\n",
    "        print()\n",
    "        #make metadata for the dendrogram\n",
    "\n",
    "        try:\n",
    "            freq = header[\"RESTFREQ\"]*u.Hz#\n",
    "            metadata['wavelength']=299792458*u.m/header[\"RESTFREQ\"]#\n",
    "            print(1,freq,metadata['wavelength'])\n",
    "        except:\n",
    "            freq = header[\"RESTFRQ\"]*u.Hz#\n",
    "            metadata['wavelength']=299792458*u.m/header[\"RESTFRQ\"]#\n",
    "        metadata['data_unit'] =scF[0][0][0].unit# header['BUNIT']\n",
    "        metadata['arc_per_pix_y'] =  abs(header[\"CDELT1\"]*3600.0 * u.arcsec)/u.pix\n",
    "        metadata['arc_per_pix_x'] =  abs(header[\"CDELT2\"]*3600.0 * u.arcsec)/u.pix\n",
    "\n",
    "\n",
    "        metadata['beam_major'] =  header[\"BMAJ\"]*3600.0 * u.arcsec\n",
    "        metadata['beam_minor'] =  header[\"BMIN\"]*3600.0 * u.arcsec\n",
    "        beam_area_ratio = metadata['beam_minor']*metadata['beam_major']/metadata['arc_per_pix_y']/metadata['arc_per_pix_x']*1.13309#beam_area_ratio = metadata['beam_minor']*metadata['beam_major']/metadata['arc_per_pix_y']/metadata['arc_per_pix_x']#This is for FWHM, use *(2*np.sqrt(2*np.log(2)))**2#For gaussian beam\n",
    "        metadata['beam_area_ratio']=beam_area_ratio\n",
    "        metadata['spatial_scale'] = np.sqrt(abs(header[\"CDELT1\"])*u.degree**2*abs(header[\"CDELT2\"]))\n",
    "        area_res = abs(header[\"CDELT1\"])*abs(header[\"CDELT2\"])*(np.pi/180*3.5)**2#mpc^2/pix^2\n",
    "        print(area_res,type(area_res))\n",
    "\n",
    "        print(metadata['beam_minor'],metadata['beam_major'])\n",
    "        print(beam_area_ratio)\n",
    "        #metadata[\"wcs\"] = wcs\n",
    "        metadata[\"velocity_scale\"] = abs(header[\"CDELT3\"])*u.km/u.s#u.km/u.s\n",
    "\n",
    "        metadata[\"vaxis\"]=0\n",
    "        metadata[\"wcsu\"]=scF.wcs\n",
    "\n",
    "\n",
    "        for k3 in range(iterations):\n",
    "\n",
    "            beam_req = Min_beam_req*(k3+1)\n",
    "            \n",
    "            for k4 in range(iterations):\n",
    "                print(kl,km,k3,k4)\n",
    "                try:\n",
    "\n",
    "                    pix_thresh_factor = k4+1\n",
    "\n",
    "                    Cube_Name_Save = Name+\"_Cropped_\"+str(Prime_Beam.value)+\"pc_beam_\"+Line_Name+str(FOV[0])+\"x\"+str(FOV[1])+'pc_'+str(vel_prime)+'_vel_res_'+str(beam_req)+\"_beam_size_req_\"+str(pix_thresh_factor)+'_times_beam_pixels.fits'\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    Names[Num][kl][km][k3][k4] = Cube_Name_Save\n",
    "                    \n",
    "                    NameS = (Cube_Name_Save+\"Sigmas\")\n",
    "                    NameR = (Cube_Name_Save+\"Radii\")\n",
    "                    NameCol = (Cube_Name_Save+\"_Column\")\n",
    "                    NameLum = (Cube_Name_Save+\"_Luminosities\")\n",
    "\n",
    "                    NameFlux = (Cube_Name_Save+\"Flux_Dense\")\n",
    "                    NameRFF = (Cube_Name_Save+\"Rad_For_Flux\")\n",
    "                    \n",
    "                    print(Cube_Name_Save)\n",
    "                    \n",
    "                    np.save(\"Names_New_All_Kinds\",Names)\n",
    "\n",
    "                    \n",
    "                   \n",
    "\n",
    "\n",
    "                    d = astrodendro.Dendrogram.compute(datn,min_delta=m,min_value=m*5,min_npix=beam_area_ratio.value*pix_thresh_factor) #The main culprit\n",
    "                    #d = astrodendro.Dendrogram.compute(datn,min_delta=m,min_value=m*5,min_npix=beam_area_ratio.value) #The main culprit\n",
    "\n",
    "                    vel,RA,Dec = scF.world[:,0,0]\n",
    "                    Rads,Sigmas,CD,Lumin,SIDS,MOM0FLUX,Distances,V_err = Dendro_Arrays(d,datn,vel,Continuum_Data,metadata,beam_size=Prime_Beam.value,beam_req=beam_req)\n",
    "                    \n",
    "\n",
    "                    ##Analyze dendograms\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    fig = plt.figure(1,figsize=(40,40))\n",
    "\n",
    "\n",
    "                    axAlpha = pylab.subplot(5, 5, 7)\n",
    "                    axBeta = pylab.subplot(5, 5, 8)\n",
    "                    axGamma = pylab.subplot(5, 5, 9)\n",
    "                    axDelta = pylab.subplot(5, 5, 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    p1=d.plotter()\n",
    "                    p1.plot_tree(axAlpha)\n",
    "                    axAlpha.set_xlabel(\"Structure\")\n",
    "                    axAlpha.set_ylabel(\"Flux (K)\")\n",
    "                    axAlpha.set_title(\"Whole data set\")\n",
    "\n",
    "\n",
    "\n",
    "                    #Plot contours for the top ten clusters\n",
    "\n",
    "\n",
    "                    #scCropped =scF.moment0().hdu.data\n",
    "                    scCropped =scF.moment0().hdu.data\n",
    "                    scCropped[np.where(scF.moment0().hdu.data<.22)]=np.nan\n",
    "                    print(np.nanmean(np.nanstd(scF.moment0().hdu.data))*1)\n",
    "                    scCropped[bp]=np.nan\n",
    "                    axDelta = pylab.subplot(5,5,8,projection=scF.moment0().wcs)\n",
    "                    #axBeta.imshow(scCropped.moment0().hdu.data, origin='lower', interpolation='nearest', cmap=plt.cm.Blues,norm=colors.LogNorm(vmin=5))\n",
    "                    imBeta = axDelta.imshow(scCropped, origin='lower', interpolation='nearest', cmap=plt.cm.Blues,vmin=0,vmax = np.nanmax(scCropped)*.7 )\n",
    "\n",
    "\n",
    "\n",
    "                    ColumnCon= np.concatenate((CD[0],CD[1]))\n",
    "                    SIDScon = np.concatenate((SIDS[0],SIDS[1]))\n",
    "                    nth =0# sorted(CD[0])[len(CD[0])-20]\n",
    "\n",
    "                    G1 = True\n",
    "\n",
    "                    RA = axDelta.coords[0]                                                                  # \n",
    "                    Dec = axDelta.coords[1]\n",
    "\n",
    "                    RA.set_ticks(size=-3)                                                                                      \n",
    "                    Dec.set_ticks(size=-3) \n",
    "                    RA.set_ticklabel(exclude_overlapping=True) \n",
    "                    Dec.set_ticklabel(exclude_overlapping=True)                                                                                     \n",
    "                    pylab.xlabel('Right Ascension',fontsize=20,labelpad=1)                               \n",
    "                    pylab.ylabel('Declination',fontsize=20,labelpad=1)\n",
    "                    axDelta.tick_params(axis = 'both', which = 'major', labelsize = 15)    \n",
    "                    cb=pylab.colorbar(imBeta,fraction=0.016,pad=0.04)                                     \n",
    "                    cb.set_label(label=\"Moment 0 K km/s\",fontsize=10,rotation=270,labelpad=20) \n",
    "                    cb.ax.tick_params(which = 'major', labelsize = 10)   \n",
    "                    pylab.annotate(s=LineN,fontsize=10,xy=(.01,1.05),xycoords=\"axes fraction\",c=\"black\")  \n",
    "                    pylab.annotate(s=\"Highest Density\",fontsize=10,xy=(.31,1.05),xycoords=\"axes fraction\",c=\"red\")  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    pc_per_pixel = abs(header[\"CDELT1\"])/180*np.pi*metadata['distance']/u.Mpc\n",
    "\n",
    "                    sig_per_pixel=np.nan#metadata['spectral_resolution']/u.pix\n",
    "\n",
    "\n",
    "                    #Finds Size, Linewidth, Luminosity, and Column Density of a structure for each structure and returns them in [[][]] arrays [Leaves][Branches]\n",
    "\n",
    "\n",
    "                    from scipy.optimize import curve_fit\n",
    "                    from scipy.optimize import leastsq\n",
    "\n",
    "                    def func(R,a,b):\n",
    "                        return a*R**(b)\n",
    "                    try:\n",
    "                        popt, pcov = curve_fit(func, Rads[0]*10**6,Sigmas[0])\n",
    "                    except:\n",
    "                        popt, pcov = [np.nan,np.nan],[[np.nan,np.nan],[np.nan,np.nan]]\n",
    "                    try:\n",
    "                        poptB, pcovB = curve_fit(func,  Rads[1]*10**6,Sigmas[1])\n",
    "                    except:\n",
    "                        poptB, pcovB = [np.nan,np.nan],[[np.nan,np.nan],[np.nan,np.nan]]\n",
    "\n",
    "                    \n",
    "\n",
    "                    Rcon = np.concatenate((Rads[0],Rads[1]))\n",
    "\n",
    "                        \n",
    "                    Scon = np.concatenate((Sigmas[0],Sigmas[1]))\n",
    "                    Scon2 = np.concatenate((Sigmas[2],Sigmas[3]))\n",
    "                    print(np.shape(Rcon))\n",
    "                    \n",
    "                    poptCon, pcovCon = curve_fit(func, Rcon*10**6, Scon)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    xs=np.linspace(np.nanmin(Rcon*10**6),np.nanmax(Rcon*10**6),50)\n",
    "\n",
    "                    ysL,ysB,ysCon=func(xs,popt[0],popt[1]),func(xs,poptB[0],poptB[1]),func(xs,poptCon[0],poptCon[1])\n",
    "\n",
    "\n",
    "                    LuminCon = np.concatenate((Lumin[0],Lumin[1]))\n",
    "                    ColumnCon= np.concatenate((CD[0],CD[1]))\n",
    "\n",
    "                    MOM0FLUXcon = np.concatenate((MOM0FLUX[0],MOM0FLUX[1]))\n",
    "                    DistancesCon= np.concatenate((Distances[0],Distances[1]))\n",
    "                    print(Distances)\n",
    "\n",
    "                    #Radius Luminosity fit\n",
    "                    #Good pixels are places where the luminosity and therefore column density are above zero\n",
    "                    gp = np.where(LuminCon>0)\n",
    "                    print(np.shape(Rcon),np.shape(LuminCon))\n",
    "                    lgp = LuminCon[gp]\n",
    "                    radgp = Rcon[gp]*10**6\n",
    "\n",
    "                    gp2 = np.where(ColumnCon>0)\n",
    "                    cgp = ColumnCon[gp2]\n",
    "                    rgp=Scon[gp2]**2/Rcon[gp2]/10**6\n",
    "                    dgp=DistancesCon[gp2]\n",
    "                    radgpFORRAT = Rcon[gp2]*10**6\n",
    "                    siggpFORRAT = Scon[gp2]\n",
    "                    lumFORRAT = LuminCon[gp2]\n",
    "                    mom0FORRAT = MOM0FLUXcon[gp2]\n",
    "\n",
    "                    #print(np.shape(Rcon[gp]*10**6),np.shape(LuminCon[gp]))\n",
    "                    RLpopt,RLpcov = curve_fit(func, np.array(radgp,dtype='float64'),np.array(lgp,dtype='float64'),maxfev=999999,p0 = np.array([10**27,1],dtype='float64'),ftol = 10**-10)\n",
    "\n",
    "                    xsRL=np.linspace(np.nanmin(radgp),np.nanmax(radgp),50)\n",
    "                    ysRL = func(xsRL,RLpopt[0],RLpopt[1])\n",
    "                    #Column density to Size-linewidth\n",
    "                    CDpopt,CDpcov = curve_fit(func, np.array(cgp,dtype='float64') ,np.array(rgp,dtype='float64'),maxfev=9999099,p0 = np.array([10,.01],dtype='float64'),ftol = 10**-10)\n",
    "\n",
    "                    Dist_popt,Dist_pcov = curve_fit(func, np.array(DistancesCon,dtype='float64') ,np.array(Scon,dtype='float64'),maxfev=9999099,ftol = 10**-10)\n",
    "                    Dist_popt2,Dist_pcov2 = curve_fit(func, np.array(dgp,dtype='float64') ,np.array(rgp,dtype='float64'),maxfev=9999099,ftol = 10**-10)\n",
    "\n",
    "                    xsDist=np.linspace(np.nanmin(DistancesCon),np.nanmax(DistancesCon),50)\n",
    "                    xsDist2=np.linspace(np.nanmin(dgp),np.nanmax(dgp),50)\n",
    "                    ysDist=func(xsDist,Dist_popt[0],Dist_popt[1])\n",
    "                    ysDist2=func(xsDist2,Dist_popt2[0],Dist_popt2[1])\n",
    "\n",
    "\n",
    "                    axdis = pylab.subplot(5, 5, 12)\n",
    "                    axdis2 = pylab.subplot(5, 5, 13)\n",
    "                    axdis.scatter(DistancesCon,Scon)\n",
    "                    axdis2.scatter(dgp,rgp)\n",
    "                    axdis.plot(xsDist,ysDist)\n",
    "                    axdis2.plot(xsDist2,ysDist2)\n",
    "                    axdis2.set_yscale('log')\n",
    "                    axdis2.set_xscale('log')\n",
    "                    axdis.set_yscale('log')\n",
    "                    axdis.set_xscale('log')\n",
    "\n",
    "                    xsCD=np.linspace(np.nanmin(cgp),np.nanmax(cgp),50)\n",
    "                    ysCD = func(xsCD,CDpopt[0],CDpopt[1])\n",
    "\n",
    "\n",
    "                    print(poptCon,pcovCon,\"Size Linewidth All_structures:\")\n",
    "                    print(\"a = \",poptCon[0],\"+-\",np.sqrt(pcovCon[0][0]))\n",
    "                    print(\"b = \",poptCon[1],\"+-\",np.sqrt(pcovCon[1][1]))\n",
    "\n",
    "\n",
    "                    print(RLpopt,RLpcov,\"Radius to Luminosity:\")\n",
    "                    print(\"c = \",RLpopt[0],\"+-\",np.sqrt(RLpcov[0][0]))\n",
    "                    print(\"d = \",RLpopt[1],\"+-\",np.sqrt(RLpcov[1][1]))\n",
    "\n",
    "\n",
    "\n",
    "                    print(CDpopt,CDpcov,\"Column Density to linewidth^2/size:\")\n",
    "                    print(\"e = \",CDpopt[0],\"+-\",np.sqrt(CDpcov[0][0]))\n",
    "                    print(\"f = \",CDpopt[1],\"+-\",np.sqrt(CDpcov[1][1]))\n",
    "\n",
    "\n",
    "\n",
    "                    ax2 = pylab.subplot(5, 5, 1)\n",
    "                    ax3 = pylab.subplot(5, 5, 2)\n",
    "                    ax4 = pylab.subplot(5, 5, 3)\n",
    "\n",
    "                    xpcon = ax2.scatter(Rcon*10**6,Scon,label=\"All_structures\",s=30,alpha=.7)\n",
    "\n",
    "\n",
    "                    p = ax2.plot(xs,ysCon)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    st=\"WDS: a=\"+ str(np.format_float_scientific(poptCon[0],1))+\"+-\"+str(np.format_float_scientific(np.sqrt(pcovCon[0][0]),1))+\" b=\"+str(np.format_float_scientific(poptCon[1],1))+\"+-\"+str(np.format_float_scientific(np.sqrt(pcovCon[1][1]),2))\n",
    "                    ax2.annotate(s=st,fontsize=10,xy=(0.01,0.01),xycoords=\"axes fraction\")\n",
    "\n",
    "                    ax2.annotate(s=r'$\\sigma$ = $a*R^b$',fontsize=10,xy=(0.01,0.10),xycoords=\"axes fraction\")\n",
    "                    ax2.set_yscale('log')\n",
    "                    ax2.set_xscale('log')\n",
    "                    ax2.set_ylim(np.nanmin(Scon),np.nanmax(Scon))\n",
    "                    ax2.set_xlabel(\"Size (pc)\",fontsize=12)\n",
    "                    ax2.set_ylabel(\"Sigma (km/s)\",fontsize=12)\n",
    "                    ax2.legend(prop={'size': 12},loc=\"upper right\")\n",
    "                    ax2.annotate(s=LineN,fontsize=10,xy=(0.01,0.89),xycoords=\"axes fraction\")\n",
    "\n",
    "                    #gp = np.where(FRs>0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    xspL = ax4.scatter(radgpFORRAT,siggpFORRAT,label=\"All_structures\",s=30)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    ax4.set_yscale('log')\n",
    "                    ax4.set_xscale('log')\n",
    "\n",
    "                    ax4.set_xlabel(\"Radius (pc)\",fontsize=12)\n",
    "                    ax4.set_ylabel(\"sig (km/s)\",fontsize=12)\n",
    "                    ax4.legend(prop={'size': 12},loc=\"upper right\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    xspF = ax3.scatter(radgpFORRAT,rgp,label=\"All_structures\",s=30)\n",
    "\n",
    "                    ax3.annotate(s=st,fontsize=12,xy=(0.01,0.04),xycoords=\"axes fraction\")\n",
    "                    ax3.set_yscale('log')\n",
    "                    ax3.set_xscale('log')\n",
    "                    ax3.set_ylim(np.nanmin(rgp),np.nanmax(rgp))\n",
    "                    ax3.set_xlabel(\"Rad (pc)\",fontsize=12)\n",
    "                    ax3.set_ylabel(\"Linewidth Ratio (km^2/s^2/pc)\",fontsize=12)\n",
    "                    ax3.legend(prop={'size': 12})\n",
    "\n",
    "                    gp3 = np.where(lumFORRAT>0)\n",
    "                    lumFORRAT = lumFORRAT[gp3]\n",
    "                    rgpFORRAT = rgp[gp3]\n",
    "                    mom0FORRAT = mom0FORRAT[gp3]\n",
    "\n",
    "\n",
    "\n",
    "                    ax5 = pylab.subplot(5, 5, 4)\n",
    "                    ax6 = pylab.subplot(5, 5, 5)\n",
    "                    ax7 = pylab.subplot(5, 5, 6)\n",
    "\n",
    "\n",
    "\n",
    "                    xpconhh = ax5.scatter(radgpFORRAT,cgp,label=\"All_structures\",s=30,alpha=.7)\n",
    "                    ax5.set_yscale('log')\n",
    "                    ax5.set_xscale('log')\n",
    "                    ax5.set_xlabel(\"Size (pc)\",fontsize=12)\n",
    "                    ax5.set_ylabel(\"Column Density (#/cm^2 > 7e22)\",fontsize=12)\n",
    "                    ax5.legend(prop={'size': 12},loc=\"upper right\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    xspF2 = ax6.scatter(cgp,rgp,label=\"All_structures\",s=30,alpha=.7)\n",
    "                    pF2 = ax6.plot(xsCD,ysCD)\n",
    "\n",
    "                    ax6.set_yscale('log')\n",
    "                    ax6.set_xscale('log')\n",
    "                    ax6.set_ylim(np.nanmin(rgp),np.nanmax(rgp))\n",
    "                    ax6.set_xlabel(\"Column Density (#/cm^2 > 7e22)\",fontsize=12)\n",
    "                    ax6.set_ylabel(\"Linewidth Ratio (km^2/s^2/pc)\",fontsize=12)\n",
    "                    ax6.legend(prop={'size': 12},loc=\"upper right\")\n",
    "                    ax6.annotate(s=LineN,fontsize=10,xy=(0.01,0.89),xycoords=\"axes fraction\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    xspLu2 = ax7.scatter(radgp,lgp,label=\"All_structure Whole Data Set\",s=30,alpha=.7)\n",
    "                    pFLLu2 = ax7.plot(xsRL,ysRL)\n",
    "\n",
    "                    st = \"WDS, c = \"+ str(np.format_float_scientific(RLpopt[0],3))+\"+-\"+str(np.format_float_scientific(np.sqrt(RLpcov[0][0]),3))+\" d = \"+str(np.format_float_scientific(RLpopt[1],3))+\"+-\"+str(np.format_float_scientific(np.sqrt(RLpcov[1][1]),3))\n",
    "                    ax7.annotate(s='L = $c*R^d$',fontsize=12,xy=(0.01,0.13),xycoords=\"axes fraction\")\n",
    "                    ax7.annotate(s=st,fontsize=12,xy=(0.01,0.04),xycoords=\"axes fraction\")\n",
    "\n",
    "                    ax7.set_yscale('log')\n",
    "                    ax7.set_xscale('log')\n",
    "                    ax7.set_ylim(np.nanmin(lgp),np.nanmax(lgp))\n",
    "                    ax7.set_xlabel(\"Radius (pc)\",fontsize=9)\n",
    "                    ax7.set_ylabel(\"Luminosity (erg)\",fontsize=9)\n",
    "                    ax7.legend(prop={'size': 12},loc=\"upper right\")\n",
    "                    ax7.annotate(s=LineN,fontsize=10,xy=(0.01,0.89),xycoords=\"axes fraction\")\n",
    "\n",
    "\n",
    "                    axLam = pylab.subplot(5, 5, 11)\n",
    "                    lum_rat = axLam.scatter(lumFORRAT/radgpFORRAT**2,rgpFORRAT,label=\"All_structure  \",s=30,alpha=.7)\n",
    "                    #Off by factors for area, simply using r^2\n",
    "\n",
    "                    axLam.set_yscale('log')\n",
    "                    axLam.set_xscale('log')\n",
    "                    axLam.set_xlabel(\"Lum/R^2 (erg/pc^2)\",fontsize=9)\n",
    "                    axLam.set_ylabel(\"Linewidth Ratio (km/s)^2/pc\",fontsize=9)\n",
    "                    axLam.legend(prop={'size': 12},loc=\"upper right\")\n",
    "                    axLam.annotate(s=LineN,fontsize=10,xy=(0.01,0.89),xycoords=\"axes fraction\")\n",
    "\n",
    "\n",
    "\n",
    "                    axDelta = pylab.subplot(5, 5, 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    gp4=np.where(MOM0FLUXcon>0)\n",
    "                    mom0FORFlux=MOM0FLUXcon[gp4]\n",
    "                    radgpFORFlux=Rcon[gp4]*10**6\n",
    "                    rgpFORFlux=Scon[gp4]**2/Rcon[gp4]/10**6\n",
    "\n",
    "                    mom0_rat = axDelta.scatter(mom0FORFlux/radgpFORFlux**2,rgpFORFlux,label=\"All_structure  \",s=30,alpha=.7)\n",
    "                    #Off by factors for area, simply using r^2\n",
    "\n",
    "                    axDelta.set_yscale('log')\n",
    "                    axDelta.set_xscale('log')\n",
    "                    axDelta.set_xlabel(\"Mom0 Flux/pc^2 (K km/s / R^2)\",fontsize=9)\n",
    "                    axDelta.set_ylabel(\"Linewidth Ratio (km/s)^2/pc\",fontsize=9)\n",
    "                    axDelta.legend(prop={'size': 12},loc=\"upper right\")\n",
    "                    axDelta.annotate(s=LineN,fontsize=10,xy=(0.01,0.89),xycoords=\"axes fraction\")\n",
    "\n",
    "\n",
    "                    pylab.show()\n",
    "\n",
    "\n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    v1 = d.viewer()\n",
    "                    v1.show()\n",
    "\n",
    "                    #Must use text because np load is broken\n",
    "                    if(Abs_Level==\"All\"):\n",
    "                        Suffix=''\n",
    "                    if(Abs_Level==\"None\"):\n",
    "                        Suffix='_NA'\n",
    "                    if(Abs_Level==\"No Clusters\"):\n",
    "                        Suffix='_No_Clusters'\n",
    "                    if(Abs_Level==\"None (m)\"):\n",
    "                        Suffix='None_m'\n",
    "                    if(Abs_Level==\"None All Channels\"):\n",
    "                        Suffix='None_All_Channels'\n",
    "                        \n",
    "                    \n",
    "                    \n",
    "\n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameCol+\"_Leaves\"+Suffix), CD[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameCol+\"_Branches\"+Suffix), CD[1],fmt='%s')\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameLum+\"_Leaves\"+Suffix), Lumin[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameLum+\"_Branches\"+Suffix), Lumin[1],fmt='%s')\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameS+\"_Leaves\"+Suffix), Sigmas[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameS+\"_Branches\"+Suffix), Sigmas[1],fmt='%s')\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameR+\"_Leaves\"+Suffix), Rads[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameR+\"_Branches\"+Suffix), Rads[1],fmt='%s')\n",
    "\n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameFlux+\"_Leaves\"+Suffix), MOM0FLUX[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameFlux+\"_Branches\"+Suffix), MOM0FLUX[1],fmt='%s')\n",
    "\n",
    "\n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,Cube_Name_Save+\"Distances_Leaves\"+Suffix), Distances[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,Cube_Name_Save+\"Distances_Branches\"+Suffix), Distances[1],fmt='%s')\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,Cube_Name_Save+\"V_err_Leaves\"+Suffix), V_err[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,Cube_Name_Save+\"V_err_Branches\"+Suffix), V_err[1],fmt='%s')\n",
    "\n",
    "                    SIDS=np.concatenate((SIDS[0],SIDS[1]))\n",
    "\n",
    "                    print(SIDS[len(SIDS)-3:len(SIDS)-1])\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    print(kl,km,k3,k4)\n",
    "                    print(\"Failed\")\n",
    "                    print(\"-\"*60)\n",
    "                    traceback.print_exc(file=sys.stdout)\n",
    "                    \n",
    "                    if(Abs_Level==\"All\"):\n",
    "                        Suffix=''\n",
    "                    if(Abs_Level==\"None\"):\n",
    "                        Suffix='_NA'\n",
    "                    if(Abs_Level==\"No Clusters\"):\n",
    "                        Suffix='_No_Clusters'\n",
    "                    if(Abs_Level==\"None (m)\"):\n",
    "                        Suffix='None_m'\n",
    "                    if(Abs_Level==\"None All Channels\"):\n",
    "                        Suffix='None_All_Channels'\n",
    "                    nans = [[np.nan,np.nan],[np.nan,np.nan]]\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameCol+\"_Leaves\"+Suffix), nans[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameCol+\"_Branches\"+Suffix), nans[1],fmt='%s')\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameLum+\"_Leaves\"+Suffix), nans[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameLum+\"_Branches\"+Suffix), nans[1],fmt='%s')\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameS+\"_Leaves\"+Suffix), nans[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameS+\"_Branches\"+Suffix), nans[1],fmt='%s')\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameR+\"_Leaves\"+Suffix), nans[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameR+\"_Branches\"+Suffix), nans[1],fmt='%s')\n",
    "\n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameFlux+\"_Leaves\"+Suffix), nans[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameFlux+\"_Branches\"+Suffix), nans[1],fmt='%s')\n",
    "\n",
    "\n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,Cube_Name_Save+\"Distances_Leaves\"+Suffix), nans[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,Cube_Name_Save+\"Distances_Branches\"+Suffix), nans[1],fmt='%s')\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,Cube_Name_Save+\"V_err_Leaves\"+Suffix), nans[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,Cube_Name_Save+\"V_err_Branches\"+Suffix), nans[1],fmt='%s')\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609597e5-d7e1-4b2b-9072-b6ff3be535fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#CO \n",
    "\n",
    "\n",
    "Num=5\n",
    "Overlaps=0#4\n",
    "Ram_Limiter=1#What percent of the cube my ram can handle\n",
    "LineN=\"CO-J3-2_New_4.3\"\n",
    "Name = \"CO 3-2_Abs_New_4.3\"\n",
    "name = \"CO_3_2_CM_Contours_DS_10_Abs_New_4.3.jpeg\"\n",
    "Num_per_kg= 6.0221409*10**23/(2.8*10**-3)#6.0221409*10**23/29.0180*10**-3#num/kg for h2\n",
    "\n",
    "\n",
    "try:\n",
    "    Names=list(np.load(\"Names_New.npy\"))\n",
    "except:\n",
    "    Names=list(np.load(\"Names.npy\"))\n",
    "Names[Num] = Name\n",
    "\n",
    "\n",
    "np.save(\"Names_New\",Names)\n",
    "\n",
    "print(Name)\n",
    "\n",
    "\n",
    "path =\"Cropped_NGC_Spliced_Reprojected_Whole_CO_32_70x360pc_4.3.fits\"\n",
    "\n",
    "pathCont = 'Continuum_Reproject.fits'\n",
    "\n",
    "#Continuum image\n",
    "scCont = spectral_cube.Projection.from_hdu(fits.open(pathCont)[0])\n",
    "#Put this up here for the column density map\n",
    "metadata = {}\n",
    "metadata[\"distance\"] = 3.5*u.Mpc\n",
    "arc_per_pix_yc =  abs(scCont.hdu.header[\"CDELT1\"]*3600.0 * u.arcsec)/u.pix\n",
    "arc_per_pix_xc =  abs(scCont.hdu.header[\"CDELT2\"]*3600.0 * u.arcsec)/u.pix\n",
    "beam_majorc =  scCont.hdu.header[\"BMAJ\"]*3600.0 * u.arcsec\n",
    "beam_minorc =  scCont.hdu.header[\"BMIN\"]*3600.0 * u.arcsec\n",
    "beam_area_ratioc = beam_minorc*beam_majorc/arc_per_pix_yc/arc_per_pix_xc*1.13309#beam_area_ratioc = beam_minorc*beam_majorc/arc_per_pix_yc/arc_per_pix_xc#This is for FWHM, use *(2*np.sqrt(2*np.log(2)))**2#For gaussian beam\n",
    "metadata['beam_area_ratioc']=beam_area_ratioc\n",
    "pc_per_pixelc = abs(scCont.hdu.header[\"CDELT1\"])/180*np.pi*metadata['distance']/u.Mpc\n",
    "print(pc_per_pixelc,\"MPC per pix\")\n",
    "\n",
    "#Make subcube\n",
    "\n",
    "Qp = SpectralCube.read(path).with_spectral_unit(u.km/u.s,velocity_convention=\"radio\") \n",
    "Qp.allow_huge_operations=True\n",
    "\n",
    "Q = Qp.to(u.K)#Jy to Kelvin\n",
    "\n",
    "sc = Q.unmasked_copy()\n",
    "\n",
    "\n",
    "\n",
    "scW = sc.wcs[:][:][0]\n",
    "dat = sc.hdu.data[int(len(sc)*((1-Ram_Limiter)/2)):int(len(sc)*(Ram_Limiter + (1-Ram_Limiter)/2)),:,:]\n",
    "scn = sc[int(len(sc)*((1-Ram_Limiter)/2)):int(len(sc)*(Ram_Limiter + (1-Ram_Limiter)/2)),:,:]\n",
    "scF = scn\n",
    "datn = dat\n",
    "#scF = scn[:,400:700,600:360]#Crop(scn,scn.wcs[:][:][0],cen_p1,cen_p2,0,False)\n",
    "#datn = dat[:,400:700,600:360]#Crop(dat,scn.wcs[:][:][0],cen_p1,cen_p2,0,False\n",
    "\n",
    "#m=.115\n",
    "\n",
    "#print(m,\"Presumed Noise (K)\")\n",
    "\n",
    "#Continuum image\n",
    "scCont = spectral_cube.Projection.from_hdu(fits.open(pathCont)[0])\n",
    "#Do the same thing to the continuum image\n",
    "scCont.allow_huge_operations=True\n",
    "scContW = scCont.reproject(scF.moment0().header)\n",
    "#m=.115\n",
    "\n",
    "\n",
    "scW = sc.wcs[:][:][0]\n",
    "\n",
    "cen_p1 = SkyCoord('00h47m33.9s', '-25d17m26.8s', frame='icrs')\n",
    "cen_p2 = SkyCoord('00h47m32.6s', '-25d17m10.2s', frame='icrs')\n",
    "\n",
    "\n",
    "#Do the same thing to the continuum image\n",
    "scCont.allow_huge_operations=True\n",
    "scContW = scCont.reproject(scF.moment0().header)\n",
    "Continuum_Data  =scContW.hdu.data\n",
    "scWCS = scF.wcs[:][:][0]\n",
    "\n",
    "moment_0_sub  = scF.to(u.K).moment(order=0,how='slice')            # Calculate the Moment 0 map \n",
    "\n",
    "cSD = (Flux_to_Mass(scContW.hdu.data*u.Jy/u.beam/beam_area_ratioc*u.pix**2*u.beam)/(pc_per_pixelc*10**6*3.086*10**18*u.cm)**2)*(1.989*10**30*u.kg/u.M_sun)*Num_per_kg/u.kg #Flux goes to luminosity for a gaussian beam and goes to column density for square pixels, mass goes to kg to number\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rm=moment_0_sub.hdu.data/cSD\n",
    "rmU = rm*u.K*u.km/u.s#Just put back in the units\n",
    "rmU = np.array(rmU /(u.K*u.km/u.s)/u.cm**2*10**22,dtype='float64')#Now remove them all\n",
    "\n",
    "######ratio\n",
    "   \n",
    "bp = np.where(cSD<=7*10**22/u.cm**2)\n",
    "bp2 = np.where( moment_0_sub.hdu.data < .22)\n",
    "Continuum_Data[bp] = np.nan\n",
    "cSD[bp]=np.nan\n",
    "rmU[bp]=np.nan\n",
    "rmU[bp2]=np.nan\n",
    "\n",
    "Non_nan=((datn[0,:,:]>0)  | (datn[0,:,:]<0 ))\n",
    "\n",
    "\n",
    "m = (np.nanstd(datn[0,:,:],where= Non_nan)) #Noise K\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(1,figsize=(40,40))\n",
    "for i in range(8):\n",
    "    datnPrime=np.copy(datn)\n",
    "    scFPrime = SpectralCube(data=datnPrime,header=scF.header,wcs=scF.wcs)\n",
    "    if(i==3):\n",
    "        Abs_Level = \"No absorption masking\"\n",
    "        scFPrime = SpectralCube(data=datnPrime,header=scF.header,wcs=scF.wcs)\n",
    "        pass\n",
    "    if(i==4):\n",
    "        datnPrime[np.where(datn<0)]=np.nan\n",
    "        scFPrime = SpectralCube(data=datnPrime,header=scF.header,wcs=scF.wcs)\n",
    "        Abs_Level = \"All negative values masking\"\n",
    "    if(i==5):\n",
    "        datnPrime[np.where(datn<-m)]=np.nan\n",
    "        Abs_Level = \"1 sig negative values masking\"\n",
    "        scFPrime = SpectralCube(data=datnPrime,header=scF.header,wcs=scF.wcs)\n",
    "    if(i==6):\n",
    "        for lmi in range(len(datn)):\n",
    "            bpP = np.where(datn[lmi]<-3*m)\n",
    "            for lmj in range(len(datn)):\n",
    "                datnPrime[lmj][bpP]=np.nan\n",
    "        Abs_Level = \"3 sig negative masked in all channels\"\n",
    "        scFPrime = SpectralCube(data=datnPrime,header=scF.header,wcs=scF.wcs)\n",
    "    if(i==7):\n",
    "        IDs,RAs,Decs,HWHM  =    np.genfromtxt(\"NGC_Clusters_\"+\"IDs\"+\"\",dtype=type(\"12h23.14s\")),np.genfromtxt(\"NGC_Clusters_\"+\"RAs\"+\"\",dtype=type(\"12h23.14s\")),np.genfromtxt(\"NGC_Clusters_\"+\"Decs\"+\"\",dtype=type(\"12h23.14s\")),np.genfromtxt(\"NGC_Clusters_\"+\"HWHM\"+\"\")\n",
    "\n",
    "        datnPrime=  Mask_Clusters_NGC(HWHM,scWCS,scF.hdu.header,datn,RAs,Decs,One_Pc=False,One_Pc_Size=1,HWHM_Fac=3)\n",
    "        scFPrime = SpectralCube(data=datnPrime,header=scF.header,wcs=scF.wcs)\n",
    "        Abs_Level = \"34 clusters masked\"\n",
    "    Mom0_Data = scFPrime.moment0().hdu.data\n",
    "    print(m,\"Unmatched Noise (K)\")\n",
    "\n",
    "\n",
    "    #Make_Plot(\"Column Density\",\"(#/cm^2)\",cSD,float(np.nanmin(cSD*u.cm**2)),float(np.nanmax(cSD*u.cm**2)),scCont.wcs,1,1,1,True)\n",
    "    #Make_Plot((LineN+\" Moment 0/Column Density\"),\"Moment 0 over Column Density of the Continuum (K km/s/(#/cm^2))\",rmU,np.nanmean(rmU)*.5,abs(np.nanmean(rmU))*8,scCont.wcs,1,1,1,True)\n",
    "    print(i)\n",
    "    if i ==0:\n",
    "        Abs_Level = \"\"\n",
    "        scContPrime = scCont.to(u.Jy/u.beam)\n",
    "        ax = pylab.subplot(8,1,i+1,projection=scF.wcs[:][:][0]) \n",
    "        RA = ax.coords[0]                                                                  # \n",
    "        Dec = ax.coords[1]\n",
    "        im = pylab.imshow(scContPrime.hdu.data,vmin=np.nanmin(scContPrime.hdu.data),vmax=np.nanmax(scContPrime.hdu.data))\n",
    "        RA.set_ticks(size=-3)                                                                                      \n",
    "        Dec.set_ticks(size=-3) \n",
    "        RA.set_ticklabel(exclude_overlapping=True) \n",
    "        Dec.set_ticklabel(exclude_overlapping=True)                                                                                     \n",
    "        pylab.xlabel('Right Ascension',fontsize=20,labelpad=1)                               \n",
    "        pylab.ylabel('Declination',fontsize=20,labelpad=1)\n",
    "        ax.tick_params(axis = 'both', which = 'major', labelsize = 15)    \n",
    "        cb=pylab.colorbar(im,fraction=.1,pad=0.0)                                     \n",
    "        #cb.set_label(label=LineN+\" \"+Abs_Level+\" 850um (Jy/Beam)\",fontsize=12,rotation=260,labelpad=10) \n",
    "        cb.set_label(label=\" 850um (Jy/Beam)\",fontsize=12,rotation=270,labelpad=10) \n",
    "        s=LineN+\" \"+Abs_Level+\" 850um (Jy/Beam)\"\n",
    "        ax.set_title(s, fontsize=12)\n",
    "        cb.ax.tick_params(which = 'major', labelsize = 10)   \n",
    "        #pylab.annotate(s=Name2,fontsize=10,xy=(pos1,pos2),xycoords=\"axes fraction\") \n",
    "    elif i ==1:\n",
    "        Abs_Level = \"\"\n",
    "        scContPrime = scCont.to(u.K)\n",
    "        ax = pylab.subplot(8,1,i+1,projection=scF.wcs[:][:][0]) \n",
    "        RA = ax.coords[0]                                                                  # \n",
    "        Dec = ax.coords[1]\n",
    "        im = pylab.imshow(scContPrime.hdu.data,vmin=np.nanmin(scContPrime.hdu.data),vmax=np.nanmax(scContPrime.hdu.data))\n",
    "        RA.set_ticks(size=-3)                                                                                      \n",
    "        Dec.set_ticks(size=-3) \n",
    "        RA.set_ticklabel(exclude_overlapping=True) \n",
    "        Dec.set_ticklabel(exclude_overlapping=True)                                                                                     \n",
    "        pylab.xlabel('Right Ascension',fontsize=20,labelpad=1)                               \n",
    "        pylab.ylabel('Declination',fontsize=20,labelpad=1)\n",
    "        ax.tick_params(axis = 'both', which = 'major', labelsize = 15)    \n",
    "        cb=pylab.colorbar(im,fraction=.1,pad=0.0)                                     \n",
    "        #cb.set_label(label=LineN+\" \"+Abs_Level+\" 850um (K)\",fontsize=12,rotation=260,labelpad=10) \n",
    "        s=LineN+\" \"+Abs_Level+\" 850um (K)\"\n",
    "        ax.set_title(s, fontsize=12)\n",
    "        cb.set_label(label=\" 850um (K)\",fontsize=12,rotation=270,labelpad=10) \n",
    "        cb.ax.tick_params(which = 'major', labelsize = 10)   \n",
    "        #pylab.annotate(s=Name2,fontsize=10,xy=(pos1,pos2),xycoords=\"axes fraction\") \n",
    "    elif i ==2:\n",
    "        Abs_Level = \"\"\n",
    "        ax = pylab.subplot(8,1,i+1,projection=scF.wcs[:][:][0]) \n",
    "        RA = ax.coords[0]                                                                  # \n",
    "        Dec = ax.coords[1]\n",
    "        im = pylab.imshow(cSD,vmin=np.nanmin(cSD*u.cm**2),vmax=np.nanmax(cSD*u.cm**2))\n",
    "        RA.set_ticks(size=-3)                                                                                      \n",
    "        Dec.set_ticks(size=-3) \n",
    "        RA.set_ticklabel(exclude_overlapping=True) \n",
    "        Dec.set_ticklabel(exclude_overlapping=True)                                                                                     \n",
    "        pylab.xlabel('Right Ascension',fontsize=20,labelpad=1)                               \n",
    "        pylab.ylabel('Declination',fontsize=20,labelpad=1)\n",
    "        ax.tick_params(axis = 'both', which = 'major', labelsize = 15)    \n",
    "        cb=pylab.colorbar(im,fraction=.1,pad=0.0)                                     \n",
    "        #cb.set_label(label=LineN+\" \"+Abs_Level+\" 850um continuum derived CD (#/cm^2)\",fontsize=12,rotation=260,labelpad=10) \n",
    "        s=LineN+\" \"+Abs_Level+\" 850um continuum \"\n",
    "        ax.set_title(s, fontsize=12)\n",
    "        cb.set_label(label=\" 850um continuum derived CD (#/cm^2)\",fontsize=12,rotation=270,labelpad=10) \n",
    "        cb.ax.tick_params(which = 'major', labelsize = 12)   \n",
    "        #pylab.annotate(s=Name2,fontsize=10,xy=(pos1,pos2),xycoords=\"axes fraction\") \n",
    "    else:\n",
    "        print(\"L\",np.shape(scF.wcs[:][:][0]),np.shape(datnPrime),np.shape(datn))\n",
    "        ax = pylab.subplot(8,1,i+1,projection=scF.wcs[:][:][0]) \n",
    "        RA = ax.coords[0]                                                                  # \n",
    "        Dec = ax.coords[1]\n",
    "        im = pylab.imshow(Mom0_Data,vmin=np.nanmin(scF.moment0().hdu.data),vmax=np.nanmax(scF.moment0().hdu.data))\n",
    "        RA.set_ticks(size=-3)                                                                                      \n",
    "        Dec.set_ticks(size=-3) \n",
    "        RA.set_ticklabel(exclude_overlapping=True) \n",
    "        Dec.set_ticklabel(exclude_overlapping=True)                                                                                     \n",
    "        pylab.xlabel('Right Ascension',fontsize=20,labelpad=1)                               \n",
    "        pylab.ylabel('Declination',fontsize=20,labelpad=1)\n",
    "        ax.tick_params(axis = 'both', which = 'major', labelsize = 15)    \n",
    "        cb=pylab.colorbar(im,fraction=.1,pad=0.0)                                     \n",
    "        #cb.set_label(label=LineN+\" \"+Abs_Level+\" Momennt 0 (K km/s)\",fontsize=12,rotation=0,labelpad=10) \n",
    "        s=LineN+\" \"+Abs_Level+\" Momennt 0 (K km/s)\"\n",
    "        ax.set_title(s, fontsize=12)\n",
    "        cb.set_label(label=\" Momennt 0 (K km/s)\",fontsize=12,rotation=270,labelpad=10) \n",
    "        cb.ax.tick_params(which = 'major', labelsize = 12)   \n",
    "        #pylab.annotate(s=Name2,fontsize=10,xy=(pos1,pos2),xycoords=\"axes fraction\")  \n",
    "plt.tight_layout(h_pad=10)\n",
    "fig.savefig(bbox_inches='tight',fname=\"NGC_CO_3_2_4.3_All_abs_Levels.jpeg\")\n",
    "pylab.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2034f1b4-216f-4092-b9ab-b63d9f77427b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#Find Gaussians From Scouse\n",
    "\n",
    "\n",
    "datadirectory = './' # path to whereever you put the data\n",
    "outputdir = './' # path to wherever you would like scouse to put the output\n",
    "filename = '4.3pc_beam__CMZ_CO_J3_2_4.3_start70x360pc_3.9599999999999995LH_vel_res' # the filename of the data, without the '.fits' extension - e.g. 'n2h+10_37'\n",
    "\n",
    "# config files can be found in outputdir/config_files/ and can be updated there\n",
    "config_file=scouse.run_setup(filename, datadirectory, outputdir=outputdir)\n",
    "\n",
    "# running scouse\n",
    "s = scouse.stage_1(config=config_file, interactive=False) # GUI based \n",
    "s = scouse.stage_2(config=config_file, refit=False)\n",
    "s = scouse.stage_3(config=config_file)\n",
    "s = scouse.stage_4(config=config_file, bitesize=True)\n",
    "\n",
    "output_ascii_indiv(s, outputdir)\n",
    "\n",
    "'''\n",
    "'''\n",
    "\n",
    "\n",
    "for kl in range(iterations):\n",
    "      \n",
    "    Prime_Beam = Min_res*((kl*iter_factor+1))#\n",
    "    print(Prime_Beam)\n",
    "    \n",
    "    \n",
    "    for km in range(iterations):\n",
    "        vel_prime = min_vel*((km*iter_factor+1))\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        try:\n",
    "            Names=list(np.load(\"Names_New_All_Kinds.npy\",allow_pickle=True))\n",
    "        except Exception as e:\n",
    "\n",
    "            print(e)\n",
    "            print(\"initialized names\")\n",
    "            Names = list(np.empty((20,iterations,iterations,iterations,iterations),dtype=object))\n",
    "                        \n",
    "\n",
    "        #Continuum image\n",
    "        scCont = spectral_cube.Projection.from_hdu(fits.open(pathCont)[0])\n",
    "        #Put this up here for the column density map\n",
    "        metadata = {}\n",
    "        metadata[\"distance\"] = 3.5*u.Mpc\n",
    "        arc_per_pix_yc =  abs(scCont.hdu.header[\"CDELT1\"]*3600.0 * u.arcsec)/u.pix\n",
    "        arc_per_pix_xc =  abs(scCont.hdu.header[\"CDELT2\"]*3600.0 * u.arcsec)/u.pix\n",
    "        beam_majorc =  scCont.hdu.header[\"BMAJ\"]*3600.0 * u.arcsec\n",
    "        beam_minorc =  scCont.hdu.header[\"BMIN\"]*3600.0 * u.arcsec\n",
    "        beam_area_ratioc = beam_minorc*beam_majorc/arc_per_pix_yc/arc_per_pix_xc*1.13309#beam_area_ratioc = beam_minorc*beam_majorc/arc_per_pix_yc/arc_per_pix_xc#This is for FWHM, use *(2*np.sqrt(2*np.log(2)))**2#For gaussian beam\n",
    "        metadata['beam_area_ratioc']=beam_area_ratioc\n",
    "        pc_per_pixelc = abs(scCont.hdu.header[\"CDELT1\"])/180*np.pi*metadata['distance']/u.Mpc\n",
    "        print(pc_per_pixelc,\"MPC per pix\")\n",
    "\n",
    "        #Make subcube\n",
    "\n",
    "\n",
    "\n",
    "        Cube_Name_Load = \"Cropped_\"+str(Prime_Beam.value)+\"pc_beam_\"+Line_Name+str(FOV[0])+\"x\"+str(FOV[1])+'pc_'+str(vel_prime)+'_vel_res.fits'\n",
    "        path = Cube_Name_Load\n",
    "        \n",
    "        Qp = SpectralCube.read(path).with_spectral_unit(u.km/u.s,velocity_convention=\"radio\") \n",
    "        Qp.allow_huge_operations=True\n",
    "\n",
    "        Q = Qp.to(u.K)#Jy to Kelvin\n",
    "\n",
    "        sc = Q.unmasked_copy()\n",
    "\n",
    "\n",
    "\n",
    "        scW = sc.wcs[:][:][0]\n",
    "        dat = sc.hdu.data[int(len(sc)*((1-Ram_Limiter)/2)):int(len(sc)*(Ram_Limiter + (1-Ram_Limiter)/2)),:,:]\n",
    "        scn = sc[int(len(sc)*((1-Ram_Limiter)/2)):int(len(sc)*(Ram_Limiter + (1-Ram_Limiter)/2)),:,:]\n",
    "        scF = scn\n",
    "        datn = dat\n",
    "\n",
    "\n",
    "        #m=.115\n",
    "\n",
    "        #print(m,\"Presumed Noise (K)\")\n",
    "\n",
    "        #Continuum image\n",
    "        scCont = spectral_cube.Projection.from_hdu(fits.open(pathCont)[0])\n",
    "        #Do the same thing to the continuum image\n",
    "        scCont.allow_huge_operations=True\n",
    "        scContW = scCont.reproject(scF.moment0().header)\n",
    "        #m=.115\n",
    "\n",
    "\n",
    "        scW = sc.wcs[:][:][0]\n",
    "\n",
    "        cen_p1 = SkyCoord('00h47m33.9s', '-25d17m26.8s', frame='icrs')\n",
    "        cen_p2 = SkyCoord('00h47m32.6s', '-25d17m10.2s', frame='icrs')\n",
    "\n",
    "\n",
    "        #Do the same thing to the continuum image\n",
    "        scCont.allow_huge_operations=True\n",
    "        scContW = scCont.reproject(scF.moment0().header)\n",
    "        Continuum_Data  =scContW.hdu.data\n",
    "        scWCS = scF.wcs[:][:][0]\n",
    "\n",
    "        moment_0_sub  = scF.to(u.K).moment(order=0,how='slice')            # Calculate the Moment 0 map \n",
    "\n",
    "\n",
    "\n",
    "        ######Moment 0 for both\n",
    "        ######and cont\n",
    "        Make_Plot((LineN+\" Moment 0\"),\"Moment 0 (K km/s)\",moment_0_sub.hdu.data,0,np.nanmax(moment_0_sub.hdu.data),moment_0_sub.wcs,1,1,1,True)\n",
    "\n",
    "\n",
    "        cSD = (Flux_to_Mass(scContW.hdu.data*u.Jy/u.beam/beam_area_ratioc*u.pix**2*u.beam)/(pc_per_pixelc*10**6*3.086*10**18*u.cm)**2)*(1.989*10**30*u.kg/u.M_sun)*Num_per_kg/u.kg #Flux goes to luminosity for a gaussian beam and goes to column density for square pixels, mass goes to kg to number\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        rm=moment_0_sub.hdu.data/cSD\n",
    "        rmU = rm*u.K*u.km/u.s#Just put back in the units\n",
    "        rmU = np.array(rmU /(u.K*u.km/u.s)/u.cm**2*10**22,dtype='float64')#Now remove them all\n",
    "\n",
    "        ######ratio\n",
    "\n",
    "        bp = np.where(cSD<=7*10**22/u.cm**2)\n",
    "        bp2 = np.where( moment_0_sub.hdu.data < .22)\n",
    "        Continuum_Data[bp] = np.nan\n",
    "        cSD[bp]=np.nan\n",
    "        rmU[bp]=np.nan\n",
    "        rmU[bp2]=np.nan\n",
    "\n",
    "        Non_nan=((datn[0,:,:]>0)  | (datn[0,:,:]<0 ))\n",
    "\n",
    "        m = (np.nanstd(datn[0,:,:],where= Non_nan)) #Noise K\n",
    "        if(Abs_Level==\"All\"):\n",
    "            pass\n",
    "        if(Abs_Level==\"None\"):\n",
    "            datn[np.where(datn<0)]=np.nan\n",
    "        if(Abs_Level==\"None (m)\"):\n",
    "            datn[np.where(datn<-m)]=np.nan\n",
    "        if(Abs_Level==\"None All Channels\"):\n",
    "            for lmi in range(len(datn)):\n",
    "                bpP = np.where(datn[lmi]<-m)\n",
    "                for lmj in range(len(datn)):\n",
    "                    datn[lmj][bpP]=np.nan\n",
    "        if(Abs_Level==\"No Clusters\"):\n",
    "            IDs,RAs,Decs,HWHM  =    np.genfromtxt(\"NGC_Clusters_\"+\"IDs\"+\"\",dtype=type(\"12h23.14s\")),np.genfromtxt(\"NGC_Clusters_\"+\"RAs\"+\"\",dtype=type(\"12h23.14s\")),np.genfromtxt(\"NGC_Clusters_\"+\"Decs\"+\"\",dtype=type(\"12h23.14s\")),np.genfromtxt(\"NGC_Clusters_\"+\"HWHM\"+\"\")\n",
    "\n",
    "            datn=  Mask_Clusters_NGC(HWHM,scWCS,scF.hdu.header,datn,RAs,Decs,One_Pc=False,One_Pc_Size=1,HWHM_Fac=3)\n",
    "\n",
    "        print(m,\"Unmatched Noise (K)\", \"Abs = \",Abs_Level)\n",
    "\n",
    "\n",
    "        Make_Plot(\"Column Density\",\"(#/cm^2)\",cSD,float(np.nanmin(cSD*u.cm**2)),float(np.nanmax(cSD*u.cm**2)),scCont.wcs,1,1,1,True)\n",
    "        Make_Plot((LineN+\" Moment 0/Column Density\"),\"Moment 0 over Column Density of the Continuum (K km/s/(#/cm^2))\",rmU,np.nanmean(rmU)*.5,abs(np.nanmean(rmU))*8,scCont.wcs,1,1,1,True)\n",
    "\n",
    "        print(np.nanmin(rmU))\n",
    "\n",
    "\n",
    "\n",
    "        header = scF.hdu.header\n",
    "        print()\n",
    "        #make metadata for the dendrogram\n",
    "\n",
    "        try:\n",
    "            freq = header[\"RESTFREQ\"]*u.Hz#\n",
    "            metadata['wavelength']=299792458*u.m/header[\"RESTFREQ\"]#\n",
    "            print(1,freq,metadata['wavelength'])\n",
    "        except:\n",
    "            freq = header[\"RESTFRQ\"]*u.Hz#\n",
    "            metadata['wavelength']=299792458*u.m/header[\"RESTFRQ\"]#\n",
    "        metadata['data_unit'] =scF[0][0][0].unit# header['BUNIT']\n",
    "        metadata['arc_per_pix_y'] =  abs(header[\"CDELT1\"]*3600.0 * u.arcsec)/u.pix\n",
    "        metadata['arc_per_pix_x'] =  abs(header[\"CDELT2\"]*3600.0 * u.arcsec)/u.pix\n",
    "\n",
    "\n",
    "        metadata['beam_major'] =  header[\"BMAJ\"]*3600.0 * u.arcsec\n",
    "        metadata['beam_minor'] =  header[\"BMIN\"]*3600.0 * u.arcsec\n",
    "        beam_area_ratio = metadata['beam_minor']*metadata['beam_major']/metadata['arc_per_pix_y']/metadata['arc_per_pix_x']*1.13309#beam_area_ratio = metadata['beam_minor']*metadata['beam_major']/metadata['arc_per_pix_y']/metadata['arc_per_pix_x']#This is for FWHM, use *(2*np.sqrt(2*np.log(2)))**2#For gaussian beam\n",
    "        metadata['beam_area_ratio']=beam_area_ratio\n",
    "        metadata['spatial_scale'] = np.sqrt(abs(header[\"CDELT1\"])*u.degree**2*abs(header[\"CDELT2\"]))\n",
    "        area_res = abs(header[\"CDELT1\"])*abs(header[\"CDELT2\"])*(np.pi/180*3.5)**2#mpc^2/pix^2\n",
    "        print(area_res,type(area_res))\n",
    "\n",
    "        print(metadata['beam_minor'],metadata['beam_major'])\n",
    "        print(beam_area_ratio)\n",
    "        #metadata[\"wcs\"] = wcs\n",
    "        metadata[\"velocity_scale\"] = abs(header[\"CDELT3\"])*u.km/u.s#u.km/u.s\n",
    "\n",
    "        metadata[\"vaxis\"]=0\n",
    "        metadata[\"wcsu\"]=scF.wcs\n",
    "\n",
    "\n",
    "        for k3 in range(iterations):\n",
    "\n",
    "            beam_req = Min_beam_req*(k3+1)\n",
    "            \n",
    "            for k4 in range(iterations):\n",
    "                print(kl,km,k3,k4)\n",
    "                try:\n",
    "\n",
    "                    pix_thresh_factor = k4+1\n",
    "\n",
    "                    Cube_Name_Save = Name+\"_Cropped_\"+str(Prime_Beam.value)+\"pc_beam_\"+Line_Name+str(FOV[0])+\"x\"+str(FOV[1])+'pc_'+str(vel_prime)+'_vel_res_'+str(beam_req)+\"_beam_size_req_\"+str(pix_thresh_factor)+'_times_beam_pixels.fits'\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    Names[Num][kl][km][k3][k4] = Cube_Name_Save\n",
    "                    \n",
    "                    NameS = (Cube_Name_Save+\"Sigmas\")\n",
    "                    NameR = (Cube_Name_Save+\"Radii\")\n",
    "                    NameCol = (Cube_Name_Save+\"_Column\")\n",
    "                    NameLum = (Cube_Name_Save+\"_Luminosities\")\n",
    "\n",
    "                    NameFlux = (Cube_Name_Save+\"Flux_Dense\")\n",
    "                    NameRFF = (Cube_Name_Save+\"Rad_For_Flux\")\n",
    "                    \n",
    "                    print(Cube_Name_Save)\n",
    "                    \n",
    "                    np.save(\"Names_New_All_Kinds\",Names)\n",
    "\n",
    "                    \n",
    "                   \n",
    "\n",
    "\n",
    "                    d = astrodendro.Dendrogram.compute(datn,min_delta=m,min_value=m*5,min_npix=beam_area_ratio.value*pix_thresh_factor) #The main culprit\n",
    "                    #d = astrodendro.Dendrogram.compute(datn,min_delta=m,min_value=m*5,min_npix=beam_area_ratio.value) #The main culprit\n",
    "\n",
    "                    vel,RA,Dec = scF.world[:,0,0]\n",
    "                    Rads,Sigmas,CD,Lumin,SIDS,MOM0FLUX,Distances,V_err = Dendro_Arrays(d,datn,vel,Continuum_Data,metadata,beam_size=Prime_Beam.value,beam_req=beam_req)\n",
    "                    \n",
    "\n",
    "                    ##Analyze dendograms\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    fig = plt.figure(1,figsize=(40,40))\n",
    "\n",
    "\n",
    "                    axAlpha = pylab.subplot(5, 5, 7)\n",
    "                    axBeta = pylab.subplot(5, 5, 8)\n",
    "                    axGamma = pylab.subplot(5, 5, 9)\n",
    "                    axDelta = pylab.subplot(5, 5, 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    p1=d.plotter()\n",
    "                    p1.plot_tree(axAlpha)\n",
    "                    axAlpha.set_xlabel(\"Structure\")\n",
    "                    axAlpha.set_ylabel(\"Flux (K)\")\n",
    "                    axAlpha.set_title(\"Whole data set\")\n",
    "\n",
    "\n",
    "\n",
    "                    #Plot contours for the top ten clusters\n",
    "\n",
    "\n",
    "                    #scCropped =scF.moment0().hdu.data\n",
    "                    scCropped =scF.moment0().hdu.data\n",
    "                    scCropped[np.where(scF.moment0().hdu.data<.22)]=np.nan\n",
    "                    print(np.nanmean(np.nanstd(scF.moment0().hdu.data))*1)\n",
    "                    scCropped[bp]=np.nan\n",
    "                    axDelta = pylab.subplot(5,5,8,projection=scF.moment0().wcs)\n",
    "                    #axBeta.imshow(scCropped.moment0().hdu.data, origin='lower', interpolation='nearest', cmap=plt.cm.Blues,norm=colors.LogNorm(vmin=5))\n",
    "                    imBeta = axDelta.imshow(scCropped, origin='lower', interpolation='nearest', cmap=plt.cm.Blues,vmin=0,vmax = np.nanmax(scCropped)*.7 )\n",
    "\n",
    "\n",
    "\n",
    "                    ColumnCon= np.concatenate((CD[0],CD[1]))\n",
    "                    SIDScon = np.concatenate((SIDS[0],SIDS[1]))\n",
    "                    nth =0# sorted(CD[0])[len(CD[0])-20]\n",
    "\n",
    "                    G1 = True\n",
    "\n",
    "                    RA = axDelta.coords[0]                                                                  # \n",
    "                    Dec = axDelta.coords[1]\n",
    "\n",
    "                    RA.set_ticks(size=-3)                                                                                      \n",
    "                    Dec.set_ticks(size=-3) \n",
    "                    RA.set_ticklabel(exclude_overlapping=True) \n",
    "                    Dec.set_ticklabel(exclude_overlapping=True)                                                                                     \n",
    "                    pylab.xlabel('Right Ascension',fontsize=20,labelpad=1)                               \n",
    "                    pylab.ylabel('Declination',fontsize=20,labelpad=1)\n",
    "                    axDelta.tick_params(axis = 'both', which = 'major', labelsize = 15)    \n",
    "                    cb=pylab.colorbar(imBeta,fraction=0.016,pad=0.04)                                     \n",
    "                    cb.set_label(label=\"Moment 0 K km/s\",fontsize=10,rotation=270,labelpad=20) \n",
    "                    cb.ax.tick_params(which = 'major', labelsize = 10)   \n",
    "                    pylab.annotate(s=LineN,fontsize=10,xy=(.01,1.05),xycoords=\"axes fraction\",c=\"black\")  \n",
    "                    pylab.annotate(s=\"Highest Density\",fontsize=10,xy=(.31,1.05),xycoords=\"axes fraction\",c=\"red\")  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    pc_per_pixel = abs(header[\"CDELT1\"])/180*np.pi*metadata['distance']/u.Mpc\n",
    "\n",
    "                    sig_per_pixel=np.nan#metadata['spectral_resolution']/u.pix\n",
    "\n",
    "\n",
    "                    #Finds Size, Linewidth, Luminosity, and Column Density of a structure for each structure and returns them in [[][]] arrays [Leaves][Branches]\n",
    "\n",
    "\n",
    "                    from scipy.optimize import curve_fit\n",
    "                    from scipy.optimize import leastsq\n",
    "\n",
    "                    def func(R,a,b):\n",
    "                        return a*R**(b)\n",
    "                    try:\n",
    "                        popt, pcov = curve_fit(func, Rads[0]*10**6,Sigmas[0])\n",
    "                    except:\n",
    "                        popt, pcov = [np.nan,np.nan],[[np.nan,np.nan],[np.nan,np.nan]]\n",
    "                    try:\n",
    "                        poptB, pcovB = curve_fit(func,  Rads[1]*10**6,Sigmas[1])\n",
    "                    except:\n",
    "                        poptB, pcovB = [np.nan,np.nan],[[np.nan,np.nan],[np.nan,np.nan]]\n",
    "\n",
    "                    \n",
    "\n",
    "                    Rcon = np.concatenate((Rads[0],Rads[1]))\n",
    "\n",
    "                        \n",
    "                    Scon = np.concatenate((Sigmas[0],Sigmas[1]))\n",
    "                    Scon2 = np.concatenate((Sigmas[2],Sigmas[3]))\n",
    "                    print(np.shape(Rcon))\n",
    "                    \n",
    "                    poptCon, pcovCon = curve_fit(func, Rcon*10**6, Scon)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    xs=np.linspace(np.nanmin(Rcon*10**6),np.nanmax(Rcon*10**6),50)\n",
    "\n",
    "                    ysL,ysB,ysCon=func(xs,popt[0],popt[1]),func(xs,poptB[0],poptB[1]),func(xs,poptCon[0],poptCon[1])\n",
    "\n",
    "\n",
    "                    LuminCon = np.concatenate((Lumin[0],Lumin[1]))\n",
    "                    ColumnCon= np.concatenate((CD[0],CD[1]))\n",
    "\n",
    "                    MOM0FLUXcon = np.concatenate((MOM0FLUX[0],MOM0FLUX[1]))\n",
    "                    DistancesCon= np.concatenate((Distances[0],Distances[1]))\n",
    "                    print(Distances)\n",
    "\n",
    "                    #Radius Luminosity fit\n",
    "                    #Good pixels are places where the luminosity and therefore column density are above zero\n",
    "                    gp = np.where(LuminCon>0)\n",
    "                    print(np.shape(Rcon),np.shape(LuminCon))\n",
    "                    lgp = LuminCon[gp]\n",
    "                    radgp = Rcon[gp]*10**6\n",
    "\n",
    "                    gp2 = np.where(ColumnCon>0)\n",
    "                    cgp = ColumnCon[gp2]\n",
    "                    rgp=Scon[gp2]**2/Rcon[gp2]/10**6\n",
    "                    dgp=DistancesCon[gp2]\n",
    "                    radgpFORRAT = Rcon[gp2]*10**6\n",
    "                    siggpFORRAT = Scon[gp2]\n",
    "                    lumFORRAT = LuminCon[gp2]\n",
    "                    mom0FORRAT = MOM0FLUXcon[gp2]\n",
    "\n",
    "                    #print(np.shape(Rcon[gp]*10**6),np.shape(LuminCon[gp]))\n",
    "                    RLpopt,RLpcov = curve_fit(func, np.array(radgp,dtype='float64'),np.array(lgp,dtype='float64'),maxfev=999999,p0 = np.array([10**27,1],dtype='float64'),ftol = 10**-10)\n",
    "\n",
    "                    xsRL=np.linspace(np.nanmin(radgp),np.nanmax(radgp),50)\n",
    "                    ysRL = func(xsRL,RLpopt[0],RLpopt[1])\n",
    "                    #Column density to Size-linewidth\n",
    "                    CDpopt,CDpcov = curve_fit(func, np.array(cgp,dtype='float64') ,np.array(rgp,dtype='float64'),maxfev=9999099,p0 = np.array([10,.01],dtype='float64'),ftol = 10**-10)\n",
    "\n",
    "                    Dist_popt,Dist_pcov = curve_fit(func, np.array(DistancesCon,dtype='float64') ,np.array(Scon,dtype='float64'),maxfev=9999099,ftol = 10**-10)\n",
    "                    Dist_popt2,Dist_pcov2 = curve_fit(func, np.array(dgp,dtype='float64') ,np.array(rgp,dtype='float64'),maxfev=9999099,ftol = 10**-10)\n",
    "\n",
    "                    xsDist=np.linspace(np.nanmin(DistancesCon),np.nanmax(DistancesCon),50)\n",
    "                    xsDist2=np.linspace(np.nanmin(dgp),np.nanmax(dgp),50)\n",
    "                    ysDist=func(xsDist,Dist_popt[0],Dist_popt[1])\n",
    "                    ysDist2=func(xsDist2,Dist_popt2[0],Dist_popt2[1])\n",
    "\n",
    "\n",
    "                    axdis = pylab.subplot(5, 5, 12)\n",
    "                    axdis2 = pylab.subplot(5, 5, 13)\n",
    "                    axdis.scatter(DistancesCon,Scon)\n",
    "                    axdis2.scatter(dgp,rgp)\n",
    "                    axdis.plot(xsDist,ysDist)\n",
    "                    axdis2.plot(xsDist2,ysDist2)\n",
    "                    axdis2.set_yscale('log')\n",
    "                    axdis2.set_xscale('log')\n",
    "                    axdis.set_yscale('log')\n",
    "                    axdis.set_xscale('log')\n",
    "\n",
    "                    xsCD=np.linspace(np.nanmin(cgp),np.nanmax(cgp),50)\n",
    "                    ysCD = func(xsCD,CDpopt[0],CDpopt[1])\n",
    "\n",
    "\n",
    "                    print(poptCon,pcovCon,\"Size Linewidth All_structures:\")\n",
    "                    print(\"a = \",poptCon[0],\"+-\",np.sqrt(pcovCon[0][0]))\n",
    "                    print(\"b = \",poptCon[1],\"+-\",np.sqrt(pcovCon[1][1]))\n",
    "\n",
    "\n",
    "                    print(RLpopt,RLpcov,\"Radius to Luminosity:\")\n",
    "                    print(\"c = \",RLpopt[0],\"+-\",np.sqrt(RLpcov[0][0]))\n",
    "                    print(\"d = \",RLpopt[1],\"+-\",np.sqrt(RLpcov[1][1]))\n",
    "\n",
    "\n",
    "\n",
    "                    print(CDpopt,CDpcov,\"Column Density to linewidth^2/size:\")\n",
    "                    print(\"e = \",CDpopt[0],\"+-\",np.sqrt(CDpcov[0][0]))\n",
    "                    print(\"f = \",CDpopt[1],\"+-\",np.sqrt(CDpcov[1][1]))\n",
    "\n",
    "\n",
    "\n",
    "                    ax2 = pylab.subplot(5, 5, 1)\n",
    "                    ax3 = pylab.subplot(5, 5, 2)\n",
    "                    ax4 = pylab.subplot(5, 5, 3)\n",
    "\n",
    "                    xpcon = ax2.scatter(Rcon*10**6,Scon,label=\"All_structures\",s=30,alpha=.7)\n",
    "\n",
    "\n",
    "                    p = ax2.plot(xs,ysCon)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    st=\"WDS: a=\"+ str(np.format_float_scientific(poptCon[0],1))+\"+-\"+str(np.format_float_scientific(np.sqrt(pcovCon[0][0]),1))+\" b=\"+str(np.format_float_scientific(poptCon[1],1))+\"+-\"+str(np.format_float_scientific(np.sqrt(pcovCon[1][1]),2))\n",
    "                    ax2.annotate(s=st,fontsize=10,xy=(0.01,0.01),xycoords=\"axes fraction\")\n",
    "\n",
    "                    ax2.annotate(s=r'$\\sigma$ = $a*R^b$',fontsize=10,xy=(0.01,0.10),xycoords=\"axes fraction\")\n",
    "                    ax2.set_yscale('log')\n",
    "                    ax2.set_xscale('log')\n",
    "                    ax2.set_ylim(np.nanmin(Scon),np.nanmax(Scon))\n",
    "                    ax2.set_xlabel(\"Size (pc)\",fontsize=12)\n",
    "                    ax2.set_ylabel(\"Sigma (km/s)\",fontsize=12)\n",
    "                    ax2.legend(prop={'size': 12},loc=\"upper right\")\n",
    "                    ax2.annotate(s=LineN,fontsize=10,xy=(0.01,0.89),xycoords=\"axes fraction\")\n",
    "\n",
    "                    #gp = np.where(FRs>0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    xspL = ax4.scatter(radgpFORRAT,siggpFORRAT,label=\"All_structures\",s=30)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    ax4.set_yscale('log')\n",
    "                    ax4.set_xscale('log')\n",
    "\n",
    "                    ax4.set_xlabel(\"Radius (pc)\",fontsize=12)\n",
    "                    ax4.set_ylabel(\"sig (km/s)\",fontsize=12)\n",
    "                    ax4.legend(prop={'size': 12},loc=\"upper right\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    xspF = ax3.scatter(radgpFORRAT,rgp,label=\"All_structures\",s=30)\n",
    "\n",
    "                    ax3.annotate(s=st,fontsize=12,xy=(0.01,0.04),xycoords=\"axes fraction\")\n",
    "                    ax3.set_yscale('log')\n",
    "                    ax3.set_xscale('log')\n",
    "                    ax3.set_ylim(np.nanmin(rgp),np.nanmax(rgp))\n",
    "                    ax3.set_xlabel(\"Rad (pc)\",fontsize=12)\n",
    "                    ax3.set_ylabel(\"Linewidth Ratio (km^2/s^2/pc)\",fontsize=12)\n",
    "                    ax3.legend(prop={'size': 12})\n",
    "\n",
    "                    gp3 = np.where(lumFORRAT>0)\n",
    "                    lumFORRAT = lumFORRAT[gp3]\n",
    "                    rgpFORRAT = rgp[gp3]\n",
    "                    mom0FORRAT = mom0FORRAT[gp3]\n",
    "\n",
    "\n",
    "\n",
    "                    ax5 = pylab.subplot(5, 5, 4)\n",
    "                    ax6 = pylab.subplot(5, 5, 5)\n",
    "                    ax7 = pylab.subplot(5, 5, 6)\n",
    "\n",
    "\n",
    "\n",
    "                    xpconhh = ax5.scatter(radgpFORRAT,cgp,label=\"All_structures\",s=30,alpha=.7)\n",
    "                    ax5.set_yscale('log')\n",
    "                    ax5.set_xscale('log')\n",
    "                    ax5.set_xlabel(\"Size (pc)\",fontsize=12)\n",
    "                    ax5.set_ylabel(\"Column Density (#/cm^2 > 7e22)\",fontsize=12)\n",
    "                    ax5.legend(prop={'size': 12},loc=\"upper right\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    xspF2 = ax6.scatter(cgp,rgp,label=\"All_structures\",s=30,alpha=.7)\n",
    "                    pF2 = ax6.plot(xsCD,ysCD)\n",
    "\n",
    "                    ax6.set_yscale('log')\n",
    "                    ax6.set_xscale('log')\n",
    "                    ax6.set_ylim(np.nanmin(rgp),np.nanmax(rgp))\n",
    "                    ax6.set_xlabel(\"Column Density (#/cm^2 > 7e22)\",fontsize=12)\n",
    "                    ax6.set_ylabel(\"Linewidth Ratio (km^2/s^2/pc)\",fontsize=12)\n",
    "                    ax6.legend(prop={'size': 12},loc=\"upper right\")\n",
    "                    ax6.annotate(s=LineN,fontsize=10,xy=(0.01,0.89),xycoords=\"axes fraction\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    xspLu2 = ax7.scatter(radgp,lgp,label=\"All_structure Whole Data Set\",s=30,alpha=.7)\n",
    "                    pFLLu2 = ax7.plot(xsRL,ysRL)\n",
    "\n",
    "                    st = \"WDS, c = \"+ str(np.format_float_scientific(RLpopt[0],3))+\"+-\"+str(np.format_float_scientific(np.sqrt(RLpcov[0][0]),3))+\" d = \"+str(np.format_float_scientific(RLpopt[1],3))+\"+-\"+str(np.format_float_scientific(np.sqrt(RLpcov[1][1]),3))\n",
    "                    ax7.annotate(s='L = $c*R^d$',fontsize=12,xy=(0.01,0.13),xycoords=\"axes fraction\")\n",
    "                    ax7.annotate(s=st,fontsize=12,xy=(0.01,0.04),xycoords=\"axes fraction\")\n",
    "\n",
    "                    ax7.set_yscale('log')\n",
    "                    ax7.set_xscale('log')\n",
    "                    ax7.set_ylim(np.nanmin(lgp),np.nanmax(lgp))\n",
    "                    ax7.set_xlabel(\"Radius (pc)\",fontsize=9)\n",
    "                    ax7.set_ylabel(\"Luminosity (erg)\",fontsize=9)\n",
    "                    ax7.legend(prop={'size': 12},loc=\"upper right\")\n",
    "                    ax7.annotate(s=LineN,fontsize=10,xy=(0.01,0.89),xycoords=\"axes fraction\")\n",
    "\n",
    "\n",
    "                    axLam = pylab.subplot(5, 5, 11)\n",
    "                    lum_rat = axLam.scatter(lumFORRAT/radgpFORRAT**2,rgpFORRAT,label=\"All_structure  \",s=30,alpha=.7)\n",
    "                    #Off by factors for area, simply using r^2\n",
    "\n",
    "                    axLam.set_yscale('log')\n",
    "                    axLam.set_xscale('log')\n",
    "                    axLam.set_xlabel(\"Lum/R^2 (erg/pc^2)\",fontsize=9)\n",
    "                    axLam.set_ylabel(\"Linewidth Ratio (km/s)^2/pc\",fontsize=9)\n",
    "                    axLam.legend(prop={'size': 12},loc=\"upper right\")\n",
    "                    axLam.annotate(s=LineN,fontsize=10,xy=(0.01,0.89),xycoords=\"axes fraction\")\n",
    "\n",
    "\n",
    "\n",
    "                    axDelta = pylab.subplot(5, 5, 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    gp4=np.where(MOM0FLUXcon>0)\n",
    "                    mom0FORFlux=MOM0FLUXcon[gp4]\n",
    "                    radgpFORFlux=Rcon[gp4]*10**6\n",
    "                    rgpFORFlux=Scon[gp4]**2/Rcon[gp4]/10**6\n",
    "\n",
    "                    mom0_rat = axDelta.scatter(mom0FORFlux/radgpFORFlux**2,rgpFORFlux,label=\"All_structure  \",s=30,alpha=.7)\n",
    "                    #Off by factors for area, simply using r^2\n",
    "\n",
    "                    axDelta.set_yscale('log')\n",
    "                    axDelta.set_xscale('log')\n",
    "                    axDelta.set_xlabel(\"Mom0 Flux/pc^2 (K km/s / R^2)\",fontsize=9)\n",
    "                    axDelta.set_ylabel(\"Linewidth Ratio (km/s)^2/pc\",fontsize=9)\n",
    "                    axDelta.legend(prop={'size': 12},loc=\"upper right\")\n",
    "                    axDelta.annotate(s=LineN,fontsize=10,xy=(0.01,0.89),xycoords=\"axes fraction\")\n",
    "\n",
    "\n",
    "                    pylab.show()\n",
    "\n",
    "\n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    v1 = d.viewer()\n",
    "                    v1.show()\n",
    "\n",
    "                    #Must use text because np load is broken\n",
    "                    if(Abs_Level==\"All\"):\n",
    "                        Suffix=''\n",
    "                    if(Abs_Level==\"None\"):\n",
    "                        Suffix='_NA'\n",
    "                    if(Abs_Level==\"No Clusters\"):\n",
    "                        Suffix='_No_Clusters'\n",
    "                    if(Abs_Level==\"None (m)\"):\n",
    "                        Suffix='None_m'\n",
    "                    if(Abs_Level==\"None All Channels\"):\n",
    "                        Suffix='None_All_Channels'\n",
    "                        \n",
    "                    \n",
    "                    \n",
    "\n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameCol+\"_Leaves\"+Suffix), CD[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameCol+\"_Branches\"+Suffix), CD[1],fmt='%s')\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameLum+\"_Leaves\"+Suffix), Lumin[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameLum+\"_Branches\"+Suffix), Lumin[1],fmt='%s')\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameS+\"_Leaves\"+Suffix), Sigmas[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameS+\"_Branches\"+Suffix), Sigmas[1],fmt='%s')\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameR+\"_Leaves\"+Suffix), Rads[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameR+\"_Branches\"+Suffix), Rads[1],fmt='%s')\n",
    "\n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameFlux+\"_Leaves\"+Suffix), MOM0FLUX[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameFlux+\"_Branches\"+Suffix), MOM0FLUX[1],fmt='%s')\n",
    "\n",
    "\n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,Cube_Name_Save+\"Distances_Leaves\"+Suffix), Distances[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,Cube_Name_Save+\"Distances_Branches\"+Suffix), Distances[1],fmt='%s')\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,Cube_Name_Save+\"V_err_Leaves\"+Suffix), V_err[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,Cube_Name_Save+\"V_err_Branches\"+Suffix), V_err[1],fmt='%s')\n",
    "\n",
    "                    SIDS=np.concatenate((SIDS[0],SIDS[1]))\n",
    "\n",
    "                    print(SIDS[len(SIDS)-3:len(SIDS)-1])\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    print(kl,km,k3,k4)\n",
    "                    print(\"Failed\")\n",
    "                    print(\"-\"*60)\n",
    "                    traceback.print_exc(file=sys.stdout)\n",
    "                    \n",
    "                    if(Abs_Level==\"All\"):\n",
    "                        Suffix=''\n",
    "                    if(Abs_Level==\"None\"):\n",
    "                        Suffix='_NA'\n",
    "                    if(Abs_Level==\"No Clusters\"):\n",
    "                        Suffix='_No_Clusters'\n",
    "                    if(Abs_Level==\"None (m)\"):\n",
    "                        Suffix='None_m'\n",
    "                    if(Abs_Level==\"None All Channels\"):\n",
    "                        Suffix='None_All_Channels'\n",
    "                    nans = [[np.nan,np.nan],[np.nan,np.nan]]\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameCol+\"_Leaves\"+Suffix), nans[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameCol+\"_Branches\"+Suffix), nans[1],fmt='%s')\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameLum+\"_Leaves\"+Suffix), nans[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameLum+\"_Branches\"+Suffix), nans[1],fmt='%s')\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameS+\"_Leaves\"+Suffix), nans[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameS+\"_Branches\"+Suffix), nans[1],fmt='%s')\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameR+\"_Leaves\"+Suffix), nans[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameR+\"_Branches\"+Suffix), nans[1],fmt='%s')\n",
    "\n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,NameFlux+\"_Leaves\"+Suffix), nans[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,NameFlux+\"_Branches\"+Suffix), nans[1],fmt='%s')\n",
    "\n",
    "\n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,Cube_Name_Save+\"Distances_Leaves\"+Suffix), nans[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,Cube_Name_Save+\"Distances_Branches\"+Suffix), nans[1],fmt='%s')\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    np.savetxt(os.path.join(savePath,Cube_Name_Save+\"V_err_Leaves\"+Suffix), nans[0],fmt='%s')\n",
    "                    np.savetxt(os.path.join(savePath,Cube_Name_Save+\"V_err_Branches\"+Suffix), nans[1],fmt='%s')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfa9f99-753b-4de6-89c1-ff2f0da463d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do a crude noise estimate on the 30 edge channels\n",
    "#filename = '4.3pc_beam__CMZ_CO_J3_2_4.3_start70x360pc_3.9599999999999995LH_vel_res.fits' \n",
    "filename = '6.02pc_beam__NGC_HCN_J1_0_70x360pc_5.9399999999999995_vel_res.fits'\n",
    "#rmsmap = np.vstack([spc.cube[:15], spc.cube[85:]]).std(axis=0)\n",
    "\n",
    "Qp = SpectralCube.read(filename).with_spectral_unit(u.km/u.s,velocity_convention=\"radio\") \n",
    "#Qp = SpectralCube.read(filename).with_spectral_unit(u.Hz,velocity_convention=\"radio\") \n",
    "Qp.allow_huge_operations=True\n",
    "\n",
    "Q = Qp.to(u.K)#Jy to Kelvin\n",
    "\n",
    "sc = Q.unmasked_copy().hdu\n",
    "\n",
    "sc.data[np.where(sc.data==0)] = np.nan\n",
    "sc= SpectralCube.read(sc)\n",
    "\n",
    "\n",
    "datn=sc.hdu.data\n",
    "\n",
    "Non_nan=((datn[0,:,:]>0)  | (datn[0,:,:]<0 ))\n",
    "m = (np.nanstd(datn[0,:,:],where= Non_nan)) #Noise K\n",
    "\n",
    "\n",
    "sc = sc[:,60:80,60:80]\n",
    "\n",
    "\n",
    "Make_Plot(Name=\"a\",Name2=\"b\",Data=sc.moment0().hdu.data,vmin=0,vmax=20000,WCS=sc.wcs[:][:][0],rows=1,columns=1,index=1,show=True)\n",
    "#spc = pyspeckit.Cube(filename)\n",
    "#spc = pyspeckit.Cube(cube=sc)\n",
    "\n",
    "#print(spc.data,np.shape(spc.flux),np.shape(spc))\n",
    "#datn_spec=spc.data\n",
    "\n",
    "sp_data = np.average(sc,axis=(1,2))\n",
    "vel,RA,Dec = sc.world[:,0,0]\n",
    "\n",
    "m_mat = np.full(np.shape(sp_data),m)\n",
    "sp = pyspeckit.Spectrum(data=sp_data,xarr=vel,error=m_mat,unit='K')\n",
    "#sp.xarr.set_unit(u.km/u.s)\n",
    "\n",
    "\n",
    "# now do the same thing, but allow the widths to vary too\n",
    "# there are 7 parameters:\n",
    "# 1. the centroid\n",
    "# 2,3,4 - the amplitudes of the 0-1, 2-1, and 1-1 lines\n",
    "# 5,6,7 - the widths of the 0-1, 2-1, and 1-1 lines\n",
    "\n",
    "sp.Registry.add_fitter('hcn_varyhf_width',pyspeckit.models.hcn.hcn_varyhf_amp_width_fitter,3)\n",
    "\n",
    "# Run the fitter\n",
    "'''sp.specfit(fittype='hcn_varyhf_width',\n",
    "           guesses=[1,1,1,1,1,1,1],\n",
    "           show_hyperfine_components=True,\n",
    "           clear=True)'''\n",
    "sp.specfit(fittype='gaussian',\n",
    "           guesses=[1,1,1],\n",
    "           show_hyperfine_components=True,\n",
    "           clear=True)\n",
    "#sp.xarr.set_unit(u.km/u.s)\n",
    "# print the fitted parameters:\n",
    "print(sp.specfit.parinfo)\n",
    "# Param #0      CENTER0 =      -51.865 +/-       0.0525058\n",
    "# Param #1    AMP10-010 =      1.83238 +/-       0.0773993   Range:   [0,inf)\n",
    "# Param #2    AMP12-010 =      5.26566 +/-       0.0835981   Range:   [0,inf)\n",
    "# Param #3    AMP11-010 =      3.02621 +/-       0.0909095   Range:   [0,inf)\n",
    "# Param #4  WIDTH10-010 =      2.16711 +/-        0.118651   Range:   [0,inf)\n",
    "# Param #5  WIDTH12-010 =      1.90987 +/-       0.0476163   Range:   [0,inf)\n",
    "# Param #6  WIDTH11-010 =      1.64409 +/-        0.076998   Range:   [0,inf)\n",
    "\n",
    "\n",
    "\n",
    "sp.plotter(axis=sp.plotter.axis,xmin = -0, xmax=500, ymin=-2, clear=False,color='g')\n",
    "\n",
    "sp.specfit.plotresiduals(axis=sp.plotter.axis,clear=False,yoffset=-1,color='g',label=True)\n",
    "#sp.plotter.reset_limits(ymin=-2)\n",
    "\n",
    "# Save the figure (this step is just so that an image can be included on the web page)\n",
    "sp.plotter.savefig('hcn_freehf_ampandwidth_fit.jpeg')\n",
    "\n",
    "'''# Finally, how well does a 2-component fit work?\n",
    "sp.specfit(fittype='hcn_fixedhf',\n",
    "           multifit=None,\n",
    "           guesses=[1,-48,0.6,0.1,-46,0.6],\n",
    "           show_hyperfine_components=True,\n",
    "           clear=True)\n",
    "sp.specfit.plotresiduals(axis=sp.plotter.axis,clear=False,yoffset=-1,color='g',label=False)\n",
    "sp.plotter.reset_limits(ymin=-2)'''\n",
    "\n",
    "# Save the figure (this step is just so that an image can be included on the web page)\n",
    "#sp.plotter.savefig('hcn_fixedhf_fit_2components.jpeg')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7fd895-0fb2-48fc-861b-a22cec247202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit with automatic guesses\n",
    "sp.specfit(fittype='gaussian')\n",
    "# (this will produce a plot overlay showing the fit curve and values)\n",
    "sp.plotter.savefig('basic_plot_example_withfit.jpeg')\n",
    "\n",
    "# Redo the overlay with no annotation\n",
    "\n",
    "# remove both the legend and the model overlay\n",
    "sp.specfit.clear()\n",
    "# then re-plot the model without an annotation (legend)\n",
    "sp.specfit.plot_fit(annotate=False)\n",
    "sp.plotter.savefig('basic_plot_example_withfit_no_annotation.jpeg')\n",
    "\n",
    "\n",
    "# overlay another spectrum\n",
    "# We use the 'synthetic' spectrum with no noise, then shift it by 10 km/s\n",
    "sp2 = pyspeckit.Spectrum(data=sp_data, error=m_mat, xarr=vel,\n",
    "                         unit=\"K\")\n",
    "sp2.specfit(fittype='gaussian')\n",
    "\n",
    "# again, remove the overlaid model fit\n",
    "sp.specfit.clear()\n",
    "\n",
    "# to overplot, you need to tell the plotter which matplotlib axis to use and\n",
    "# tell it not to clear the plot first\n",
    "sp2.plotter(axis=sp.plotter.axis,\n",
    "            clear=False,\n",
    "            color='g')\n",
    "sp2.specfit.plot_fit(annotate=False)\n",
    "# sp2.plotter and sp.plotter can both be used here (they refer to the same axis\n",
    "# and figure now)\n",
    "sp.plotter.savefig('basic_plot_example_with_second_spectrum_overlaid_in_green.jpeg')\n",
    "\n",
    "# the plot window will follow the last plotted spectrum's limits by default;\n",
    "# that can be overridden with the xmin/xmax keywords\n",
    "sp2.plotter(axis=sp.plotter.axis,\n",
    "            xmin=-100, xmax=200,\n",
    "            ymin=-0.5, ymax=1.5,\n",
    "            clear=False,\n",
    "            color='g')\n",
    "sp.plotter.savefig('basic_plot_example_with_second_spectrum_overlaid_in_green_wider_limits.jpeg')\n",
    "\n",
    "\n",
    "# you can also offset the spectra and set different \n",
    "# this time, we need to clear the axis first, then do a fresh overlay\n",
    "\n",
    "# fresh plot\n",
    "#sp.plotter(clear=True)\n",
    "\n",
    "# overlay, shifted down by 0.2 in y and with a wider linewidth\n",
    "sp2.plotter(axis=sp.plotter.axis,\n",
    "            offset=-0.2,\n",
    "            clear=False,\n",
    "            color='r',\n",
    "            linewidth=2,\n",
    "            alpha=0.5,\n",
    "           )\n",
    "# you can also modify the axis properties directly\n",
    "sp.plotter.axis.set_ylim(-0.25, 1.1)\n",
    "sp2.plotter.savefig('basic_plot_example_with_second_spectrum_offset_overlaid_in_red.jpeg')\n",
    "\n",
    "\n",
    "sp2.plotter(axis=sp2.plotter.axis,xmin = -0, xmax=500, ymin=-2, clear=False,color='g')\n",
    "\n",
    "sp2.specfit.plotresiduals(axis=sp2.plotter.axis,clear=False,yoffset=-1,color='g',label=True)\n",
    "\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ded73a-41a8-4234-9b71-6fb44a4abfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pyspeckit\n",
    "import pylab as pl\n",
    "import astropy.units as u\n",
    "\n",
    "# Load the spectrum & properly identify the units\n",
    "# The data is from http://adsabs.harvard.edu/abs/1999A%26A...348..600P\n",
    "# do a crude noise estimate on the 30 edge channels\n",
    "#filename = '4.3pc_beam__CMZ_CO_J3_2_4.3_start70x360pc_3.9599999999999995LH_vel_res.fits' \n",
    "filename = '6.02pc_beam__NGC_HCN_J1_0_70x360pc_5.9399999999999995_vel_res.fits'\n",
    "#rmsmap = np.vstack([spc.cube[:15], spc.cube[85:]]).std(axis=0)\n",
    "\n",
    "Qp = SpectralCube.read(filename).with_spectral_unit(u.km/u.s,velocity_convention=\"radio\") \n",
    "#Qp = SpectralCube.read(filename).with_spectral_unit(u.Hz,velocity_convention=\"radio\") \n",
    "Qp.allow_huge_operations=True\n",
    "\n",
    "Q = Qp.to(u.K)#Jy to Kelvin\n",
    "\n",
    "sc = Q.unmasked_copy().hdu\n",
    "\n",
    "sc.data[np.where(sc.data==0)] = np.nan\n",
    "sc= SpectralCube.read(sc)\n",
    "\n",
    "\n",
    "datn=sc.hdu.data\n",
    "\n",
    "Non_nan=((datn[0,:,:]>0)  | (datn[0,:,:]<0 ))\n",
    "m = (np.nanstd(datn[0,:,:],where= Non_nan)) #Noise K\n",
    "\n",
    "\n",
    "sc = sc[:,60:80,60:80]\n",
    "\n",
    "\n",
    "\n",
    "header = sc.hdu.header\n",
    "print()\n",
    "#make metadata for the dendrogram\n",
    "\n",
    "try:\n",
    "    freq = header[\"RESTFREQ\"]*u.Hz#\n",
    "    \n",
    "    \n",
    "except:\n",
    "    freq = header[\"RESTFRQ\"]*u.Hz#\n",
    "    \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "Make_Plot(Name=\"a\",Name2=\"b\",Data=sc.moment0().hdu.data,vmin=0,vmax=20000,WCS=sc.wcs[:][:][0],rows=1,columns=1,index=1,show=True)\n",
    "#spc = pyspeckit.Cube(filename)\n",
    "#spc = pyspeckit.Cube(cube=sc)\n",
    "\n",
    "#print(spc.data,np.shape(spc.flux),np.shape(spc))\n",
    "#datn_spec=spc.data\n",
    "\n",
    "sp_data = np.average(sc,axis=(1,2))\n",
    "vel,RA,Dec = sc.world[:,0,0]\n",
    "\n",
    "m_mat = np.full(np.shape(sp_data),m)\n",
    "sp = pyspeckit.Spectrum(data=sp_data,xarr=vel,error=m_mat,unit='K')\n",
    "\n",
    "sp.xarr.set_unit(u.km/u.s)\n",
    "sp.xarr.refX = freq\n",
    "sp.xarr.velocity_convention = 'radio'\n",
    "sp.xarr.xtype='velocity'\n",
    "sp.unit='$T_A^*$'\n",
    "\n",
    "# set the error array based on a signal-free part of the spectrum\n",
    "sp.error[:] = m_mat\n",
    "# Register the fitter\n",
    "# The HCN fitter is 'built-in' but is not registered by default; this example\n",
    "# shows how to register a fitting procedure\n",
    "# 'multi' indicates that it is possible to fit multiple components and a\n",
    "# background will not automatically be fit\n",
    "# 5 is the number of parameters in the model (line center,\n",
    "# line width, and amplitude for the 0-1, 2-1, and 1-1 lines)\n",
    "\n",
    "# Plot the results\n",
    "sp.plotter()\n",
    "# Run the fixed-ampltiude fitter and show the individual fit components\n",
    "sp.specfit(fittype='gaussian',\n",
    "           multifit=None,\n",
    "           guesses=[250,255,5],\n",
    "           show_hyperfine_components=True)\n",
    "\n",
    "sp.specfit.plotresiduals(axis=sp.plotter.axis,clear=False,yoffset=-1,color='g',label=False)\n",
    "sp.plotter.reset_limits(ymin=-2)\n",
    "\n",
    "# Save the figure (this step is just so that an image can be included on the web page)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81659d6c-a579-4208-86ce-0808d970d8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gaussians all chanlles\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for Abs_Level in Abs_Levels:\n",
    "\n",
    "    \n",
    "                \n",
    "\n",
    "    for kl in range(iterations):\n",
    "\n",
    "        Prime_Beam = Min_res*((kl*iter_factor+1))#\n",
    "        print(Prime_Beam)\n",
    "\n",
    "\n",
    "        for km in range(iterations):\n",
    "            vel_prime = min_vel*((km*iter_factor+1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            Cube_Name_Load = \"Cropped_\"+str(Prime_Beam.value)+\"pc_beam_\"+Line_Name+str(FOV[0])+\"x\"+str(FOV[1])+'pc_'+str(vel_prime)+'_vel_res.fits'\n",
    "            path = Cube_Name_Load\n",
    "\n",
    "            Qp = SpectralCube.read(path).with_spectral_unit(u.km/u.s,velocity_convention=\"radio\") \n",
    "            Qp.allow_huge_operations=True\n",
    "\n",
    "            Q = Qp.to(u.K)#Jy to Kelvin\n",
    "\n",
    "            sc = Q.unmasked_copy()\n",
    "            \n",
    "            scWCS = sc.wcs[:][:][0]\n",
    "            \n",
    "            \n",
    "            datn = sc.hdu.data\n",
    "\n",
    "\n",
    "            \n",
    "            try:\n",
    "                freq = header[\"RESTFREQ\"]*u.Hz#\n",
    "            except:\n",
    "                freq = header[\"RESTFRQ\"]*u.Hz#\n",
    "                    \n",
    "            cen_p1 = SkyCoord('00h47m33.9s', '-25d17m26.8s', frame='icrs')\n",
    "            cen_p2 = SkyCoord('00h47m32.6s', '-25d17m10.2s', frame='icrs')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            Non_nan=((datn[0,:,:]>0)  | (datn[0,:,:]<0 ))\n",
    "\n",
    "            m = (np.nanstd(datn[0,:,:],where= Non_nan)) #Noise K\n",
    "            \n",
    "            IDs,RAs,Decs,HWHM  =    np.genfromtxt(\"NGC_Clusters_\"+\"IDs\"+\"\",dtype=type(\"12h23.14s\")),np.genfromtxt(\"NGC_Clusters_\"+\"RAs\"+\"\",dtype=type(\"12h23.14s\")),np.genfromtxt(\"NGC_Clusters_\"+\"Decs\"+\"\",dtype=type(\"12h23.14s\")),np.genfromtxt(\"NGC_Clusters_\"+\"HWHM\"+\"\")\n",
    "            \n",
    "            for fffff in range(len(RAs)):\n",
    "                sky = SkyCoord(str(RAs[fffff]),str(Decs[fffff]), frame='icrs')\n",
    "                \n",
    "                \n",
    "                \n",
    "            if(Abs_Level==\"All\"):\n",
    "                pass\n",
    "            if(Abs_Level==\"None\"):\n",
    "                datn[np.where(datn<0)]=np.nan\n",
    "            if(Abs_Level==\"None (m)\"):\n",
    "                datn[np.where(datn<-m)]=np.nan\n",
    "            if(Abs_Level==\"None All Channels\"):\n",
    "                for lmi in range(len(datn)):\n",
    "                    bpP = np.where(datn[lmi]<-m)\n",
    "                    for lmj in range(len(datn)):\n",
    "                        datn[lmj][bpP]=np.nan\n",
    "            if(Abs_Level==\"No Clusters\"):\n",
    "                IDs,RAs,Decs,HWHM  =    np.genfromtxt(\"NGC_Clusters_\"+\"IDs\"+\"\",dtype=type(\"12h23.14s\")),np.genfromtxt(\"NGC_Clusters_\"+\"RAs\"+\"\",dtype=type(\"12h23.14s\")),np.genfromtxt(\"NGC_Clusters_\"+\"Decs\"+\"\",dtype=type(\"12h23.14s\")),np.genfromtxt(\"NGC_Clusters_\"+\"HWHM\"+\"\")\n",
    "\n",
    "                datn=  Mask_Clusters_NGC(HWHM,scWCS,sc.hdu.header,datn,RAs,Decs,One_Pc=False,One_Pc_Size=1,HWHM_Fac=3)\n",
    "            \n",
    "            for ID_Num in range(len(IDs)):\n",
    "                \n",
    "                #fig = plt.figure(1,figsize=(60,120))\n",
    "                #gs0 = gridspec.GridSpec(np.ceil(len(IDs)/5), np.ceil(len(IDs)/5), figure=fig)\n",
    "                #gs00 = gridspec.GridSpecFromSubplotSpec(1, 1, subplot_spec=gs0[ID_Num])\n",
    "                \n",
    "                ID = IDs[ID_Num]\n",
    "                \n",
    "                header = sc.hdu.header\n",
    "                sky = SkyCoord(str(RAs[ID_Num]),str(Decs[ID_Num]), frame='icrs')\n",
    "                \n",
    "                \n",
    "                p1,p2 = int(scWCS.world_to_pixel(sky)[0]),int(scWCS.world_to_pixel(sky)[1]) #Ra,dec\n",
    "                #circle = plt.Circle((p1, p2), HWHM[i]/pixel_res, color='r',fill=False)\n",
    "                \n",
    "                datnP = datn[:,p2-5:p2+5,p1-5:p1+5]#Make cubes from the cluster locations +- some amount of pixels\n",
    "\n",
    "                sp_data = np.average(datnP,axis=(1,2))\n",
    "                \n",
    "                #print(sp_data)\n",
    "                vel,RA,Dec = sc.world[:,0,0]\n",
    "\n",
    "                m_mat = np.full(np.shape(sp_data),m)\n",
    "                \n",
    "                sp = pyspeckit.Spectrum(data=sp_data,xarr=vel,error=m_mat,unit='K')\n",
    "\n",
    "                sp.xarr.set_unit(u.km/u.s)\n",
    "                sp.xarr.refX = freq\n",
    "                sp.xarr.velocity_convention = 'radio'\n",
    "                sp.xarr.xtype='velocity'\n",
    "                sp.unit='$T_A^*$'\n",
    "\n",
    "                # set the error array based on a signal-free part of the spectrum\n",
    "                sp.error[:] = m_mat\n",
    "\n",
    "                # Plot the results\n",
    "                sp.plotter(title = Cube_Name_Load+\"_\"+str(ID))\n",
    "                \n",
    "                print( Cube_Name_Load+\"_\"+str(ID))\n",
    "                # Run the fixed-ampltiude fitter and show the individual fit components\n",
    "                sp.specfit(fittype='gaussian',\n",
    "                           guesses=[250,255,5],\n",
    "                           show_hyperfine_components=True)\n",
    "\n",
    "                sp.specfit.plotresiduals(axis=sp.plotter.axis,clear=False,yoffset=-1,color='g',label=False)\n",
    "                sp.plotter.reset_limits(ymin=-2)\n",
    "\n",
    "            print(m,\"Unmatched Noise (K)\")\n",
    "\n",
    "            \n",
    "\n",
    "pathCont = 'Continuum_Reproject.fits'\n",
    "\n",
    "\n",
    "sc= spectral_cube.Projection.from_hdu(fits.open(pathCont)[0])\n",
    "\n",
    "fig = plt.figure(1,figsize=(20,20))\n",
    "ax = pylab.subplot(1,1,1,projection=sc.wcs)\n",
    "\n",
    "\n",
    "\n",
    "RA = ax.coords[0]                                                                  # \n",
    "Dec = ax.coords[1]\n",
    "im = pylab.imshow(sc.hdu.data,norm=colors.SymLogNorm(.01))\n",
    "RA.set_ticks(size=-3)                                                                                      \n",
    "Dec.set_ticks(size=-3) \n",
    "RA.set_ticklabel(exclude_overlapping=True) \n",
    "Dec.set_ticklabel(exclude_overlapping=True)                                                                                     \n",
    "pylab.xlabel('RA',fontsize=20,labelpad=1)                               \n",
    "pylab.ylabel('Dec',fontsize=20,labelpad=1)\n",
    "ax.tick_params(axis = 'both', which = 'major', labelsize = 15)    \n",
    "cb=pylab.colorbar(im,fraction=.051,pad=0.0)                                     \n",
    "cb.set_label(label='NGC253 cont (850um)(Jy/beam)',fontsize=16,rotation=270,labelpad=20) \n",
    "cb.ax.tick_params(which = 'major', labelsize = 10)   \n",
    "\n",
    "for i in range(len(RAs)):\n",
    "    #print(str(RAs[i]),str(Decs[i]))\n",
    "    sky = SkyCoord(str(RAs[i]),str(Decs[i]), frame='icrs')\n",
    "    distance =3.5*u.Mpc\n",
    "    \n",
    "    pixel_res = abs(distance.to(u.pc)/u.pc*sc.hdu.header['cdelt1']*np.pi/180)\n",
    "    \n",
    "    \n",
    "    p1,p2 = int(sc.wcs.world_to_pixel(sky)[0]),int(sc.wcs.world_to_pixel(sky)[1]) #Ra,dec\n",
    "    circle = plt.Circle((p1, p2), HWHM[i]/pixel_res, color='r',fill=False)\n",
    "    ax.add_patch(circle)\n",
    "    \n",
    "    pylab.annotate(s=str(IDs[i]),fontsize=10,xy=(p1-2,p2+4),c=\"white\")  \n",
    "    #print(p1,p2,np.shape(sc))\n",
    "pylab.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7a2758-16f8-421f-9d75-24dcd6d09d08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828187e8-80c3-4640-9feb-c65156fe2d12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
