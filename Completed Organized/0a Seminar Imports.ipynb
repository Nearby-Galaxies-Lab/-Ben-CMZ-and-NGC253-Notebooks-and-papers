{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc0ed5b-634f-455a-80e0-6f7bfa128b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################################################################################################################################################\n",
    "######################################################################################################################################################################################################################################\n",
    "######################################################################################################################################################################################################################################\n",
    "\n",
    "#Need this so that the other files can get the imports.\n",
    "#Put it in the same directory as the file you want to run.\n",
    "\n",
    "######################################################################################################################################################################################################################################\n",
    "######################################################################################################################################################################################################################################\n",
    "######################################################################################################################################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "import sys, traceback\n",
    "print(sys.executable)\n",
    "print(sys.version)\n",
    "print(sys.version_info)\n",
    "\n",
    "import math\n",
    "import astropy\n",
    "print('astropy',astropy.__version__ )\n",
    "from spectral_cube import SpectralCube      # This is a handy package for working with 3D data cubes\n",
    "from spectral_cube import LazyMask\n",
    "from astropy.coordinates import SkyCoord\n",
    "from reproject import reproject_interp      \n",
    "from reproject.mosaicking import find_optimal_celestial_wcs \n",
    "import regions\n",
    "import reproject\n",
    "print('reproject',reproject.__version__)\n",
    "import spectral_cube\n",
    "print('spectral_cube',spectral_cube.__version__)\n",
    "import numpy as np                          \n",
    "import pylab                                \n",
    "import matplotlib \n",
    "import matplotlib.gridspec as gridspec                                                                                             \n",
    "import scipy\n",
    "import astropy.io.fits as fits                                                          \n",
    "from astropy.wcs import WCS                 \n",
    "from astropy import units as u              \n",
    "import pyspeckit as psk   \n",
    "import astrodendro\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib import pyplot as plt\n",
    "# Suppress warnings we don't care about:\n",
    "import sys\n",
    "import gc\n",
    "from astropy.convolution import Gaussian1DKernel\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "%matplotlib inline\n",
    "from astrodendro.analysis import PPVStatistic\n",
    "import os\n",
    "\n",
    "print(astrodendro.__file__)\n",
    "\n",
    "from matplotlib.patches import Ellipse\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import radio_beam\n",
    "from astropy.table import Table\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.optimize import leastsq\n",
    "#%matplotlib widget\n",
    "Num_per_kg= 6.0221409*10**23/(2.8*10**-3)#6.0221409*10**23/29.0180*10**-3#num/kg for h2\n",
    "\n",
    "#Create a function that uses the dendrogram input to calculate all the quantities, and has the size and linewidth requirements of the Shetty paper\n",
    "#Requires the computed dendrogram, the data from the line image, the velocity axis, and the data from the Continuum image, as well as metadata for the structures\n",
    "#Finds Size, Linewidth, Luminosity, and Column Density of a structure for each structure and returns them in [[][]] arrays [Leaves][Branches]\n",
    "#Continuum is in Jansky/Beam, Line data should have the unit specified in the metadata as 'data_unit'\n",
    "\n",
    "def Dendro_Arrays(Dendrogram,LineData,DataVel,ContData,metadata,ColD = True,beam_size=999,beam_req = 999999,Trunks=True):\n",
    "    SizeA,SigmaA,LuminA,CDA,SIDS,MOM0_FLUX,Distances,V_rms_err = [[],[],[],[]],[[],[],[],[]],[[],[]],[[],[]],[[],[]],[[],[]],[[],[]],[[],[]]\n",
    "    print(metadata)\n",
    "    \n",
    "    d_copy= Dendrogram\n",
    "    #catalog = astrodendro.ppv_catalog(d, metadata)\n",
    "    center = SkyCoord('00h47m33.14s' ,'-25d17m17.52s',frame='icrs')\n",
    "    center_ra_pix,center_dec_pix = int(metadata['wcsu'][:][:][0].world_to_pixel(center)[0]),int(metadata['wcsu'][:][:][0].world_to_pixel(center)[1])\n",
    "    sliced= LineData[12]\n",
    "    CubeShape = np.shape(sliced)\n",
    "    for t in Dendrogram.all_structures: \n",
    "\n",
    "        I = t.indices()\n",
    "        Cont = True\n",
    "        if t.is_branch:\n",
    "                if t.parent==None:\n",
    "                    Cont=True\n",
    "                else:\n",
    "                    if(Trunks):\n",
    "                        Cont = True\n",
    "                    else:\n",
    "                        Cont = False\n",
    "        \n",
    "        for lmi in range(len(I[0])):\n",
    "            NansNE=0\n",
    "            NansSE=0\n",
    "            NansNW=0\n",
    "            NansSW=0\n",
    "            Length = 10\n",
    "            #I[1][lmi+10]>\n",
    "            for lmj in range(Length):\n",
    "                #Check four 45 degree prongs from each point and see if they have at least 7 nans in 10 pixels. If that happens its too close to the boundary\n",
    "                try:\n",
    "\n",
    "                    if(sliced[I[1][lmi]+lmj,I[2][lmi]-lmj]>0 or sliced[I[1][lmi]+lmj,I[2][lmi]-lmj]<0 ):\n",
    "                        pass\n",
    "                    else:\n",
    "                        NansSE+=1\n",
    "                    if(sliced[I[1][lmi]-lmj,I[2][lmi]-lmj]>0 or sliced[I[1][lmi]-lmj,I[2][lmi]-lmj]<0 ):\n",
    "                        pass\n",
    "                    else:\n",
    "                        NansSW+=1\n",
    "                    if(sliced[I[1][lmi]-lmj,I[2][lmi]+lmj]>0 or sliced[I[1][lmi]-lmj,I[2][lmi]+lmj]<0 ):\n",
    "                        pass\n",
    "                    else:\n",
    "                        NansNW+=1\n",
    "                    if(sliced[I[1][lmi]+lmj,I[2][lmi]+lmj]>0 or sliced[I[1][lmi]+lmj,I[2][lmi]+lmj]<0 ):\n",
    "                        pass\n",
    "                    else:\n",
    "                        NansNE+=1\n",
    "                except:\n",
    "                    #only fails if the I goes close to the boundary of the cube and tries to get a pixel outside the cube\n",
    "                    Cont = False\n",
    "            if(NansNE>Length-3 or NansNW>Length-3 or NansSE>Length-3 or NansSW>Length-3):\n",
    "                Cont=False\n",
    "                break\n",
    "\n",
    "        if(Cont):\n",
    "            s = PPVStatistic(t,metadata=metadata)\n",
    "            s_radius = s.radius\n",
    "            s_v_rms = s.v_rms\n",
    "            if((float((s_radius*np.pi/180*3.5/u.deg)))*10**6<beam_size*7 and (float((s_radius*np.pi/180*3.5/u.deg)))*10**6>beam_size*beam_req and (float(s_v_rms/u.km*u.s))>.01):\n",
    "            \n",
    "            \n",
    "\n",
    "                nproj_pix=len(set(zip(*tuple(I[i] for i in [1,2]))))\n",
    "                v_IWM = np.nansum(LineData[I]*(DataVel[I[0]])/u.km*u.s)/np.nansum(LineData[I])\n",
    "                sig_Sh = np.sqrt(np.nansum(LineData[I]*((DataVel[I[0]])/u.km*u.s-v_IWM)**2)/np.nansum(LineData[I])) \n",
    "                \n",
    "                #The flux from the continuum\n",
    "                #Convert to Jansky from Jansky per beam:\n",
    "                if(ColD ==True):\n",
    "                    Cont_Flux=0\n",
    "\n",
    "                    proj = tuple(set(zip(*tuple(I[i] for i in [1,2]))))\n",
    "                    for lmi in range(len(proj)):\n",
    "\n",
    "                        Cont_Flux+=ContData[proj[lmi]]\n",
    "                    Cont_Flux=Cont_Flux/(metadata['beam_area_ratioc']*(2*np.sqrt(2*np.log(2))))*u.pix**2*u.beam/u.beam*u.Jy#SHould be input as Jansky /beam and will be converted to Jansky, then to unitless. The beam is changed from FWHM to Gaussian\n",
    "                    Dust_Column = Flux_to_Mass(Cont_Flux)*Num_per_kg/((s_radius*np.pi/180*3.5/u.deg)**2*(3.086*10**24)**2)/np.pi*(1.989*10**30*u.kg/u.M_sun)/u.kg\n",
    "                else:\n",
    "                    Dust_Column=0\n",
    "                if(str(Dust_Column) == str(np.nan) or str(Dust_Column)==str(np.inf)):\n",
    "                    Dust_Column=0\n",
    "                lum = Flux_to_Lum(s.flux)\n",
    "                s_flux = s.flux\n",
    "\n",
    "                Index = tuple(I[i] for i in [0,1,2])\n",
    "                K_Km_s_Flux=np.nansum(LineData[Index]*metadata[\"velocity_scale\"])#Find the total flux from the structures in K km/s, assuming the input data is in K as it should be, \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                Distance = np.sqrt((float(s.x_cen/u.pix)-center_ra_pix)**2+(float(s.y_cen/u.pix)- center_dec_pix)**2)*metadata['spatial_scale']*np.pi/180*3.5*10**6/u.deg#pc dist from barycenter\n",
    "                \n",
    "                \n",
    "                V_err= Get_V_rms_err(dend1=d_copy,idx=int(t.idx),struct=t,m=m,NF=1,iterations=5,metadata=metadata)\n",
    "                \n",
    "                \n",
    "                if(t.is_leaf):\n",
    "\n",
    "                    SizeA[0].append((float((s_radius*np.pi/180*3.5/u.deg)))) #define size as astrodendro\n",
    "                    SigmaA[0].append((float(s_v_rms/u.km*u.s)))#\n",
    "                    CDA[0].append(float(Dust_Column))\n",
    "                    LuminA[0].append(float(lum*u.Hz*u.s/u.erg))\n",
    "                    SIDS[0].append(float(t.idx))\n",
    "                    MOM0_FLUX[0].append(float(K_Km_s_Flux*u.s/u.km))\n",
    "                    Distances[0].append(float(Distance))\n",
    "                    V_rms_err[0].append(float(V_err))\n",
    "                if(t.is_branch\t):\n",
    "\n",
    "                    SizeA[1].append((float((s_radius*np.pi/180*3.5/u.deg)))) #define size as astrodendro\n",
    "                    SigmaA[1].append((float(s_v_rms/u.km*u.s)))#\n",
    "                    CDA[1].append(float(Dust_Column))\n",
    "                    LuminA[1].append(float(lum*u.Hz*u.s/u.erg))\n",
    "                    SIDS[1].append(float(t.idx))\n",
    "                    MOM0_FLUX[1].append(float(K_Km_s_Flux*u.s/u.km))\n",
    "                    Distances[1].append(float(Distance))\n",
    "                    V_rms_err[1].append(float(V_err))\n",
    "                del s\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "    SizeA[0] = np.array(SizeA[0],dtype=type(1.))\n",
    "    SizeA[1] = np.array(SizeA[1],dtype=type(1.))\n",
    "    SizeA[2] = np.array(SizeA[2],dtype=type(1.))\n",
    "    SizeA[3] = np.array(SizeA[3],dtype=type(1.))\n",
    "    SigmaA[0] = np.array(SigmaA[0],dtype=type(1.))\n",
    "    SigmaA[1] = np.array(SigmaA[1],dtype=type(1.))\n",
    "    SigmaA[2] = np.array(SigmaA[2],dtype=type(1.))\n",
    "    SigmaA[3] = np.array(SigmaA[3],dtype=type(1.))\n",
    "    CDA[0] = np.array(CDA[0],dtype=type(1.))\n",
    "    CDA[1] = np.array(CDA[1],dtype=type(1.))\n",
    "    LuminA[0] = np.array(LuminA[0],dtype=type(1.))\n",
    "    LuminA[1] = np.array(LuminA[1],dtype=type(1.))\n",
    "    SIDS[0] = np.array(SIDS[0],dtype=type(1.))\n",
    "    SIDS[1] = np.array(SIDS[1],dtype=type(1.))\n",
    "    MOM0_FLUX[0] = np.array(MOM0_FLUX[0],dtype=type(1.))\n",
    "    MOM0_FLUX[1] = np.array(MOM0_FLUX[1],dtype=type(1.))\n",
    "    Distances[0] = np.array(Distances[0],dtype=type(1.))\n",
    "    Distances[1] = np.array(Distances[1],dtype=type(1.))\n",
    "    V_rms_err[0] = np.array(V_rms_err[0],dtype=type(1.))\n",
    "    V_rms_err[1] = np.array(V_rms_err[1],dtype=type(1.))\n",
    "    \n",
    "    return np.array(SizeA),np.array(SigmaA),np.array(CDA),np.array(LuminA),np.array(SIDS),np.array(MOM0_FLUX),np.array(Distances),np.array(V_rms_err)\n",
    "\n",
    "#Make a function to make an image \n",
    "\n",
    "#Data to plot, minimum of color bar, maximum, WCS projection for coords, and position of the image in the larger figure\n",
    "def Make_Plot(Name,Name2,Data,vmin,vmax,WCS,rows,columns,index,show):\n",
    "    \n",
    "\n",
    "    ax = pylab.subplot(rows,columns,index,projection=WCS) \n",
    "    RA = ax.coords[0]                                                                  # \n",
    "    Dec = ax.coords[1]\n",
    "    im = pylab.imshow(Data,vmin=vmin,vmax=vmax,cmap='rainbow')\n",
    "    RA.set_ticks(size=-3)                                                                                      \n",
    "    Dec.set_ticks(size=-3) \n",
    "    RA.set_ticklabel(exclude_overlapping=True) \n",
    "    Dec.set_ticklabel(exclude_overlapping=True)                                                                                     \n",
    "    pylab.xlabel('Right Ascension',fontsize=20,labelpad=1)                               \n",
    "    pylab.ylabel('Declination',fontsize=20,labelpad=1)\n",
    "    ax.tick_params(axis = 'both', which = 'major', labelsize = 15)    \n",
    "    cb=pylab.colorbar(im,fraction=0.1,pad=0.0)                                     \n",
    "    cb.set_label(label=Name,fontsize=10,rotation=270,labelpad=20) \n",
    "    cb.ax.tick_params(which = 'major', labelsize = 10)   \n",
    "    pylab.annotate(s=Name2,fontsize=10,xy=(0.02,1.05),xycoords=\"axes fraction\")  \n",
    "    if(show==True):\n",
    "        pylab.show()\n",
    "def Make_Plot_Anno(Name,Name2,Data,vmin,vmax,WCS,rows,columns,index,show,pos1,pos2):\n",
    "    \n",
    "\n",
    "    ax = pylab.subplot(rows,columns,index,projection=WCS) \n",
    "    RA = ax.coords[0]                                                                  # \n",
    "    Dec = ax.coords[1]\n",
    "    im = pylab.imshow(Data,vmin=vmin,vmax=vmax,cmap='rainbow')\n",
    "    RA.set_ticks(size=-3)                                                                                      \n",
    "    Dec.set_ticks(size=-3) \n",
    "    RA.set_ticklabel(exclude_overlapping=True) \n",
    "    Dec.set_ticklabel(exclude_overlapping=True)                                                                                     \n",
    "    pylab.xlabel('Right Ascension',fontsize=20,labelpad=1)                               \n",
    "    pylab.ylabel('Declination',fontsize=20,labelpad=1)\n",
    "    ax.tick_params(axis = 'both', which = 'major', labelsize = 15)    \n",
    "    cb=pylab.colorbar(im,fraction=.1,pad=0.0)                                     \n",
    "    cb.set_label(label=Name,fontsize=10,rotation=270,labelpad=20) \n",
    "    cb.ax.tick_params(which = 'major', labelsize = 10)   \n",
    "    pylab.annotate(s=Name2,fontsize=10,xy=(pos1,pos2),xycoords=\"axes fraction\")  \n",
    "    if(show==True):\n",
    "        pylab.show()\n",
    "        \n",
    "        \n",
    "#Put this up here for the column density map\n",
    "def Flux_to_Mass(flux):\n",
    "    J_to_e = 10**-23*u.erg/u.s/u.cm**2/u.Hz/u.Jy\n",
    "    flux_erg = flux*J_to_e\n",
    "    L = 4*np.pi*(3.5*3.086*10**24)**2*flux_erg*u.cm**2 #Megaparsec is converted to cm\n",
    "    \n",
    "    \n",
    "    a_850 = 6.7*10**19*u.erg/u.s/u.Hz/u.M_sun #6.7+-1.7\n",
    "    \n",
    "    M_mol = L/a_850#Just in Solar mass*1.989*10**30*u.kg/u.M_sun #Determines mass of the cont for 850 in kg\n",
    "    return M_mol\n",
    "def Flux_to_Lum(flux):\n",
    "    J_to_e = 10**-23*u.erg/u.s/u.cm**2/u.Hz/u.Jy\n",
    "    flux_erg = flux*J_to_e\n",
    "    L = 4*np.pi*(3.5*3.086*10**24)**2*flux_erg*u.cm**2 #Megaparsec is converted to cm\n",
    "    \n",
    "    return L\n",
    "\n",
    "\n",
    "def Get_V_rms_err(dend1,struct,idx,m,NF,iterations,metadata):\n",
    "    \n",
    "    \n",
    "    vs=[]\n",
    "    np.random.seed((99)**2*123)\n",
    "    for llll in range(iterations):\n",
    "        \n",
    "        #print(llll)\n",
    "        s = dend1.__getitem__(idx)\n",
    "        #s = struct#copy.deepcopy(struct)\n",
    "        #s2 = struct#copy.deepcopy(struct)\n",
    "        npixels = np.product(np.shape(s.values()))\n",
    "        #print(np.shape(s.values()),s.values())\n",
    "        \n",
    "        additional_noise = np.random.normal(0., m*NF, npixels)\n",
    "        additional_noise = np.reshape(additional_noise, np.shape(s.values()))\n",
    "        #add or subract noise to the values and calculate the v rms, them find the std of that array and\n",
    "        # call that the uncertainty in v rms for a structure\n",
    "        dat1P = dend1.data[s.indices()]\n",
    "        dend1.data[s.indices()]+= additional_noise\n",
    "        s = dend1.__getitem__(idx)\n",
    "        vs.append(float(PPVStatistic(s,metadata=metadata).v_rms/u.km*u.s))\n",
    "        dend1.data[s.indices()]= dat1P#reset the dend data\n",
    "        \n",
    "        dend1.data[s.indices()]-= additional_noise\n",
    "        #s._values+=additional_noise\n",
    "        #print(s.values(),s._values)\n",
    "        \n",
    "        #s2._values-=additional_noise\n",
    "        s = dend1.__getitem__(idx)\n",
    "        #print(dat1P[0],s._values[0],\"kaasl\")\n",
    "        vs.append(float(PPVStatistic(s,metadata=metadata).v_rms/u.km*u.s))\n",
    "        \n",
    "        del s\n",
    "        #del s2\n",
    "        \n",
    "    v_rms_std = np.nanstd(vs)\n",
    "    #print(v_rms_std)\n",
    "    return v_rms_std\n",
    "\n",
    "#Return a cropped cube for some ra and dec, also crops the velocity axis if needed (0 for no crop)\n",
    "def Crop(cube,WCS,Np1,Np2,BadVel,D2):\n",
    "    NraDP1 = [int(WCS.world_to_pixel(Np1)[0]),int(WCS.world_to_pixel(Np1)[1])]\n",
    "    NraDP2 = [int(WCS.world_to_pixel(Np2)[0]),int(WCS.world_to_pixel(Np2)[1])]\n",
    "    if(D2==False):\n",
    "        return cube[BadVel:np.shape(cube)[0]-BadVel,NraDP1[1]:NraDP2[1],NraDP1[0]:NraDP2[0]]\n",
    "    if(D2==True):\n",
    "        return cube[NraDP1[1]:NraDP2[1],NraDP1[0]:NraDP2[0]]\n",
    "\n",
    "    \n",
    "def Read_Clusters(FileName):\n",
    "    \n",
    "    sh= len(np.genfromtxt(FileName,usecols=0))\n",
    "    Data=[]\n",
    "    for lmi in range(50):\n",
    "        try:\n",
    "            Data.append(np.genfromtxt(FileName,usecols=lmi,dtype=type(\"2d4m\")))\n",
    "            #print(np.genfromtxt(FileName,usecols=lmi,dtype=type(\"2d4m\"),skip_header=1))\n",
    "        except:\n",
    "            pass\n",
    "    return Data\n",
    "def Find_Clusters_NGC(Data):\n",
    "    for lmi in range(len(Data)):\n",
    "        if \"ID\" in Data[lmi]:\n",
    "            IDs= Data[lmi][1:9999]\n",
    "        if \"RA\" in Data[lmi]: \n",
    "            RAs= Data[lmi][1:9999]\n",
    "        if \"Dec\" in Data[lmi]:\n",
    "            Decs= Data[lmi][1:9999]\n",
    "        if \"r_deconv\" in Data[lmi]: \n",
    "            R_deconv= Data[lmi][1:9999]#pc\n",
    "        if \"glon\" in Data[lmi]: \n",
    "            glons= Data[lmi][1:9999]#\n",
    "        if \"glat\" in Data[lmi]: \n",
    "            glats= Data[lmi][1:9999]#\n",
    "            \n",
    "    return IDs,RAs,Decs,R_deconv\n",
    "#Take the cont in Jy and find the HWHM from the structures in the catalog\n",
    "def Find_Clusters(Data,wcs,Cont_Data,header):\n",
    "    for lmi in range(len(Data)):\n",
    "        if \"ID\" in Data[lmi]:\n",
    "            IDs= Data[lmi][1:9999]\n",
    "        if \"RA\" in Data[lmi]: \n",
    "            RAs= Data[lmi][1:9999]\n",
    "        if \"Dec\" in Data[lmi]:\n",
    "            Decs= Data[lmi][1:9999]\n",
    "        if \"r_deconv\" in Data[lmi]: \n",
    "            R_deconv= Data[lmi][1:9999]#pc\n",
    "        if \"glon\" in Data[lmi]: \n",
    "            glons= Data[lmi][1:9999]#\n",
    "        if \"glat\" in Data[lmi]: \n",
    "            glats= Data[lmi][1:9999]#\n",
    "        if \"herschel_column\" in Data[lmi]: \n",
    "            CD= (Data[lmi][1:9999])#pc\n",
    "            \n",
    "        if \"flux_integrated\" in Data[lmi]: \n",
    "            Flux_1p3mm= Data[lmi][1:9999]#pc\n",
    "    #remove nan \n",
    "    for lmii in range(len(CD)):\n",
    "        try:\n",
    "            if CD[lmii]=='np.nan':\n",
    "                CD= np.delete(CD, lmii)\n",
    "                Flux_1p3mm= np.delete(Flux_1p3mm, lmii)\n",
    "                IDs= np.delete(IDs, lmii)\n",
    "                glats= np.delete(glats, lmii)\n",
    "                glons= np.delete(glons, lmii)\n",
    "                \n",
    "        except:\n",
    "            CD = np.array(CD,dtype=type(1.2**5))#float\n",
    "            break\n",
    "    glats_New=[]\n",
    "    glons_New=[]\n",
    "    CDs_New=[]\n",
    "    IDs_New=[]\n",
    "    Flux_1p3mm_New=[]\n",
    "\n",
    "    #print(CD,sorted(CD),type(CD),type(CD[0]))\n",
    "    nth = sorted(CD)[len(CD)-34]#34 most dense leaves\n",
    "    #print(nth,\"A\",CD,sorted(CD))\n",
    "    for lmj in range(len(CD)):\n",
    "        if CD[lmj]>nth:\n",
    "            glats_New.append(glats[lmj])\n",
    "            glons_New.append(glons[lmj])\n",
    "            CDs_New.append(CD[lmj])\n",
    "            IDs_New.append(int(IDs[lmj]))\n",
    "            Flux_1p3mm_New.append(Flux_1p3mm[lmj])\n",
    "    HWHM_rad = []      \n",
    "    #print(Flux_1p3mm_New,glats_New,glons_New,CDs_New,IDs_New)\n",
    "    for lmi in range(len(CDs_New)):\n",
    "        glat = glats_New[lmi]\n",
    "        glon = glons_New[lmi]\n",
    "        Flux = float(Flux_1p3mm_New[lmi])#INtegerated flux in jy\n",
    "        \n",
    "        Circle_R = 0\n",
    "        distance = 8.178*10**-3*u.Mpc\n",
    "        \n",
    "        pixel_res = abs(header['cdelt1'])*np.pi/180*distance*10**6/u.Mpc*u.pc # cdelt in deg, goes to res in pc\n",
    "        \n",
    "        #sky = SkyCoord('00h47m33.9s', '-25d17m26.8s', frame='icrs')\n",
    "        sky = SkyCoord(l=float(glon)*u.deg, b=float(glat)*u.deg, frame='galactic')\n",
    "        #center = SkyCoord(l=359.94487501*u.degree,b=-00.04391769*u.degree, frame='galactic')\n",
    "        p1,p2 = int(wcs.world_to_pixel(sky)[0]),int(wcs.world_to_pixel(sky)[1]) #Ra,dec\n",
    "        \n",
    "        while(True):\n",
    "            Circle_R += .01\n",
    "            #pixels=[(p1,p2)]\n",
    "            pixels=[(p2,p1)]#Goes lat then long for the cont data\n",
    "            #print(p1,p2)\n",
    "            #print(np.shape(Cont_Data[p2-50:p2+50]))\n",
    "            #print(np.shape(Cont_Data[50,p1-50:p1+50]))\n",
    "            for lmii in range(np.shape(Cont_Data[p2-50:p2+50])[0]):\n",
    "                for lmjj in range(np.shape(Cont_Data[p2-50+lmii,p1-50:p1+50])[0]):\n",
    "                    #Find pixels within the circle around the center (excude the center since its there already)\n",
    "                    #print(np.sqrt((lmii-50)**2+(lmjj-50)**2)*pixel_res,lmjj)\n",
    "                    if np.sqrt((lmii-50)**2+(lmjj-50)**2)*pixel_res.value < Circle_R and lmjj!=50:\n",
    "                        pixels.append((lmjj-50+p2,lmii-50+p1))#Goes lat then long\n",
    "                        \n",
    "            \n",
    "            \n",
    "            sum_flux=0\n",
    "            for lmkk in range(len(pixels)):\n",
    "                sum_flux += (Cont_Data[pixels[lmkk]])\n",
    "            #print(p1,p2,glat,glon,np.shape(Cont_Data),pixels,Cont_Data[pixels[0]],Flux,sum_flux,Circle_R)\n",
    "            if sum_flux>Flux/2:\n",
    "                HWHM_rad.append(Circle_R)#Pc\n",
    "                break\n",
    "                \n",
    "    return HWHM_rad,CDs_New,glons_New,glats_New,IDs_New\n",
    "\n",
    "#Return masked data around clusters or one pc around clusters\n",
    "def Mask_Clusters_NGC(HWHM,wcs,header,unmasked_data,ras,decs,One_Pc=False,One_Pc_Size=1,HWHM_Fac=1):\n",
    "    \n",
    "    Masked_Data=copy.deepcopy(unmasked_data)\n",
    "    for lmi in range(len(HWHM)):\n",
    "        ra = ras[lmi]\n",
    "        dec = decs[lmi]\n",
    "                \n",
    "        Circle_R = HWHM[lmi]*HWHM_Fac\n",
    "        if(One_Pc):\n",
    "            \n",
    "            Circle_R=One_Pc_Size\n",
    "        distance = 3.5*u.Mpc\n",
    "        \n",
    "        pixel_res = abs(header['cdelt1'])*np.pi/180*distance*10**6/u.Mpc*u.pc # cdelt in deg, goes to res in pc\n",
    "        \n",
    "        #sky = SkyCoord('00h47m33.9s', '-25d17m26.8s', frame='icrs')\n",
    "        sky = SkyCoord(str(ra),str(dec), frame='icrs')\n",
    "        #center = SkyCoord(l=359.94487501*u.degree,b=-00.04391769*u.degree, frame='galactic')\n",
    "        p1,p2 = int(wcs.world_to_pixel(sky)[0]),int(wcs.world_to_pixel(sky)[1]) #Ra,dec\n",
    "        \n",
    "\n",
    "\n",
    "        #pixels=[(p1,p2)]\n",
    "        pixels=[(p2,p1)]#Goes lat then long for the cont data\n",
    "        #print(p1,p2)\n",
    "        #print(np.shape(Cont_Data[p2-50:p2+50]))\n",
    "        #print(np.shape(Cont_Data[50,p1-50:p1+50]))\n",
    "        for lmii in range(np.shape(unmasked_data[0,p2-50:p2+50])[0]):\n",
    "            for lmjj in range(np.shape(unmasked_data[0,p2-50+lmii,p1-50:p1+50])[0]):\n",
    "                #Find pixels within the circle around the center (excude the center since its there already)\n",
    "                #print(np.sqrt((lmii-50)**2+(lmjj-50)**2)*pixel_res,lmjj)\n",
    "                \n",
    "                if np.sqrt((lmii-50)**2+(lmjj-50)**2)*pixel_res.value < Circle_R and lmjj!=50:\n",
    "                    pixels.append((lmjj-50+p2,lmii-50+p1))#Goes lat then long\n",
    "        \n",
    "        for lmi in range(len(unmasked_data)):\n",
    "            \n",
    "            for lmj in range(len(pixels)):\n",
    "                #print(Masked_Data[lmi,pixels[lmj][0],pixels[lmj][1]],lmi,pixels,np.shape(Masked_Data))\n",
    "                Masked_Data[lmi,pixels[lmj][0],pixels[lmj][1]]=np.nan\n",
    "                #print(Masked_Data[lmi,pixels[lmj][0],pixels[lmj][1]],lmi,pixels,np.shape(Masked_Data))\n",
    "     \n",
    "    return Masked_Data\n",
    "            \n",
    "#Make_Plot(\"Tes\",\"Test2\",Q.moment0().hdu.data,0,0,Q.wcs[:][:][0],2,2,1,True)\n",
    "#Make_Plot(\"Tes\",\"Test2\",Q.moment0().hdu.data,0,0,Q.wcs[:][:][0],2,2,2,True)\n",
    "\n",
    "if(os.path.exists(\"./Result Files\")):\n",
    "    print(\"Results will be saved to ./Result Files\")\n",
    "else:\n",
    "    %mkdir \"./Result Files\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
