{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdc0ed5b-634f-455a-80e0-6f7bfa128b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ben/miniconda3/bin/python\n",
      "3.8.5 (default, Sep  4 2020, 07:30:14) \n",
      "[GCC 7.3.0]\n",
      "sys.version_info(major=3, minor=8, micro=5, releaselevel='final', serial=0)\n",
      "astropy 5.1.dev153+gb740594dc\n",
      "reproject 0.8\n",
      "spectral_cube 0.6.1.dev22+g003ef16\n",
      "/home/ben/.local/lib/python3.8/site-packages/spectral_cube/__init__.py\n",
      "/home/ben/.local/lib/python3.8/site-packages/astrodendro/__init__.py\n",
      "1.23.1 Numpy\n",
      "Results will be saved to ./Result Files\n"
     ]
    }
   ],
   "source": [
    "######################################################################################################################################################################################################################################\n",
    "######################################################################################################################################################################################################################################\n",
    "######################################################################################################################################################################################################################################\n",
    "\n",
    "#Need this so that the other files can get the imports.\n",
    "#Put it in the same directory as the file you want to run.\n",
    "\n",
    "######################################################################################################################################################################################################################################\n",
    "######################################################################################################################################################################################################################################\n",
    "######################################################################################################################################################################################################################################\n",
    "\n",
    "\n",
    "import sys, traceback\n",
    "print(sys.executable)\n",
    "print(sys.version)\n",
    "print(sys.version_info)\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "import math\n",
    "import astropy\n",
    "print('astropy',astropy.__version__ )\n",
    "from spectral_cube import SpectralCube      # This is a handy package for working with 3D data cubes\n",
    "from spectral_cube import LazyMask\n",
    "from astropy.coordinates import SkyCoord\n",
    "from reproject import reproject_interp      \n",
    "from reproject.mosaicking import find_optimal_celestial_wcs \n",
    "import regions\n",
    "import reproject\n",
    "print('reproject',reproject.__version__)\n",
    "import spectral_cube\n",
    "print('spectral_cube',spectral_cube.__version__)\n",
    "import numpy as np                          \n",
    "import pylab                                \n",
    "import matplotlib \n",
    "import matplotlib.gridspec as gridspec                                                                                             \n",
    "import scipy\n",
    "import astropy.io.fits as fits                                                          \n",
    "from astropy.wcs import WCS                 \n",
    "from astropy import units as u              \n",
    "\n",
    "import astrodendro #Change numpy.int to int, modified asscalar to just take an element\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib import pyplot as plt\n",
    "# Suppress warnings we don't care about:\n",
    "import sys\n",
    "import gc\n",
    "from astropy.convolution import Gaussian1DKernel\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "%matplotlib inline\n",
    "from astrodendro.analysis import PPVStatistic\n",
    "import os\n",
    "print(spectral_cube.__file__)\n",
    "\n",
    "print(astrodendro.__file__)\n",
    "\n",
    "from matplotlib.patches import Ellipse\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import radio_beam\n",
    "from astropy.table import Table\n",
    "print(np.__version__,\"Numpy\")\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.optimize import leastsq\n",
    "#%matplotlib widget\n",
    "Num_per_kg= 6.0221409*10**23/(2.8*10**-3)#6.0221409*10**23/29.0180*10**-3#num/kg for h2\n",
    "\n",
    "#Create a function that uses the dendrogram input to calculate all the quantities, and has the size and linewidth requirements of the Shetty paper\n",
    "#Requires the computed dendrogram, the data from the line image, the velocity axis, and the data from the Continuum image, as well as metadata for the structures\n",
    "#Finds Size, Linewidth, Luminosity, and Column Density of a structure for each structure and returns them in [[][]] arrays [Leaves][Branches]\n",
    "#Continuum is in Jansky/Beam, Line data should have the unit specified in the metadata as 'data_unit'\n",
    "gal=\"GC\"\n",
    "\n",
    "dist_cmz = 8.178*10**-3*u.Mpc\n",
    "\n",
    "def Dendro_Arrays(Dendrogram,LineData,DataVel,ContData,metadata,ColD = True,beam_size=999,beam_req = 999999,Trunks=True,max_size=18,edge_cases=False):\n",
    "    SizeA,SigmaA,LuminA,CDA,SIDS,MOM0_FLUX,Distances,V_rms_err = [[],[],[],[]],[[],[],[],[]],[[],[]],[[],[]],[[],[]],[[],[]],[[],[]],[[],[]]\n",
    "    print(metadata)\n",
    "    \n",
    "    d_copy= Dendrogram\n",
    "    #catalog = astrodendro.ppv_catalog(d, metadata)\n",
    "    if (gal ==\"GC\"):\n",
    "        center = SkyCoord('-00d03m20.76s  ', '-00d02m46.176s', frame='galactic')\n",
    "        dist_val=8.178*10**3\n",
    "    else:\n",
    "        center = SkyCoord('00h47m33.14s' ,'-25d17m17.52s',frame='icrs')\n",
    "        dist_val=3.5*10**6\n",
    "    \n",
    "    center_ra_pix,center_dec_pix = int(metadata['wcsu'][:][:][0].world_to_pixel(center)[0]),int(metadata['wcsu'][:][:][0].world_to_pixel(center)[1])\n",
    "    \n",
    "    sliced= LineData[6]\n",
    "    CubeShape = np.shape(sliced)\n",
    "    DataShape=[[0,0],[0,0]]#The part of the cube that actually has data\n",
    "\n",
    "    for lmi in range(CubeShape[0]):\n",
    "        allData=np.nansum(sliced[lmi])\n",
    "        if(allData>0 or allData<0):\n",
    "            DataShape[0][0] = lmi+3\n",
    "            break\n",
    "    for lmi in range(CubeShape[0]):\n",
    "        allData=np.nansum(sliced[CubeShape[0] - lmi -1])\n",
    "        if(allData>0 or allData<0):\n",
    "            DataShape[0][1] = CubeShape[0] - lmi -3\n",
    "            break\n",
    "    for lmi in range(CubeShape[1]):\n",
    "        allData=(sliced[DataShape[0][0],lmi])\n",
    "        if(allData>0 or allData<0):\n",
    "            DataShape[1][0] = lmi+3\n",
    "            break\n",
    "    for lmi in range(CubeShape[1]):\n",
    "        allData=(sliced[DataShape[0][0],CubeShape[1] - lmi -1])\n",
    "        if(allData>0 or allData<0):\n",
    "            DataShape[1][1] = CubeShape[1] - lmi -3\n",
    "            break\n",
    "    for t in Dendrogram.all_structures: \n",
    "\n",
    "        I = t.indices()\n",
    "        Cont = True\n",
    "        if t.is_branch:\n",
    "                if t.parent==None:\n",
    "                    \n",
    "                    if(Trunks):\n",
    "                        Cont = True\n",
    "                    else:\n",
    "                        Cont = False\n",
    "                else:\n",
    "                    Cont=True\n",
    "                    \n",
    "        for lmi in range(len(I[0])):\n",
    "            if(I[1][lmi]<=DataShape[0][0] or I[1][lmi]>=DataShape[0][1] or I[2][lmi]<=DataShape[1][0] or I[2][lmi]>=DataShape[1][1]):\n",
    "                #print(I[1][lmi],I[0][lmi])\n",
    "                if edge_cases:\n",
    "                    Cont=True\n",
    "                else:\n",
    "                    Cont=False\n",
    "                break\n",
    "                \n",
    "\n",
    "        if(Cont):\n",
    "            s = PPVStatistic(t,metadata=metadata)\n",
    "            s_radius = s.radius\n",
    "            s_v_rms = s.v_rms\n",
    "            \n",
    "            \n",
    "            if((float((s_radius*np.pi/180*dist_val/10**6/u.deg)))*10**6<max_size and (float((s_radius*np.pi/180*dist_val/10**6/u.deg)))*10**6>beam_size*beam_req and (float(s_v_rms/u.km*u.s))>.01):\n",
    "            \n",
    "            \n",
    "\n",
    "                nproj_pix=len(set(zip(*tuple(I[i] for i in [1,2]))))\n",
    "                v_IWM = np.nansum(LineData[I]*(DataVel[I[0]])/u.km*u.s)/np.nansum(LineData[I])\n",
    "                sig_Sh = np.sqrt(np.nansum(LineData[I]*((DataVel[I[0]])/u.km*u.s-v_IWM)**2)/np.nansum(LineData[I])) \n",
    "                \n",
    "                #The flux from the continuum\n",
    "                #Convert to Jansky from Jansky per beam:\n",
    "                if(ColD ==True):\n",
    "                    Cont_Flux=0\n",
    "\n",
    "                    proj = tuple(set(zip(*tuple(I[i] for i in [1,2]))))\n",
    "                    for lmi in range(len(proj)):\n",
    "\n",
    "                        Cont_Flux+=ContData[proj[lmi]]\n",
    "                    Cont_Flux=Cont_Flux/(metadata['beam_area_ratioc']*(2*np.sqrt(2*np.log(2))))*u.pix**2*u.beam/u.beam*u.Jy#SHould be input as Jansky /beam and will be converted to Jansky, then to unitless. The beam is changed from FWHM to Gaussian\n",
    "                    Dust_Column = Flux_to_Mass(Cont_Flux)*Num_per_kg/((s_radius*np.pi/180*dist_cmz.value/u.deg)**2*(3.086*10**24)**2)/np.pi*(1.989*10**30*u.kg/u.M_sun)/u.kg\n",
    "                    \n",
    "                else:\n",
    "                    Dust_Column=0\n",
    "                if(str(Dust_Column) == str(np.nan) or str(Dust_Column)==str(np.inf)):\n",
    "                    Dust_Column=0\n",
    "                lum = Flux_to_Lum(s.flux)\n",
    "                s_flux = s.flux\n",
    "\n",
    "                Index = tuple(I[i] for i in [0,1,2])\n",
    "                K_Km_s_Flux=np.nansum(LineData[Index]*metadata[\"velocity_scale\"])#Find the total flux from the structures in K km/s, assuming the input data is in K as it should be, \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                Distance = np.sqrt((float(s.x_cen/u.pix)-center_ra_pix)**2+(float(s.y_cen/u.pix)- center_dec_pix)**2)*metadata['spatial_scale']*np.pi/180*dist_cmz.value*10**6/u.deg#pc dist from barycenter\n",
    "                \n",
    "                \n",
    "                V_err= Get_V_rms_err(dend1=d_copy,idx=int(t.idx),struct=t,m=m,NF=1,iterations=5,metadata=metadata)\n",
    "                \n",
    "                \n",
    "                if(t.is_leaf):\n",
    "\n",
    "                    SizeA[0].append((float((s_radius*np.pi/180*dist_val/10**6/u.deg)))) #define size as astrodendro\n",
    "                    SigmaA[0].append((float(s_v_rms/u.km*u.s)))#\n",
    "                    CDA[0].append(float(Dust_Column))\n",
    "                    LuminA[0].append(float(lum*u.Hz*u.s/u.erg))\n",
    "                    SIDS[0].append(float(t.idx))\n",
    "                    MOM0_FLUX[0].append(float(K_Km_s_Flux*u.s/u.km))\n",
    "                    Distances[0].append(float(Distance))\n",
    "                    V_rms_err[0].append(float(V_err))\n",
    "                if(t.is_branch\t):\n",
    "\n",
    "                    SizeA[1].append((float((s_radius*np.pi/180*dist_val/10**6/u.deg)))) #define size as astrodendro\n",
    "                    SigmaA[1].append((float(s_v_rms/u.km*u.s)))#\n",
    "                    CDA[1].append(float(Dust_Column))\n",
    "                    LuminA[1].append(float(lum*u.Hz*u.s/u.erg))\n",
    "                    SIDS[1].append(float(t.idx))\n",
    "                    MOM0_FLUX[1].append(float(K_Km_s_Flux*u.s/u.km))\n",
    "                    Distances[1].append(float(Distance))\n",
    "                    V_rms_err[1].append(float(V_err))\n",
    "                del s\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "    SizeA[0] = np.array(SizeA[0],dtype=type(1.))\n",
    "    SizeA[1] = np.array(SizeA[1],dtype=type(1.))\n",
    "    SizeA[2] = np.array(SizeA[2],dtype=type(1.))\n",
    "    SizeA[3] = np.array(SizeA[3],dtype=type(1.))\n",
    "    SigmaA[0] = np.array(SigmaA[0],dtype=type(1.))\n",
    "    SigmaA[1] = np.array(SigmaA[1],dtype=type(1.))\n",
    "    SigmaA[2] = np.array(SigmaA[2],dtype=type(1.))\n",
    "    SigmaA[3] = np.array(SigmaA[3],dtype=type(1.))\n",
    "    CDA[0] = np.array(CDA[0],dtype=type(1.))\n",
    "    CDA[1] = np.array(CDA[1],dtype=type(1.))\n",
    "    LuminA[0] = np.array(LuminA[0],dtype=type(1.))\n",
    "    LuminA[1] = np.array(LuminA[1],dtype=type(1.))\n",
    "    SIDS[0] = np.array(SIDS[0],dtype=type(1.))\n",
    "    SIDS[1] = np.array(SIDS[1],dtype=type(1.))\n",
    "    MOM0_FLUX[0] = np.array(MOM0_FLUX[0],dtype=type(1.))\n",
    "    MOM0_FLUX[1] = np.array(MOM0_FLUX[1],dtype=type(1.))\n",
    "    Distances[0] = np.array(Distances[0],dtype=type(1.))\n",
    "    Distances[1] = np.array(Distances[1],dtype=type(1.))\n",
    "    V_rms_err[0] = np.array(V_rms_err[0],dtype=type(1.))\n",
    "    V_rms_err[1] = np.array(V_rms_err[1],dtype=type(1.))\n",
    "    \n",
    "    return np.array(SizeA),np.array(SigmaA),np.array(CDA),np.array(LuminA),np.array(SIDS),np.array(MOM0_FLUX),np.array(Distances),np.array(V_rms_err)\n",
    "\n",
    "#Make a function to make an image \n",
    "\n",
    "#Data to plot, minimum of color bar, maximum, WCS projection for coords, and position of the image in the larger figure\n",
    "def Make_Plot(Name,Name2,Data,vmin,vmax,WCS,rows,columns,index,show):\n",
    "    \n",
    "\n",
    "    ax = pylab.subplot(rows,columns,index,projection=WCS) \n",
    "    RA = ax.coords[0]                                                                  # \n",
    "    Dec = ax.coords[1]\n",
    "    im = pylab.imshow(Data,vmin=vmin,vmax=vmax,cmap='rainbow')\n",
    "    RA.set_ticks(size=-3)                                                                                      \n",
    "    Dec.set_ticks(size=-3) \n",
    "    RA.set_ticklabel(exclude_overlapping=True) \n",
    "    Dec.set_ticklabel(exclude_overlapping=True)                                                                                     \n",
    "    \n",
    "    if(gal==\"NGC253\"):\n",
    "        pylab.xlabel('Right Ascension',fontsize=20,labelpad=1)                               \n",
    "        pylab.ylabel('Declination',fontsize=20,labelpad=1)\n",
    "    else:\n",
    "        pylab.xlabel('Glon',fontsize=20,labelpad=1)                               \n",
    "        pylab.ylabel('Glat',fontsize=20,labelpad=1)\n",
    "    ax.tick_params(axis = 'both', which = 'major', labelsize = 15)    \n",
    "    cb=pylab.colorbar(im,fraction=0.1,pad=0.0)                                     \n",
    "    cb.set_label(label=Name,fontsize=10,rotation=270,labelpad=20) \n",
    "    cb.ax.tick_params(which = 'major', labelsize = 10)   \n",
    "    pylab.annotate(text=Name2,fontsize=10,xy=(0.02,1.05),xycoords=\"axes fraction\")  \n",
    "    if(show==True):\n",
    "        pylab.show()\n",
    "def Make_Plot_Anno(Name,Name2,Data,vmin,vmax,WCS,rows,columns,index,show,pos1,pos2):\n",
    "    \n",
    "\n",
    "    ax = pylab.subplot(rows,columns,index,projection=WCS) \n",
    "    RA = ax.coords[0]                                                                  # \n",
    "    Dec = ax.coords[1]\n",
    "    im = pylab.imshow(Data,vmin=vmin,vmax=vmax,cmap='rainbow')\n",
    "    RA.set_ticks(size=-3)                                                                                      \n",
    "    Dec.set_ticks(size=-3) \n",
    "    RA.set_ticklabel(exclude_overlapping=True) \n",
    "    Dec.set_ticklabel(exclude_overlapping=True)                                                                                     \n",
    "    if(gal==\"NGC253\"):\n",
    "        pylab.xlabel('Right Ascension',fontsize=20,labelpad=1)                               \n",
    "        pylab.ylabel('Declination',fontsize=20,labelpad=1)\n",
    "    else:\n",
    "        pylab.xlabel('Glon',fontsize=20,labelpad=1)                               \n",
    "        pylab.ylabel('Glat',fontsize=20,labelpad=1)\n",
    "    ax.tick_params(axis = 'both', which = 'major', labelsize = 15)    \n",
    "    cb=pylab.colorbar(im,fraction=.1,pad=0.0)                                     \n",
    "    cb.set_label(label=Name,fontsize=10,rotation=270,labelpad=20) \n",
    "    cb.ax.tick_params(which = 'major', labelsize = 10)   \n",
    "    pylab.annotate(text=Name2,fontsize=10,xy=(pos1,pos2),xycoords=\"axes fraction\")  \n",
    "    if(show==True):\n",
    "        pylab.show()\n",
    "        \n",
    "        \n",
    "#Put this up here for the column density map\n",
    "def Flux_to_Mass(flux):\n",
    "    J_to_e = 10**-23*u.erg/u.s/u.cm**2/u.Hz/u.Jy\n",
    "    flux_erg = flux*J_to_e\n",
    "    if(gal==\"NGC253\"):\n",
    "        L = 4*np.pi*(3.5*3.086*10**24)**2*flux_erg*u.cm**2 #Megaparsec is converted to cm\n",
    "    else:\n",
    "        L = 4*np.pi*(8.178*10**-3*3.086*10**24)**2*flux_erg*u.cm**2 #Megaparsec is converted to cm\n",
    "    \n",
    "    \n",
    "    a_850 = 6.7*10**19*u.erg/u.s/u.Hz/u.M_sun #6.7+-1.7\n",
    "    \n",
    "    M_mol = L/a_850#Just in Solar mass*1.989*10**30*u.kg/u.M_sun #Determines mass of the cont for 850 in kg\n",
    "    return M_mol\n",
    "def Flux_to_Lum(flux):\n",
    "    J_to_e = 10**-23*u.erg/u.s/u.cm**2/u.Hz/u.Jy\n",
    "    flux_erg = flux*J_to_e\n",
    "    if(gal==\"NGC253\"):\n",
    "        L = 4*np.pi*(3.5*3.086*10**24)**2*flux_erg*u.cm**2 #Megaparsec is converted to cm\n",
    "    else:\n",
    "        L = 4*np.pi*(8.178*10**-3*3.086*10**24)**2*flux_erg*u.cm**2 #Megaparsec is converted to cm\n",
    "    \n",
    "    return L\n",
    "\n",
    "\n",
    "def Get_V_rms_err(dend1,struct,idx,m,NF,iterations,metadata):\n",
    "    \n",
    "    \n",
    "    vs=[]\n",
    "    np.random.seed((99)**2*123)\n",
    "    for llll in range(iterations):\n",
    "        \n",
    "        #print(llll)\n",
    "        s = dend1.__getitem__(idx)\n",
    "        #s = struct#copy.deepcopy(struct)\n",
    "        #s2 = struct#copy.deepcopy(struct)\n",
    "        npixels = np.product(np.shape(s.values()))\n",
    "        #print(np.shape(s.values()),s.values())\n",
    "        \n",
    "        additional_noise = np.random.normal(0., m*NF, npixels)\n",
    "        additional_noise = np.reshape(additional_noise, np.shape(s.values()))\n",
    "        #add or subract noise to the values and calculate the v rms, them find the std of that array and\n",
    "        # call that the uncertainty in v rms for a structure\n",
    "        dat1P = dend1.data[s.indices()]\n",
    "        dend1.data[s.indices()]+= additional_noise\n",
    "        s = dend1.__getitem__(idx)\n",
    "        vs.append(float(PPVStatistic(s,metadata=metadata).v_rms/u.km*u.s))\n",
    "        dend1.data[s.indices()]= dat1P#reset the dend data\n",
    "        \n",
    "        dend1.data[s.indices()]-= additional_noise\n",
    "        #s._values+=additional_noise\n",
    "        #print(s.values(),s._values)\n",
    "        \n",
    "        #s2._values-=additional_noise\n",
    "        s = dend1.__getitem__(idx)\n",
    "        #print(dat1P[0],s._values[0],\"kaasl\")\n",
    "        vs.append(float(PPVStatistic(s,metadata=metadata).v_rms/u.km*u.s))\n",
    "        \n",
    "        del s\n",
    "        #del s2\n",
    "        \n",
    "    v_rms_std = np.nanstd(vs)\n",
    "    #print(v_rms_std)\n",
    "    return v_rms_std\n",
    "\n",
    "#Return a cropped cube for some ra and dec, also crops the velocity axis if needed (0 for no crop)\n",
    "def Crop(cube,WCS,Np1,Np2,BadVel,D2):\n",
    "    NraDP1 = [int(WCS.world_to_pixel(Np1)[0]),int(WCS.world_to_pixel(Np1)[1])]\n",
    "    NraDP2 = [int(WCS.world_to_pixel(Np2)[0]),int(WCS.world_to_pixel(Np2)[1])]\n",
    "    if(D2==False):\n",
    "        return cube[BadVel:np.shape(cube)[0]-BadVel,NraDP1[1]:NraDP2[1],NraDP1[0]:NraDP2[0]]\n",
    "    if(D2==True):\n",
    "        return cube[NraDP1[1]:NraDP2[1],NraDP1[0]:NraDP2[0]]\n",
    "\n",
    "    \n",
    "def Read_Clusters(FileName):\n",
    "    \n",
    "    sh= len(np.genfromtxt(FileName,usecols=0))\n",
    "    Data=[]\n",
    "    for lmi in range(50):\n",
    "        try:\n",
    "            Data.append(np.genfromtxt(FileName,usecols=lmi,dtype=type(\"2d4m\")))\n",
    "            #print(np.genfromtxt(FileName,usecols=lmi,dtype=type(\"2d4m\"),skip_header=1))\n",
    "        except:\n",
    "            pass\n",
    "    return Data\n",
    "def Find_Clusters_NGC(Data):\n",
    "    for lmi in range(len(Data)):\n",
    "        if \"ID\" in Data[lmi]:\n",
    "            IDs= Data[lmi][1:9999]\n",
    "        if \"RA\" in Data[lmi]: \n",
    "            RAs= Data[lmi][1:9999]\n",
    "        if \"Dec\" in Data[lmi]:\n",
    "            Decs= Data[lmi][1:9999]\n",
    "        if \"r_deconv\" in Data[lmi]: \n",
    "            R_deconv= Data[lmi][1:9999]#pc\n",
    "        if \"glon\" in Data[lmi]: \n",
    "            glons= Data[lmi][1:9999]#\n",
    "        if \"glat\" in Data[lmi]: \n",
    "            glats= Data[lmi][1:9999]#\n",
    "            \n",
    "    return IDs,RAs,Decs,R_deconv\n",
    "#Take the cont in Jy and find the HWHM from the structures in the catalog\n",
    "def Find_Clusters(Data,wcs,Cont_Data,header):\n",
    "    for lmi in range(len(Data)):\n",
    "        if \"ID\" in Data[lmi]:\n",
    "            IDs= Data[lmi][1:9999]\n",
    "        if \"RA\" in Data[lmi]: \n",
    "            RAs= Data[lmi][1:9999]\n",
    "        if \"Dec\" in Data[lmi]:\n",
    "            Decs= Data[lmi][1:9999]\n",
    "        if \"r_deconv\" in Data[lmi]: \n",
    "            R_deconv= Data[lmi][1:9999]#pc\n",
    "        if \"glon\" in Data[lmi]: \n",
    "            glons= Data[lmi][1:9999]#\n",
    "        if \"glat\" in Data[lmi]: \n",
    "            glats= Data[lmi][1:9999]#\n",
    "        if \"herschel_column\" in Data[lmi]: \n",
    "            CD= (Data[lmi][1:9999])#pc\n",
    "            \n",
    "        if \"flux_integrated\" in Data[lmi]: \n",
    "            Flux_1p3mm= Data[lmi][1:9999]#pc\n",
    "    #remove nan \n",
    "    for lmii in range(len(CD)):\n",
    "        try:\n",
    "            if CD[lmii]=='np.nan':\n",
    "                CD= np.delete(CD, lmii)\n",
    "                Flux_1p3mm= np.delete(Flux_1p3mm, lmii)\n",
    "                IDs= np.delete(IDs, lmii)\n",
    "                glats= np.delete(glats, lmii)\n",
    "                glons= np.delete(glons, lmii)\n",
    "                \n",
    "        except:\n",
    "            CD = np.array(CD,dtype=type(1.2**5))#float\n",
    "            break\n",
    "    glats_New=[]\n",
    "    glons_New=[]\n",
    "    CDs_New=[]\n",
    "    IDs_New=[]\n",
    "    Flux_1p3mm_New=[]\n",
    "\n",
    "    #print(CD,sorted(CD),type(CD),type(CD[0]))\n",
    "    nth = sorted(CD)[len(CD)-34]#34 most dense leaves\n",
    "    #print(nth,\"A\",CD,sorted(CD))\n",
    "    for lmj in range(len(CD)):\n",
    "        if CD[lmj]>nth:\n",
    "            glats_New.append(glats[lmj])\n",
    "            glons_New.append(glons[lmj])\n",
    "            CDs_New.append(CD[lmj])\n",
    "            IDs_New.append(int(IDs[lmj]))\n",
    "            Flux_1p3mm_New.append(Flux_1p3mm[lmj])\n",
    "    HWHM_rad = []      \n",
    "    #print(Flux_1p3mm_New,glats_New,glons_New,CDs_New,IDs_New)\n",
    "    for lmi in range(len(CDs_New)):\n",
    "        glat = glats_New[lmi]\n",
    "        glon = glons_New[lmi]\n",
    "        Flux = float(Flux_1p3mm_New[lmi])#INtegerated flux in jy\n",
    "        \n",
    "        Circle_R = 0\n",
    "        distance = 8.178*10**-3*u.Mpc\n",
    "        \n",
    "        pixel_res = abs(header['cdelt1'])*np.pi/180*distance*10**6/u.Mpc*u.pc # cdelt in deg, goes to res in pc\n",
    "        \n",
    "        #sky = SkyCoord('00h47m33.9s', '-25d17m26.8s', frame='icrs')\n",
    "        sky = SkyCoord(l=float(glon)*u.deg, b=float(glat)*u.deg, frame='galactic')\n",
    "        #center = SkyCoord(l=359.94487501*u.degree,b=-00.04391769*u.degree, frame='galactic')\n",
    "        p1,p2 = int(wcs.world_to_pixel(sky)[0]),int(wcs.world_to_pixel(sky)[1]) #Ra,dec\n",
    "        \n",
    "        while(True):\n",
    "            Circle_R += .01\n",
    "            #pixels=[(p1,p2)]\n",
    "            pixels=[(p2,p1)]#Goes lat then long for the cont data\n",
    "            #print(p1,p2)\n",
    "            #print(np.shape(Cont_Data[p2-50:p2+50]))\n",
    "            #print(np.shape(Cont_Data[50,p1-50:p1+50]))\n",
    "            for lmii in range(np.shape(Cont_Data[p2-50:p2+50])[0]):\n",
    "                for lmjj in range(np.shape(Cont_Data[p2-50+lmii,p1-50:p1+50])[0]):\n",
    "                    #Find pixels within the circle around the center (excude the center since its there already)\n",
    "                    #print(np.sqrt((lmii-50)**2+(lmjj-50)**2)*pixel_res,lmjj)\n",
    "                    if np.sqrt((lmii-50)**2+(lmjj-50)**2)*pixel_res.value < Circle_R and lmjj!=50:\n",
    "                        pixels.append((lmjj-50+p2,lmii-50+p1))#Goes lat then long\n",
    "                        \n",
    "            \n",
    "            \n",
    "            sum_flux=0\n",
    "            for lmkk in range(len(pixels)):\n",
    "                sum_flux += (Cont_Data[pixels[lmkk]])\n",
    "            #print(p1,p2,glat,glon,np.shape(Cont_Data),pixels,Cont_Data[pixels[0]],Flux,sum_flux,Circle_R)\n",
    "            if sum_flux>Flux/2:\n",
    "                HWHM_rad.append(Circle_R)#Pc\n",
    "                break\n",
    "                \n",
    "    return HWHM_rad,CDs_New,glons_New,glats_New,IDs_New\n",
    "\n",
    "#Return masked data around clusters or one pc around clusters\n",
    "def Mask_Clusters_NGC(HWHM,wcs,header,unmasked_data,ras,decs,One_Pc=False,One_Pc_Size=1,HWHM_Fac=1):\n",
    "    \n",
    "    Masked_Data=copy.deepcopy(unmasked_data)\n",
    "    for lmi in range(len(HWHM)):\n",
    "        ra = ras[lmi]\n",
    "        dec = decs[lmi]\n",
    "                \n",
    "        Circle_R = HWHM[lmi]*HWHM_Fac\n",
    "        if(One_Pc):\n",
    "            \n",
    "            Circle_R=One_Pc_Size\n",
    "        distance = 3.5*u.Mpc\n",
    "        \n",
    "        pixel_res = abs(header['cdelt1'])*np.pi/180*distance*10**6/u.Mpc*u.pc # cdelt in deg, goes to res in pc\n",
    "        \n",
    "        #sky = SkyCoord('00h47m33.9s', '-25d17m26.8s', frame='icrs')\n",
    "        sky = SkyCoord(str(ra),str(dec), frame='icrs')\n",
    "        #center = SkyCoord(l=359.94487501*u.degree,b=-00.04391769*u.degree, frame='galactic')\n",
    "        p1,p2 = int(wcs.world_to_pixel(sky)[0]),int(wcs.world_to_pixel(sky)[1]) #Ra,dec\n",
    "        \n",
    "\n",
    "\n",
    "        #pixels=[(p1,p2)]\n",
    "        pixels=[(p2,p1)]#Goes lat then long for the cont data\n",
    "        #print(p1,p2)\n",
    "        #print(np.shape(Cont_Data[p2-50:p2+50]))\n",
    "        #print(np.shape(Cont_Data[50,p1-50:p1+50]))\n",
    "        for lmii in range(np.shape(unmasked_data[0,p2-50:p2+50])[0]):\n",
    "            for lmjj in range(np.shape(unmasked_data[0,p2-50+lmii,p1-50:p1+50])[0]):\n",
    "                #Find pixels within the circle around the center (excude the center since its there already)\n",
    "                #print(np.sqrt((lmii-50)**2+(lmjj-50)**2)*pixel_res,lmjj)\n",
    "                \n",
    "                if np.sqrt((lmii-50)**2+(lmjj-50)**2)*pixel_res.value < Circle_R and lmjj!=50:\n",
    "                    pixels.append((lmjj-50+p2,lmii-50+p1))#Goes lat then long\n",
    "        \n",
    "        for lmi in range(len(unmasked_data)):\n",
    "            \n",
    "            for lmj in range(len(pixels)):\n",
    "                #print(Masked_Data[lmi,pixels[lmj][0],pixels[lmj][1]],lmi,pixels,np.shape(Masked_Data))\n",
    "                Masked_Data[lmi,pixels[lmj][0],pixels[lmj][1]]=np.nan\n",
    "                #print(Masked_Data[lmi,pixels[lmj][0],pixels[lmj][1]],lmi,pixels,np.shape(Masked_Data))\n",
    "     \n",
    "    return Masked_Data\n",
    "            \n",
    "#Make_Plot(\"Tes\",\"Test2\",Q.moment0().hdu.data,0,0,Q.wcs[:][:][0],2,2,1,True)\n",
    "#Make_Plot(\"Tes\",\"Test2\",Q.moment0().hdu.data,0,0,Q.wcs[:][:][0],2,2,2,True)\n",
    "\n",
    "\n",
    "def Mask_Clusters_CMZ(HWHM,wcs,header,unmasked_data,glons,glats,One_Pc=False,One_Pc_Size=1,HWHM_Fac=1):\n",
    "    \n",
    "    Masked_Data=copy.deepcopy(unmasked_data)\n",
    "    for lmi in range(len(HWHM)):\n",
    "        glon = glons[lmi]\n",
    "        glat = glats[lmi]\n",
    "                \n",
    "        Circle_R = HWHM[lmi]*HWHM_Fac\n",
    "        if(One_Pc):\n",
    "            \n",
    "            Circle_R=One_Pc_Size\n",
    "        distance = dist_cmz\n",
    "        \n",
    "        pixel_res = abs(header['cdelt1'])*np.pi/180*distance*10**6/u.Mpc*u.pc # cdelt in deg, goes to res in pc\n",
    "        \n",
    "        #sky = SkyCoord('00h47m33.9s', '-25d17m26.8s', frame='icrs')\n",
    "        sky = SkyCoord(float(glon)*u.deg,float(glat)*u.deg, frame='galactic')\n",
    "        #center = SkyCoord(l=359.94487501*u.degree,b=-00.04391769*u.degree, frame='galactic')\n",
    "        p1,p2 = int(wcs.world_to_pixel(sky)[0]),int(wcs.world_to_pixel(sky)[1]) #Ra,dec\n",
    "        \n",
    "\n",
    "\n",
    "        #pixels=[(p1,p2)]\n",
    "        pixels=[(p2,p1)]#Goes lat then long for the cont data\n",
    "        #print(p1,p2)\n",
    "        #print(np.shape(Cont_Data[p2-50:p2+50]))\n",
    "        #print(np.shape(Cont_Data[50,p1-50:p1+50]))\n",
    "        for lmii in range(np.shape(unmasked_data[0,p2-50:p2+50])[0]):\n",
    "            for lmjj in range(np.shape(unmasked_data[0,p2-50+lmii,p1-50:p1+50])[0]):\n",
    "                #Find pixels within the circle around the center (excude the center since its there already)\n",
    "                #print(np.sqrt((lmii-50)**2+(lmjj-50)**2)*pixel_res,lmjj)\n",
    "                \n",
    "                if np.sqrt((lmii-50)**2+(lmjj-50)**2)*pixel_res.value < Circle_R and lmjj!=50:\n",
    "                    pixels.append((lmjj-50+p2,lmii-50+p1))#Goes lat then long\n",
    "        \n",
    "        for lmi in range(len(unmasked_data)):\n",
    "            \n",
    "            for lmj in range(len(pixels)):\n",
    "                #print(Masked_Data[lmi,pixels[lmj][0],pixels[lmj][1]],lmi,pixels,np.shape(Masked_Data))\n",
    "                Masked_Data[lmi,pixels[lmj][0],pixels[lmj][1]]=np.nan\n",
    "                #print(Masked_Data[lmi,pixels[lmj][0],pixels[lmj][1]],lmi,pixels,np.shape(Masked_Data))\n",
    "     \n",
    "    return Masked_Data\n",
    "            \n",
    "#Make_Plot(\"Tes\",\"Test2\",Q.moment0().hdu.data,0,0,Q.wcs[:][:][0],2,2,1,True)\n",
    "#Make_Plot(\"Tes\",\"Test2\",Q.moment0().hdu.data,0,0,Q.wcs[:][:][0],2,2,2,True)\n",
    "\n",
    "def Crop_Nans(data):\n",
    "\n",
    "    sx,sy,ex,ey=0,0,0,0\n",
    "    for lmi in range(np.shape(data[0,:,:])[0]):\n",
    "\n",
    "        if(ey!=0 and sx!=0 and ex!=0 and sy!=0):\n",
    "            print(\"F\",lmi)\n",
    "            break\n",
    "        for lmj in range(np.shape(data[0,:,:])[1]):\n",
    "\n",
    "            if(sx==0):            \n",
    "                if(np.nanmean(data[0,lmi,:])>0 or np.nanmean(data[0,lmi,:])<0):\n",
    "                    sx=lmi\n",
    "\n",
    "\n",
    "            if(sy==0):\n",
    "                if(np.nanmean(data[0,:,lmj])>0 or np.nanmean(data[0,:,lmj])<0):\n",
    "                    sy=lmj\n",
    "\n",
    "            if(ex==0):\n",
    "                if(np.nanmean(data[0,np.shape(datn[0,:,:])[0]-lmi-1,:])>0 or np.nanmean(data[0,np.shape(data[0,:,:])[0]-lmi-1,:])<0):\n",
    "                    ex=np.shape(data[0,:,:])[0]-lmi-1\n",
    "\n",
    "            if(ey==0):\n",
    "                if(np.nanmean(data[0,:,np.shape(data[0,:,:])[1]-lmj-1])>0 or np.nanmean(data[0,:,np.shape(data[0,:,:])[1]-lmj-1])<0):\n",
    "                    ey=np.shape(data[0,:,:])[1]-lmj-1\n",
    "\n",
    "            if(ey!=0 and ex!=0 and sx!=0 and sy!=0):\n",
    "                break\n",
    "    print(sx,ex,sy,ey)\n",
    "    return sx,ex,sy,ey\n",
    "\n",
    "\n",
    "from astropy.utils import NumpyRNGContext\n",
    "def gaussian_beam(f, beam_gauss_width):\n",
    "    '''\n",
    "    Fourier transform of a Gaussian beam. NOT the power spectrum (multiply exp\n",
    "    argument by 2 for power spectrum).\n",
    "    Parameters\n",
    "    ----------\n",
    "    f : np.ndarray\n",
    "        Frequencies to evaluate beam at.\n",
    "    beam_gauss_width : float\n",
    "        Beam size. Should be the Gaussian rms, not FWHM.\n",
    "    '''\n",
    "    return np.exp(-f**2 * np.pi**2 * 2 * beam_gauss_width**2)\n",
    "\n",
    "def gauss_correlated_noise_2D(shape, sigma, beam_gauss_width,\n",
    "                              randomseed=327485749):\n",
    "    \n",
    "    '''\n",
    "    Generate correlated Gaussian noise with sigma, smoothed by a\n",
    "    Gaussian kernel.\n",
    "    '''\n",
    "\n",
    "    # Making a real signal. Only need real part of FFT\n",
    "    freqs_yy, freqs_xx = np.meshgrid(np.fft.fftfreq(shape[0]),\n",
    "                                     np.fft.rfftfreq(shape[1]), indexing=\"ij\")\n",
    "\n",
    "    freqs = np.sqrt(freqs_yy**2 + freqs_xx**2)\n",
    "    # freqs[freqs == 0.] = np.NaN\n",
    "    # freqs[freqs == 0.] = 1.\n",
    "\n",
    "    imsize = shape[0]\n",
    "\n",
    "    Np1 = (imsize - 1) // 2 if imsize % 2 != 0 else imsize // 2\n",
    "    \n",
    "    with NumpyRNGContext(randomseed):\n",
    "\n",
    "        angles = np.random.uniform(0, 2 * np.pi,\n",
    "                                   size=freqs.shape)\n",
    "\n",
    "    noise = np.cos(angles) + 1j * np.sin(angles)\n",
    "\n",
    "    if imsize % 2 == 0:\n",
    "        noise[1:Np1, 0] = np.conj(noise[imsize:Np1:-1, 0])\n",
    "        noise[1:Np1, -1] = np.conj(noise[imsize:Np1:-1, -1])\n",
    "        noise[Np1, 0] = noise[Np1, 0].real + 1j * 0.0\n",
    "        noise[Np1, -1] = noise[Np1, -1].real + 1j * 0.0\n",
    "\n",
    "    else:\n",
    "        noise[1:Np1 + 1, 0] = np.conj(noise[imsize:Np1:-1, 0])\n",
    "        noise[1:Np1 + 1, -1] = np.conj(noise[imsize:Np1:-1, -1])\n",
    "\n",
    "    # Zero freq components must have no imaginary part to be own conjugate\n",
    "    noise[0, -1] = noise[0, -1].real + 1j * 0.0\n",
    "    noise[0, 0] = noise[0, 0].real + 1j * 0.0\n",
    "\n",
    "    corr_field = np.fft.irfft2(noise *\n",
    "                               gaussian_beam(freqs, beam_gauss_width))\n",
    "\n",
    "    norm = (np.sqrt(np.sum(corr_field**2)) / np.sqrt(corr_field.size)) / sigma\n",
    "\n",
    "    corr_field /= norm\n",
    "    \n",
    "    return corr_field\n",
    "restfreq = 345.79598990 * u.GHz\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#For the ngc253 data we need another function\n",
    "\n",
    "def Dendro_Arrays_NGC(Dendrogram,LineData,DataVel,ContData,metadata,ColD = True,beam_size=999,beam_req = 999999,Edge_Cases=True,Trunks=True,max_size=1):\n",
    "    SizeA,SigmaA,LuminA,CDA,SIDS,MOM0_FLUX,Distances,V_rms_err = [[],[],[],[]],[[],[],[],[]],[[],[]],[[],[]],[[],[]],[[],[]],[[],[]],[[],[]]\n",
    "    print(metadata)\n",
    "    \n",
    "    d_copy= Dendrogram\n",
    "    #catalog = astrodendro.ppv_catalog(d, metadata)\n",
    "    center = SkyCoord('00h47m33.14s' ,'-25d17m17.52s',frame='icrs')\n",
    "    center_ra_pix,center_dec_pix = int(metadata['wcsu'][:][:][0].world_to_pixel(center)[0]),int(metadata['wcsu'][:][:][0].world_to_pixel(center)[1])\n",
    "    sliced= LineData[6]\n",
    "    CubeShape = np.shape(sliced)\n",
    "    for t in Dendrogram.all_structures: \n",
    "\n",
    "        I = t.indices()\n",
    "        Cont = True\n",
    "        if t.is_branch:\n",
    "                if t.parent==None:\n",
    "                    if Trunks:\n",
    "                        Cont=True\n",
    "                    else:\n",
    "                        Cont=False\n",
    "                else:\n",
    "                    Cont = True\n",
    "        \n",
    "        for lmi in range(len(I[0])):\n",
    "            NansNE=0\n",
    "            NansSE=0\n",
    "            NansNW=0\n",
    "            NansSW=0\n",
    "            Length = 10\n",
    "            #I[1][lmi+10]>\n",
    "            if Edge_Cases==False:\n",
    "                for lmj in range(Length):\n",
    "                    #Check four 45 degree prongs from each point and see if they have at least 7 nans in 10 pixels. If that happens its too close to the boundary\n",
    "                    try:\n",
    "\n",
    "                        if(sliced[I[1][lmi]+lmj,I[2][lmi]-lmj]>0 or sliced[I[1][lmi]+lmj,I[2][lmi]-lmj]<0 ):\n",
    "                            pass\n",
    "                        else:\n",
    "                            NansSE+=1\n",
    "                        if(sliced[I[1][lmi]-lmj,I[2][lmi]-lmj]>0 or sliced[I[1][lmi]-lmj,I[2][lmi]-lmj]<0 ):\n",
    "                            pass\n",
    "                        else:\n",
    "                            NansSW+=1\n",
    "                        if(sliced[I[1][lmi]-lmj,I[2][lmi]+lmj]>0 or sliced[I[1][lmi]-lmj,I[2][lmi]+lmj]<0 ):\n",
    "                            pass\n",
    "                        else:\n",
    "                            NansNW+=1\n",
    "                        if(sliced[I[1][lmi]+lmj,I[2][lmi]+lmj]>0 or sliced[I[1][lmi]+lmj,I[2][lmi]+lmj]<0 ):\n",
    "                            pass\n",
    "                        else:\n",
    "                            NansNE+=1\n",
    "                    except:\n",
    "                        #only fails if the I goes close to the boundary of the cube and tries to get a pixel outside the cube\n",
    "                        Cont = False\n",
    "                if(NansNE>Length-3 or NansNW>Length-3 or NansSE>Length-3 or NansSW>Length-3):\n",
    "                    Cont = False\n",
    "\n",
    "                    break\n",
    "\n",
    "        if(Cont):\n",
    "            s = PPVStatistic(t,metadata=metadata)\n",
    "            s_radius = s.radius\n",
    "            s_v_rms = s.v_rms\n",
    "            #print(np.nanmax(I[0]) - np.nanmin(I[0]) )\n",
    "            #if((float((s_radius*np.pi/180*3.5/u.deg)))*10**6<max_size and (float((s_radius*np.pi/180*3.5/u.deg)))*10**6>beam_size*beam_req and (float(s_v_rms/u.km*u.s))>.01 and (np.nanmax(I[0]) - np.nanmin(I[0]))*(float((s_radius*np.pi/180*3.5/u.deg)))*10**6 >3*3):\n",
    "            if((float((s_radius*np.pi/180*3.5/u.deg)))*10**6<max_size and (float((s_radius*np.pi/180*3.5/u.deg)))*10**6>beam_size*beam_req and (float(s_v_rms/u.km*u.s))>.01 and (np.nanmax(I[0]) - np.nanmin(I[0]))>3):\n",
    "            #if((float((s_radius*np.pi/180*3.5/u.deg)))*10**6<max_size and (float((s_radius*np.pi/180*3.5/u.deg)))*10**6>beam_size*beam_req and (float(s_v_rms/u.km*u.s))>.01):\n",
    "            \n",
    "            \n",
    "\n",
    "                nproj_pix=len(set(zip(*tuple(I[i] for i in [1,2]))))\n",
    "                v_IWM = np.nansum(LineData[I]*(DataVel[I[0]])/u.km*u.s)/np.nansum(LineData[I])\n",
    "                sig_Sh = np.sqrt(np.nansum(LineData[I]*((DataVel[I[0]])/u.km*u.s-v_IWM)**2)/np.nansum(LineData[I])) \n",
    "                \n",
    "                #The flux from the continuum\n",
    "                #Convert to Jansky from Jansky per beam:\n",
    "                if(ColD ==True):\n",
    "                    Cont_Flux=0\n",
    "\n",
    "                    proj = tuple(set(zip(*tuple(I[i] for i in [1,2]))))\n",
    "                    for lmi in range(len(proj)):\n",
    "\n",
    "                        Cont_Flux+=ContData[proj[lmi]]\n",
    "                    Cont_Flux=Cont_Flux/(metadata['beam_area_ratioc']*(2*np.sqrt(2*np.log(2))))*u.pix**2*u.beam/u.beam*u.Jy#SHould be input as Jansky /beam and will be converted to Jansky, then to unitless. The beam is changed from FWHM to Gaussian\n",
    "                    Dust_Column = Flux_to_Mass(Cont_Flux)*Num_per_kg/((s_radius*np.pi/180*3.5/u.deg)**2*(3.086*10**24)**2)/np.pi*(1.989*10**30*u.kg/u.M_sun)/u.kg\n",
    "                else:\n",
    "                    Dust_Column=0\n",
    "                if(str(Dust_Column) == str(np.nan) or str(Dust_Column)==str(np.inf)):\n",
    "                    Dust_Column=0\n",
    "                lum = Flux_to_Lum(s.flux)\n",
    "                s_flux = s.flux\n",
    "\n",
    "                Index = tuple(I[i] for i in [0,1,2])\n",
    "                K_Km_s_Flux=np.nansum(LineData[Index]*metadata[\"velocity_scale\"])#Find the total flux from the structures in K km/s, assuming the input data is in K as it should be, \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                Distance = np.sqrt((float(s.x_cen/u.pix)-center_ra_pix)**2+(float(s.y_cen/u.pix)- center_dec_pix)**2)*metadata['spatial_scale']*np.pi/180*3.5*10**6/u.deg#pc dist from barycenter\n",
    "                \n",
    "                \n",
    "                V_err= 0#Get_V_rms_err(dend1=d_copy,idx=int(t.idx),struct=t,m=m,NF=1,iterations=5,metadata=metadata)\n",
    "                \n",
    "                \n",
    "                if(t.is_leaf):\n",
    "\n",
    "                    SizeA[0].append((float((s_radius*np.pi/180*3.5/u.deg)))) #define size as astrodendro\n",
    "                    SigmaA[0].append((float(s_v_rms/u.km*u.s)))#\n",
    "                    CDA[0].append(float(Dust_Column))\n",
    "                    LuminA[0].append(float(lum*u.Hz*u.s/u.erg))\n",
    "                    SIDS[0].append(float(t.idx))\n",
    "                    MOM0_FLUX[0].append(float(K_Km_s_Flux*u.s/u.km))\n",
    "                    Distances[0].append(float(Distance))\n",
    "                    V_rms_err[0].append(float(V_err))\n",
    "                if(t.is_branch\t):\n",
    "\n",
    "                    SizeA[1].append((float((s_radius*np.pi/180*3.5/u.deg)))) #define size as astrodendro\n",
    "                    SigmaA[1].append((float(s_v_rms/u.km*u.s)))#\n",
    "                    CDA[1].append(float(Dust_Column))\n",
    "                    LuminA[1].append(float(lum*u.Hz*u.s/u.erg))\n",
    "                    SIDS[1].append(float(t.idx))\n",
    "                    MOM0_FLUX[1].append(float(K_Km_s_Flux*u.s/u.km))\n",
    "                    Distances[1].append(float(Distance))\n",
    "                    V_rms_err[1].append(float(V_err))\n",
    "                del s\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "    SizeA[0] = np.array(SizeA[0],dtype=type(1.))\n",
    "    SizeA[1] = np.array(SizeA[1],dtype=type(1.))\n",
    "    SizeA[2] = np.array(SizeA[2],dtype=type(1.))\n",
    "    SizeA[3] = np.array(SizeA[3],dtype=type(1.))\n",
    "    SigmaA[0] = np.array(SigmaA[0],dtype=type(1.))\n",
    "    SigmaA[1] = np.array(SigmaA[1],dtype=type(1.))\n",
    "    SigmaA[2] = np.array(SigmaA[2],dtype=type(1.))\n",
    "    SigmaA[3] = np.array(SigmaA[3],dtype=type(1.))\n",
    "    CDA[0] = np.array(CDA[0],dtype=type(1.))\n",
    "    CDA[1] = np.array(CDA[1],dtype=type(1.))\n",
    "    LuminA[0] = np.array(LuminA[0],dtype=type(1.))\n",
    "    LuminA[1] = np.array(LuminA[1],dtype=type(1.))\n",
    "    SIDS[0] = np.array(SIDS[0],dtype=type(1.))\n",
    "    SIDS[1] = np.array(SIDS[1],dtype=type(1.))\n",
    "    MOM0_FLUX[0] = np.array(MOM0_FLUX[0],dtype=type(1.))\n",
    "    MOM0_FLUX[1] = np.array(MOM0_FLUX[1],dtype=type(1.))\n",
    "    Distances[0] = np.array(Distances[0],dtype=type(1.))\n",
    "    Distances[1] = np.array(Distances[1],dtype=type(1.))\n",
    "    V_rms_err[0] = np.array(V_rms_err[0],dtype=type(1.))\n",
    "    V_rms_err[1] = np.array(V_rms_err[1],dtype=type(1.))\n",
    "    \n",
    "    return np.array(SizeA),np.array(SigmaA),np.array(CDA),np.array(LuminA),np.array(SIDS),np.array(MOM0_FLUX),np.array(Distances),np.array(V_rms_err)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#repo func\n",
    "\n",
    "def Reproject_To_Region(File,Prime_Beam,Gal,ovs,FOV,Force_Origins=False,Force_Value_x=0,Force_Value_y=0,i_step=30,Cube_Name_Save=''):\n",
    "    \n",
    "    \n",
    "    #Need to break it up into 30-wide vel slices to do the reprojection (ram-draw too high)?\n",
    "    \n",
    "\n",
    "    \n",
    "    scB = SpectralCube.read(File) #[:] \n",
    "\n",
    "    scB = scB.with_spectral_unit(u.km/u.s,velocity_convention=\"radio\") # Change units from Hz to km/s\n",
    "    \n",
    "    #Put in the right system or not\n",
    "    scB.allow_huge_operations=True\n",
    "    vel,RA,Dec = scB.world[:,0,0]\n",
    "\n",
    "    \n",
    "\n",
    "    for i in range(int(len(scB)/i_step) +1):\n",
    "        try:\n",
    "\n",
    "            sc = scB[i*i_step:i*i_step+i_step]\n",
    "\n",
    "            print('start')\n",
    "\n",
    "            HI = sc.header\n",
    "            Nres=Prime_Beam\n",
    "            if(gal==\"NGC253\"):\n",
    "                dist=3.5*10**6\n",
    "                sc = sc.spectral_slab(0. *u.km / u.s, 501. *u.km / u.s)  # Crop out velocities we don't care about  \n",
    "            if(gal==\"GC\"):\n",
    "                dist=8.178*10**3#pc\n",
    "                sc = sc.spectral_slab(-325. *u.km / u.s, 326. *u.km / u.s)  # Crop out velocities we don't care about  \n",
    "            res=  Nres/(dist)*180/np.pi*u.deg/u.pc#deg corresponding to ~3 pc\n",
    "\n",
    "            beam = radio_beam.Beam(major=res, minor=res, pa=0*u.deg)\n",
    "\n",
    "\n",
    "            sc.allow_huge_operations=True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            #Now that we have a circular beam, this can be done easily:\n",
    "            print('fov crop start')\n",
    "\n",
    "            if(gal == 'GC'):\n",
    "\n",
    "                cdelt_x = u.Quantity(str(np.abs(sc.header['cdelt1']))+sc.header['cunit1'])\n",
    "                cdelt_y = u.Quantity(str(np.abs(sc.header['cdelt2']))+sc.header['cunit2'])\n",
    "                center = SkyCoord('-00d03m20.76s  ', '-00d02m46.176s', frame='galactic')\n",
    "\n",
    "                center_ra_pix,center_dec_pix = int(sc.wcs[:][:][0].world_to_pixel(center)[0]),int(sc.wcs[:][:][0].world_to_pixel(center)[1])\n",
    "\n",
    "                PixFov = [int(FOVp[0]/(cdelt_x/u.deg*np.pi/180*8.178*10**3))/2,int(FOVp[1]/(cdelt_y/u.deg*np.pi/180*8.178*10**3))/2]\n",
    "\n",
    "\n",
    "                pixels = np.zeros(np.shape(sc))  \n",
    "                print(PixFov)\n",
    "                #\n",
    "                #Find all pixels in the fov\n",
    "                #\n",
    "                for lmi in range(np.shape(sc)[0]):\n",
    "                    for lmj in range(np.shape(sc)[1]):\n",
    "                        for lmk in range(np.shape(sc)[2]):\n",
    "\n",
    "                            up_pixels = abs(lmj-center_dec_pix)#Should not be over the fov in the upwards direction (relative to 0 degrees)\n",
    "                            side_pixels = abs(lmk-center_ra_pix)#Should not be over the fov in the side-side direction (relative to 0 degrees)\n",
    "\n",
    "                            if(up_pixels<PixFov[0] and side_pixels<PixFov[1]):\n",
    "\n",
    "                                pixels[lmi][lmj][lmk] = 1#good\n",
    "            elif(gal == 'NGC253'):\n",
    "                #\n",
    "                #\n",
    "                #\n",
    "                center = SkyCoord('00h47m33.14s' ,'-25d17m17.52s',frame='icrs')\n",
    "                cdelt_x = u.Quantity(str(np.abs(sc.header['cdelt1']))+sc.header['cunit1'])\n",
    "                cdelt_y = u.Quantity(str(np.abs(sc.header['cdelt2']))+sc.header['cunit2'])\n",
    "\n",
    "                center_ra_pix,center_dec_pix = [int(sc.wcs[:][:][0].world_to_pixel(center)[0]),int(sc.wcs[:][:][0].world_to_pixel(center)[1])]\n",
    "                PixFov = [int(FOVp[0]/(cdelt_x/u.deg*np.pi/180*3.5*10**6))/2,int(FOVp[1]/(cdelt_y/u.deg*np.pi/180*3.5*10**6))/2]\n",
    "                print(center_ra_pix,center_dec_pix)\n",
    "                print(PixFov)\n",
    "                pixels = np.zeros(np.shape(sc))\n",
    "                print(np.shape(sc))\n",
    "\n",
    "                for lmj in range(np.shape(sc)[1]):\n",
    "                    for lmk in range(np.shape(sc)[2]):\n",
    "                        hypo = np.sqrt(((lmj-center_dec_pix)**2) + (lmk-center_ra_pix)**2)\n",
    "\n",
    "                        if (lmj-center_dec_pix!=0):\n",
    "                            ang = np.arctan(abs(lmk-center_ra_pix)/abs(lmj-center_dec_pix))#Find angle to the center\n",
    "                        else:\n",
    "                            ang = np.pi/2\n",
    "                        if(lmk>center_ra_pix and lmj>center_dec_pix):\n",
    "                            ang*=-1\n",
    "                        elif(lmk<center_ra_pix and lmj<center_dec_pix):\n",
    "                            ang*=-1\n",
    "                        elif(lmk>center_ra_pix and lmj<center_dec_pix):\n",
    "                            if ang >57*np.pi/180:\n",
    "\n",
    "                                ang= -33*np.pi/180+147*np.pi/180-ang#coming from the opposite end of the ra axis now, but projecting still to 33 deg from north.\n",
    "\n",
    "\n",
    "                            else:\n",
    "\n",
    "                                pass\n",
    "                        up_pixels = abs(hypo*np.cos(abs((33*np.pi/180)+ang)))#Should not be over the fov in the upwards direction (relative to 0 degrees)\n",
    "                        side_pixels = abs(hypo*np.sin(abs((33*np.pi/180)+ang)))#Should not be over the fov in the side-side direction (relative to 0 degrees)\n",
    "\n",
    "                        if(up_pixels<PixFov[0] and side_pixels<PixFov[1]):\n",
    "                            for lmi in range(np.shape(sc)[0]):\n",
    "                                pixels[lmi][lmj][lmk] = 1#good\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            bp = np.where(pixels!=1)\n",
    "\n",
    "            #Mask teh pixels outside the fov\n",
    "            scCopy = sc.hdu\n",
    "\n",
    "            scCopy.data[bp]=np.nan\n",
    "            sc = SpectralCube.read(scCopy)\n",
    "            del scCopy\n",
    "\n",
    "\n",
    "            sc.allow_huge_operations=True\n",
    "            datn = sc.hdu.data\n",
    "            sx,sy,ex,ey=0,0,0,0\n",
    "            for lmi in range(np.shape(datn[0,:,:])[0]):\n",
    "\n",
    "                if(ey!=0 and sx!=0 and ex!=0 and sy!=0):\n",
    "                    print(\"F\",lmi)\n",
    "                    break\n",
    "                for lmj in range(np.shape(datn[0,:,:])[1]):\n",
    "\n",
    "                    if(sx==0):            \n",
    "                        if(np.nanmean(datn[0,lmi,:])>0 or np.nanmean(datn[0,lmi,:])<0):\n",
    "                            sx=lmi\n",
    "\n",
    "\n",
    "                    if(sy==0):\n",
    "                        if(np.nanmean(datn[0,:,lmj])>0 or np.nanmean(datn[0,:,lmj])<0):\n",
    "                            sy=lmj\n",
    "\n",
    "                    if(ex==0):\n",
    "                        if(np.nanmean(datn[0,np.shape(datn[0,:,:])[0]-lmi-1,:])>0 or np.nanmean(datn[0,np.shape(datn[0,:,:])[0]-lmi-1,:])<0):\n",
    "                            ex=np.shape(datn[0,:,:])[0]-lmi-1\n",
    "\n",
    "                    if(ey==0):\n",
    "                        if(np.nanmean(datn[0,:,np.shape(datn[0,:,:])[1]-lmj-1])>0 or np.nanmean(datn[0,:,np.shape(datn[0,:,:])[1]-lmj-1])<0):\n",
    "                            ey=np.shape(datn[0,:,:])[1]-lmj-1\n",
    "\n",
    "                    if(ey!=0 and ex!=0 and sx!=0 and sy!=0):\n",
    "                        break\n",
    "            scP = sc[:,sx:ex,sy:ey]\n",
    "            scP_Hdu=scP.hdu\n",
    "            zeros=((scP_Hdu.data[:,:,:]==0))\n",
    "            bp = np.where(zeros)\n",
    "            scP_Hdu.data[bp]=np.nan\n",
    "            sc = SpectralCube.read(scP_Hdu)\n",
    "            del scP\n",
    "            del scP_Hdu\n",
    "            del zeros\n",
    "            del bp\n",
    "            sc.allow_huge_operations=True\n",
    "            print('fov crop end')\n",
    "\n",
    "            print('convolve start')\n",
    "\n",
    "            try:\n",
    "                sc = sc.convolve_to(beam)#Smoothe to circular beam at 3 pc by 3 pc\n",
    "            except:\n",
    "                cdelt_x = u.Quantity(str(np.abs(sc.header['cdelt1']))+sc.header['cunit1'])\n",
    "                cdelt_y = u.Quantity(str(np.abs(sc.header['cdelt2']))+sc.header['cunit2'])\n",
    "                if(cdelt_x>cdelt_y):\n",
    "                    majorBase=cdelt_x\n",
    "                    minorBase=cdelt_y\n",
    "                elif(cdelt_x<cdelt_y):\n",
    "                    majorBase=cdelt_y\n",
    "                    minorBase=cdelt_x\n",
    "                elif(cdelt_x==cdelt_y):\n",
    "                    majorBase=cdelt_x\n",
    "                    minorBase=cdelt_x\n",
    "                BaseBeam = radio_beam.Beam(major=majorBase, minor=minorBase, pa=0*u.deg)\n",
    "\n",
    "                sc = sc.with_beam(BaseBeam)\n",
    "\n",
    "                beam = radio_beam.Beam(major=res, minor=res, pa=0*u.deg)\n",
    "\n",
    "                sc.allow_huge_operations=True\n",
    "                print(sc.shape,np.nanmax(sc.hdu.data),'EA')\n",
    "                #Requires me to edit convolve.py and set allow_huge =True\n",
    "                sc = sc.convolve_to(beam)#Smoothe to circular beam at 3 pc by 3 pc\n",
    "            print('convolve end')\n",
    "            #\n",
    "            #prepare a header for the reprojection\n",
    "            #\n",
    "            if(gal==\"GC\"):\n",
    "                reheader = copy.deepcopy(sc.hdu.header)\n",
    "            else:\n",
    "                reheader = sc.hdu.header\n",
    "\n",
    "\n",
    "            if(gal==\"NGC253\"):\n",
    "                ## Find the number of expected pixels for the new resolution and the location of the left/right, up/down sides \n",
    "                if sc.header['cdelt1']>0:\n",
    "                    pix_x    = (res/ovs).to(u.degree).value\n",
    "                    origin_x = sc.longitude_extrema[0].to(u.degree).value\n",
    "\n",
    "                else:\n",
    "                    pix_x    = -1.*(res/ovs).to(u.degree).value\n",
    "                    origin_x = (sc.longitude_extrema[1]).to(u.degree).value\n",
    "\n",
    "                if sc.header['cdelt2']>0:\n",
    "                    pix_y    = (res/ovs).to(u.degree).value\n",
    "                    origin_y = sc.latitude_extrema[0].to(u.degree).value\n",
    "                else:\n",
    "                    pix_y    = -1.*(res/ovs).to(u.degree).value\n",
    "                    origin_y = sc.latitude_extrema[1].to(u.degree).value\n",
    "\n",
    "                npix_x   = int(np.ceil(np.diff(sc.longitude_extrema, n=1)[0]/np.abs(pix_x)).value)\n",
    "                npix_y   = int(np.ceil(np.diff(sc.latitude_extrema, n=1)[0]/np.abs(pix_y)).value)\n",
    "                print(npix_x,npix_y,pix_x,origin_x,origin_y)\n",
    "            elif gal=='GC':\n",
    "                ## Find the number of expected pixels for the new resolution and the location of the left/right, up/down sides \n",
    "\n",
    "                if sc.header['cdelt1']>0:\n",
    "\n",
    "                    pix_x    = (res/ovs).to(u.degree).value\n",
    "                    origin_x = sc.longitude_extrema[1].to(u.degree).value \n",
    "                    if(Force_Origins):\n",
    "\n",
    "                        origin_x = Force_Value_x[0]#358.6\n",
    "\n",
    "                else:\n",
    "\n",
    "                    pix_x    = -(res/ovs).to(u.degree).value\n",
    "                    origin_x = (sc.longitude_extrema[0]).to(u.degree).value \n",
    "\n",
    "                    if(Force_Origins):\n",
    "                        origin_x = Force_Value_x[1]#.9\n",
    "\n",
    "                if sc.header['cdelt2']>0:\n",
    "\n",
    "                    pix_y    = (res/ovs).to(u.degree).value\n",
    "                    origin_y = sc.latitude_extrema[0].to(u.degree).value\n",
    "\n",
    "                    if(Force_Origins):\n",
    "\n",
    "                        origin_y = Force_Value_y[0]#-.6\n",
    "\n",
    "                else:\n",
    "\n",
    "                    pix_y    = -(res/ovs).to(u.degree).value\n",
    "                    origin_y = sc.latitude_extrema[1].to(u.degree).value\n",
    "\n",
    "                    if(Force_Origins):\n",
    "\n",
    "                        origin_y = Force_Value_y[1]#.6\n",
    "\n",
    "                #manually put in the size to correct for the 360->0 difference and just because it doesnt seem to work\n",
    "                print(\"LA\",((sc.longitude_extrema[0])),(sc.longitude_extrema[1]-360*u.degree),np.abs(pix_x))\n",
    "                print(\"MA\",sc.latitude_extrema,np.abs(pix_y))\n",
    "                npix_x   =int(np.ceil((sc.longitude_extrema[0]-(sc.longitude_extrema[1]-360*u.degree))/np.abs(pix_x)).value)\n",
    "                npix_y   =int(np.ceil(np.diff(sc.latitude_extrema, n=1)[0]/np.abs(pix_y)).value)\n",
    "                if(Force_Origins):\n",
    "                    npix_x   =int(np.diff(Force_Value_x)/np.abs(pix_x))\n",
    "                    npix_y   =int(np.diff(Force_Value_y)/np.abs(pix_y))\n",
    "\n",
    "                print(npix_x,npix_y)\n",
    "\n",
    "\n",
    "            #Correct the header to the expected pixels for the new res\n",
    "\n",
    "            reheader['cdelt1'] = pix_x\n",
    "            reheader['cdelt2'] = pix_y\n",
    "\n",
    "            reheader['naxis1'] = npix_x\n",
    "            reheader['naxis2'] = npix_y\n",
    "\n",
    "            reheader['crval1'] = origin_x\n",
    "            reheader['crval2'] = origin_y\n",
    "\n",
    "            reheader['crpix1'] = 0\n",
    "            reheader['crpix2'] = 0\n",
    "            if(gal==\"GC\"):\n",
    "                reheader['CTYPE1'] = \"GLON-SIN\"\n",
    "                reheader['CTYPE2'] = \"GLAT-SIN\"\n",
    "            elif(gal==\"NGC253\"):\n",
    "                pass\n",
    "            try:\n",
    "                del reheader['lonpole']\n",
    "                del reheader['latpole']\n",
    "                del reheader['wcsaxes']#Dont need these anymore, maybe?\n",
    "                if gal ==\"GC\":\n",
    "\n",
    "                    del reheader['LBOUND1']\n",
    "                    del reheader['LBOUND2']\n",
    "                    del reheader['LBOUND3']\n",
    "                    del reheader.cards['LBOUND1']\n",
    "                    del reheader.cards['LBOUND2']\n",
    "                    del reheader.cards['LBOUND3']\n",
    "\n",
    "                    reheader['LBOUND1']=0\n",
    "                    reheader['LBOUND2']=0\n",
    "                    reheader['LBOUND3']=0\n",
    "\n",
    "                print(\"12312412\")\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "\n",
    "\n",
    "                print(\"-\"*60)\n",
    "                traceback.print_exc(file=sys.stdout)\n",
    "\n",
    "            # regrid cube to target pixel size\n",
    "\n",
    "            print('repo start')\n",
    "\n",
    "            print(np.nanmax(sc),np.shape(sc))#These should be a non zero float and the shape of the cube (30,~1000,~1000)\n",
    "\n",
    "            sc2 = sc.reproject(reheader, order='bilinear', use_memmap=True, filled=True) #Have to change reproject so it deletes output.np before making a new one\n",
    "\n",
    "            del sc\n",
    "\n",
    "            new = SpectralCube(data=sc2.hdu.data,wcs =WCS(sc2.header),header=sc2.header,mask=sc2.mask)\n",
    "            new.allow_huge_operations=True\n",
    "            new = new*sc2[0][0][0].unit\n",
    "            #do this because scs dont like being modified\n",
    "            del sc2\n",
    "            sc2 = new\n",
    "            del new\n",
    "            print('repo end')\n",
    "            print(np.nanmax(sc2),np.shape(sc2))#These should be a non zero float and the shape of the cube (30,~1000,~1000)\n",
    "\n",
    "\n",
    "            Repo_Cube = sc2\n",
    "            del sc2\n",
    "            Repo_Cube.allow_huge_operations=True\n",
    "\n",
    "            #do this again to crop the extra pixels off\n",
    "\n",
    "            sc=Repo_Cube\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            #Write the intermediary cubes that will then be spliced together\n",
    "            #or not\n",
    "            del Repo_Cube\n",
    "\n",
    "            sc.write(str(str(i)+\"_\"+Cube_Name_Save ),overwrite=True)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(kl)\n",
    "            print(\"Failed\")\n",
    "            print(\"-\"*60)\n",
    "            traceback.print_exc(file=sys.stdout)\n",
    "def Splice_vels(Cube_Name_Load):\n",
    "    \n",
    "    for i in range(20):\n",
    "        try:\n",
    "            Cube_Name_Load_p = str(i)+\"_\"+Cube_Name_Load\n",
    "            Cube_Name_Save = Cube_Name_Load\n",
    "\n",
    "            sc=SpectralCube.read((Cube_Name_Load_p)) \n",
    "            print(np.shape(sc),Cube_Name_Load_p)\n",
    "            print(sc.mask,type(sc.mask))\n",
    "\n",
    "            if i==0:\n",
    "                reheader = sc.header\n",
    "                rewcs = sc.wcs\n",
    "\n",
    "\n",
    "            print(type(sc))\n",
    "            if i ==0:\n",
    "                scW=SpectralCube.read((Cube_Name_Load_p))      \n",
    "                mask = scW.mask.include() #Need to create a mask because it doesn't get splcied\n",
    "            else:\n",
    "\n",
    "\n",
    "                if i ==1:\n",
    "                    scW = np.concatenate((scW[:].hdu.data,sc[:].hdu.data),dtype = type(sc))\n",
    "                    print(type(scW))\n",
    "                    mask = np.concatenate((mask[:],sc[:].mask.include()),dtype = type(sc[:].mask.include()))\n",
    "                else:\n",
    "                    scW = np.concatenate((scW[:],sc.hdu.data[:]),dtype = type(sc))\n",
    "                    mask = np.concatenate((mask[:],sc[:].mask.include()),dtype = type(sc[:].mask.include()))\n",
    "\n",
    "\n",
    "            print(np.shape(scW))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    def duh(lol):\n",
    "        gp = np.where(lol!=np.nan)\n",
    "        lol[gp]=True\n",
    "        return lol #Anywhere that has data will be unmasked\n",
    "    reheader[\"NAXIS3\"] = len(scW)\n",
    "    Full_Mask = LazyMask(function = duh,data = mask, wcs = rewcs)\n",
    "    scWsc = SpectralCube(data = scW,wcs = rewcs, header = reheader, mask = Full_Mask)#The spliced cube\n",
    "\n",
    "    scWsc.allow_huge_operations=True\n",
    "    scWsc = scWsc*sc[0][0][0].unit#Add unit back in\n",
    "    del sc\n",
    "\n",
    "\n",
    "    scWsc.write(Cube_Name_Save,overwrite=True)\n",
    "    #scWsc.write(\"NGC_Spliced_Reprojected_Whole_CO_32.fits\",overwrite=True)\n",
    "\n",
    "\n",
    "    print(\"done\")   \n",
    "\n",
    "    \n",
    "    \n",
    "def Repo_Velocity(scp,Cube_Name_Save,spec_grid,G_width):\n",
    "\n",
    "    scWsc_copy = scp\n",
    "    fwhm_factor = np.sqrt(8*np.log(2))\n",
    "    scWsc_copy.write(\"test0.fits\",overwrite=True)\n",
    "\n",
    "    scWsc_copy = scWsc_copy.spectral_smooth(Gaussian1DKernel(G_width/fwhm_factor))#Preserves information from the pixels lost in downsampling\n",
    "    print(\"Smoothed to Gaussian Kernel\",G_width/fwhm_factor)\n",
    "    if(Smoothe_2_5):\n",
    "        scWsc_copy = scWsc_copy.with_spectral_unit(u.km / u.s, velocity_convention='optical', rest_value=restfreq)\n",
    "    scWsc_copy.write(\"test1.fits\",overwrite=True)\n",
    "\n",
    "    scWsc_copy = scWsc_copy.spectral_interpolate(spectral_grid=spec_grid) # Match velocities to -250 251 range  \n",
    "\n",
    "    scWsc_copy.write(Cube_Name_Save,overwrite=True)\n",
    "    gc.collect()\n",
    "    del scWsc_copy\n",
    "\n",
    "    gc.collect()######################################################################\n",
    "\n",
    "\n",
    "\n",
    "      \n",
    "def Crop_nans(Cube_Name_Load,Prime_Beam,vel_prime,):\n",
    "    \n",
    "\n",
    "    Prime_Beam = Min_res*((kl*iter_factor+1))#\n",
    "    if(kl==5):\n",
    "        Prime_Beam = 3*u.pc#Nico\n",
    "        FOVp=[400,800]\n",
    "\n",
    "        if(Match_to_HCO):\n",
    "            Prime_Beam = 4.3*u.pc#Nico\n",
    "            FOVp=[70,360]\n",
    "\n",
    "    else:\n",
    "        FOVp=FOV\n",
    "\n",
    "    print(Prime_Beam)\n",
    "\n",
    "    for km in range(5,6):\n",
    "        vel_prime = min_vel*((km*iter_factor+1))\n",
    "        if(km==5):\n",
    "            vel_prime=2.5\n",
    "            ovs=5\n",
    "        if(Match_to_HCO):\n",
    "            vel_prime=3.3\n",
    "            ovs=3\n",
    "\n",
    "        \n",
    "        Cube_Name_Load = str(Prime_Beam.value)+\"pc_beam_\"+Line_Name+str(FOVp[0])+\"x\"+str(FOVp[1])+'pc_'+str(vel_prime)+'_vel_res_NEW'+Smoothe_title+'.fits'\n",
    "\n",
    "        Cube_Name_Save=str(\"Cropped_\"+Cube_Name_Load)\n",
    "        sc = SpectralCube.read(Cube_Name_Load)\n",
    "        datn = sc.hdu.data\n",
    "\n",
    "        #Get right shape\n",
    "        sx,sy,ex,ey=0,0,0,0\n",
    "        for lmi in range(np.shape(datn[0,:,:])[0]):\n",
    "\n",
    "            if(ey!=0 and sx!=0 and ex!=0 and sy!=0):\n",
    "                break\n",
    "            for lmj in range(np.shape(datn[0,:,:])[1]):\n",
    "\n",
    "                if(sx==0):            \n",
    "                    if(np.nanmean(datn[0,lmi,:])>0 or np.nanmean(datn[0,lmi,:])<0):\n",
    "                        sx=lmi\n",
    "\n",
    "\n",
    "                if(sy==0):\n",
    "                    if(np.nanmean(datn[0,:,lmj])>0 or np.nanmean(datn[0,:,lmj])<0):\n",
    "                        sy=lmj\n",
    "\n",
    "                if(ex==0):\n",
    "                    if(np.nanmean(datn[0,np.shape(datn[0,:,:])[0]-lmi-1,:])>0 or np.nanmean(datn[0,np.shape(datn[0,:,:])[0]-lmi-1,:])<0):\n",
    "                        ex=np.shape(datn[0,:,:])[0]-lmi-1\n",
    "\n",
    "                if(ey==0):\n",
    "                    if(np.nanmean(datn[0,:,np.shape(datn[0,:,:])[1]-lmj-1])>0 or np.nanmean(datn[0,:,np.shape(datn[0,:,:])[1]-lmj-1])<0):\n",
    "                        ey=np.shape(datn[0,:,:])[1]-lmj-1\n",
    "\n",
    "                if(ey!=0 and ex!=0 and sx!=0 and sy!=0):\n",
    "                    break\n",
    "        print(sx,ex,sy,ey)\n",
    "\n",
    "\n",
    "        sc = sc[:,sx:ex,sy:ey]\n",
    "\n",
    "        sc_Hdu=sc.hdu\n",
    "        zeros=((sc_Hdu.data[:,:,:]==0))\n",
    "        bp = np.where(zeros)\n",
    "        sc_Hdu.data[bp]=np.nan\n",
    "        sc = SpectralCube.read(sc_Hdu)\n",
    "\n",
    "        #Crop vel axis if needed\n",
    "\n",
    "        sp=0\n",
    "        for lmi in range(len(sc)):\n",
    "            #Check to see if the slice has been repeated by the interpolation function\n",
    "            if(np.round(np.nanmean(sc[lmi].hdu.data),5)==np.round(np.nanmean(sc[lmi+1].hdu.data),5)):\n",
    "\n",
    "                sp = lmi+1\n",
    "            else:\n",
    "                break\n",
    "        l = len(sc)-1\n",
    "        ep=l\n",
    "        for lmi in range(l):\n",
    "\n",
    "            if(np.round(np.nanmean(sc[l-lmi].hdu.data),5)==np.round(np.nanmean(sc[l-lmi-1].hdu.data),5)):\n",
    "                ep = l-lmi-1\n",
    "\n",
    "            else:\n",
    "                break\n",
    "\n",
    "\n",
    "        sc.allow_huge_operations=True\n",
    "        sc = sc[sp:ep]\n",
    "\n",
    "\n",
    "        sc.write(Cube_Name_Save,overwrite=True)\n",
    "        del sc\n",
    "        del sc_Hdu\n",
    "        gc.collect()\n",
    "        print(kl,km,'ready')\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "def Noise_matching(Input_Cube_Match,Input_Cube_Noisy,Cube_Name_Save,Force_region=False,FVX=0,FVY=0,Force_Noise=False,FNV1=0,FNV2=0):\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    #Find noise for ngc253\n",
    "    \n",
    "\n",
    "    Qp = Input_Cube_Noisy.with_spectral_unit(u.km/u.s,velocity_convention=\"radio\") \n",
    "    Qp.allow_huge_operations=True\n",
    "\n",
    "    Qp = Qp.to(u.K)#Jy to Kelvin\n",
    "\n",
    "    datn = Qp.hdu.data\n",
    "    del Qp\n",
    "\n",
    "\n",
    "    Non_nan=((datn[0,:,int(np.shape(datn)[2]/1.5):int(np.shape(datn)[2]-1)]>0)  | (datn[0,:,int(np.shape(datn)[2]/1.5):int(np.shape(datn)[2]-1)]<0 ))\n",
    "\n",
    "    NGCCO32_Noise = (np.nanstd(datn[0,:,int(np.shape(datn)[2]/1.5):int(np.shape(datn)[2]-1)],where= Non_nan)) #Noise K\n",
    "    print(np.shape(datn))\n",
    "    del datn\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    Qp = Input_Cube_Match\n",
    "    #match noise\n",
    "    Qp.allow_huge_operations=True\n",
    "    Q = Qp.to(u.K)#Jy to Kelvin\n",
    "    del Qp\n",
    "    datn=Q.hdu.data\n",
    "    \n",
    "    if gal ==\"GC\":\n",
    "        Non_nan=((datn[0,:,0:int(np.shape(datn)[2]/2)]>0)  | (datn[0,:,0:int(np.shape(datn)[2]/2)]<0 ))\n",
    "\n",
    "        m = (np.nanstd(datn[0,:,0:int(np.shape(datn)[2]/2)],where= Non_nan)) #Noise K\n",
    "    else:\n",
    "        Non_nan=((datn[0,:,int(np.shape(datn)[2]/1.5):int(np.shape(datn)[2]-1)]>0)  | (datn[0,:,int(np.shape(datn)[2]/1.5):int(np.shape(datn)[2]-1)]<0 ))\n",
    "\n",
    "        m = (np.nanstd(datn[0,:,int(np.shape(datn)[2]/1.5):int(np.shape(datn)[2]-1)],where= Non_nan)) #Noise K\n",
    "\n",
    "    if (Force_Noise):\n",
    "        m = FNV1 #Force a noise Values .037? .115?\n",
    "        NGCCO32_Noise=FNV2\n",
    "    print(m,\"Noise (K) matched to \",NGCCO32_Noise)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    npixels = np.product(Q.hdu.data.shape)\n",
    "\n",
    "    target_noise = float(NGCCO32_Noise)\n",
    "    actual_noise = m\n",
    "    additional_sigma = np.sqrt(np.abs(target_noise**2 - actual_noise**2))\n",
    "\n",
    "    additional_noise = np.random.normal(0., additional_sigma, npixels)\n",
    "    additional_noise = np.reshape(additional_noise, Q.hdu.data.shape)\n",
    "\n",
    "\n",
    "    fwhm_factor = np.sqrt(8*np.log(2))\n",
    "    add_noise = np.zeros(np.shape(datn))\n",
    "    for lmi in range(len(datn)):\n",
    "        new_seed = np.random.randint(1e9)\n",
    "        additional_noise = gauss_correlated_noise_2D(shape=(Q.hdu.data[6].shape[0],Q.hdu.data[6].shape[1]), sigma=additional_sigma, beam_gauss_width=5/fwhm_factor,randomseed=new_seed)\n",
    "        pp=np.where(additional_noise!=np.nan)\n",
    "        add_noise[lmi][pp]=additional_noise[pp]\n",
    "\n",
    "    new_data = datn+add_noise\n",
    "    QCopy = Q.hdu\n",
    "    QCopy.data = new_data\n",
    "    Q = SpectralCube.read(QCopy)\n",
    "    del QCopy\n",
    "\n",
    "    \n",
    "\n",
    "    Q.write(Cube_Name_Save,overwrite=True)\n",
    "    del Q\n",
    "    print(\"Wrote to\",Cube_Name_Save)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#!py -m pip uninstall astropy\n",
    "#!py -m pip install git+https://github.com/astropy/astropy\n",
    "#!pip install emcee\n",
    "!pip install corner\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "!py -m pip install git+https://github.com/radio-astro-tools/spectral-cube.git\n",
    "!py -m pip install reproject\n",
    "!py -m pip install git+https://github.com/radio-astro-tools/spectral-cube.git \n",
    "!py -m pip install pyspeckit\n",
    "!py -m pip install regions\n",
    "!py -m pip install astrodendro\n",
    "!py -m pip  install wcsaxes \n",
    "!py -m pip  install ipympl\n",
    "!py -m pip install dask\n",
    "!py -m pip install radio_beam\n",
    "!py -m pip install casa_formats_io\n",
    "#try:\n",
    "#    !pip install casa_formats_io --no-binary :all:\n",
    "#except:\n",
    "#    !pip install casa_formats_io --no-cache --no-binary :all:\n",
    "\n",
    "!py -m pip  install spectral_cube \n",
    "!py -m pip  install typing \n",
    "!py -m pip install mypy\n",
    "!py -m pip  install typing_extensions \n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "if(os.path.exists(\"./Result Files\")):\n",
    "    print(\"Results will be saved to ./Result Files\")\n",
    "else:\n",
    "    %mkdir \"./Result Files\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
