{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70ef739a-a7c7-4cf7-af18-f90fa538af1d",
   "metadata": {},
   "source": [
    "# 0 Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f5c8564-b572-4681-9045-0d4ddc6bd720",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\b347m182\\Anaconda new\\python.exe\n",
      "3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]\n",
      "sys.version_info(major=3, minor=8, micro=5, releaselevel='final', serial=0)\n",
      "astropy 5.1\n",
      "reproject 0.9.1\n",
      "spectral_cube 0.6.1.dev247+ge29d254\n",
      "C:\\Users\\b347m182\\Anaconda new\\lib\\site-packages\\spectral_cube\\__init__.py\n",
      "C:\\Users\\b347m182\\Anaconda new\\lib\\site-packages\\astrodendro\\__init__.py\n",
      "1.23.0 Numpy\n"
     ]
    }
   ],
   "source": [
    "import sys, traceback\n",
    "print(sys.executable)\n",
    "print(sys.version)\n",
    "print(sys.version_info)\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "import math\n",
    "import astropy\n",
    "print('astropy',astropy.__version__ )\n",
    "from spectral_cube import SpectralCube      # This is a handy package for working with 3D data cubes\n",
    "from spectral_cube import LazyMask\n",
    "from astropy.coordinates import SkyCoord\n",
    "from reproject import reproject_interp      \n",
    "from reproject.mosaicking import find_optimal_celestial_wcs \n",
    "import regions\n",
    "import reproject\n",
    "print('reproject',reproject.__version__)\n",
    "import spectral_cube\n",
    "print('spectral_cube',spectral_cube.__version__)\n",
    "import numpy as np                          \n",
    "import pylab                                \n",
    "import matplotlib \n",
    "import matplotlib.gridspec as gridspec                                                                                             \n",
    "import scipy\n",
    "import astropy.io.fits as fits                                                          \n",
    "from astropy.wcs import WCS                 \n",
    "from astropy import units as u              \n",
    "\n",
    "import astrodendro #Change numpy.int to int, modified asscalar to just take an element\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib import pyplot as plt\n",
    "# Suppress warnings we don't care about:\n",
    "import sys\n",
    "import gc\n",
    "from astropy.convolution import Gaussian1DKernel\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "%matplotlib inline\n",
    "from astrodendro.analysis import PPVStatistic\n",
    "import os\n",
    "print(spectral_cube.__file__)\n",
    "\n",
    "print(astrodendro.__file__)\n",
    "\n",
    "from matplotlib.patches import Ellipse\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import radio_beam\n",
    "from astropy.table import Table\n",
    "print(np.__version__,\"Numpy\")\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.optimize import leastsq\n",
    "#%matplotlib widget\n",
    "Num_per_kg= 6.0221409*10**23/(2.8*10**-3)#6.0221409*10**23/29.0180*10**-3#num/kg for h2\n",
    "\n",
    "#Create a function that uses the dendrogram input to calculate all the quantities, and has the size and linewidth requirements of the Shetty paper\n",
    "#Requires the computed dendrogram, the data from the line image, the velocity axis, and the data from the Continuum image, as well as metadata for the structures\n",
    "#Finds Size, Linewidth, Luminosity, and Column Density of a structure for each structure and returns them in [[][]] arrays [Leaves][Branches]\n",
    "#Continuum is in Jansky/Beam, Line data should have the unit specified in the metadata as 'data_unit'\n",
    "gal=\"GC\"\n",
    "\n",
    "dist_cmz = 8.178*10**-3*u.Mpc\n",
    "\n",
    "def Dendro_Arrays(Dendrogram,LineData,DataVel,ContData,metadata,ColD = True,beam_size=999,beam_req = 999999,Trunks=True,max_size=18,edge_cases=False):\n",
    "    SizeA,SigmaA,LuminA,CDA,SIDS,MOM0_FLUX,Distances,V_rms_err = [[],[],[],[]],[[],[],[],[]],[[],[]],[[],[]],[[],[]],[[],[]],[[],[]],[[],[]]\n",
    "    print(metadata)\n",
    "    \n",
    "    d_copy= Dendrogram\n",
    "    #catalog = astrodendro.ppv_catalog(d, metadata)\n",
    "    if (gal ==\"GC\"):\n",
    "        center = SkyCoord('-00d03m20.76s  ', '-00d02m46.176s', frame='galactic')\n",
    "        dist_val=8.178*10**3\n",
    "    else:\n",
    "        center = SkyCoord('00h47m33.14s' ,'-25d17m17.52s',frame='icrs')\n",
    "        dist_val=3.5*10**6\n",
    "    \n",
    "    center_ra_pix,center_dec_pix = int(metadata['wcsu'][:][:][0].world_to_pixel(center)[0]),int(metadata['wcsu'][:][:][0].world_to_pixel(center)[1])\n",
    "    \n",
    "    sliced= LineData[12]\n",
    "    CubeShape = np.shape(sliced)\n",
    "    DataShape=[[0,0],[0,0]]#The part of the cube that actually has data\n",
    "\n",
    "    for lmi in range(CubeShape[0]):\n",
    "        allData=np.nansum(sliced[lmi])\n",
    "        if(allData>0 or allData<0):\n",
    "            DataShape[0][0] = lmi+3\n",
    "            break\n",
    "    for lmi in range(CubeShape[0]):\n",
    "        allData=np.nansum(sliced[CubeShape[0] - lmi -1])\n",
    "        if(allData>0 or allData<0):\n",
    "            DataShape[0][1] = CubeShape[0] - lmi -3\n",
    "            break\n",
    "    for lmi in range(CubeShape[1]):\n",
    "        allData=(sliced[DataShape[0][0],lmi])\n",
    "        if(allData>0 or allData<0):\n",
    "            DataShape[1][0] = lmi+3\n",
    "            break\n",
    "    for lmi in range(CubeShape[1]):\n",
    "        allData=(sliced[DataShape[0][0],CubeShape[1] - lmi -1])\n",
    "        if(allData>0 or allData<0):\n",
    "            DataShape[1][1] = CubeShape[1] - lmi -3\n",
    "            break\n",
    "    for t in Dendrogram.all_structures: \n",
    "\n",
    "        I = t.indices()\n",
    "        Cont = True\n",
    "        if t.is_branch:\n",
    "                if t.parent==None:\n",
    "                    \n",
    "                    if(Trunks):\n",
    "                        Cont = True\n",
    "                    else:\n",
    "                        Cont = False\n",
    "                else:\n",
    "                    Cont=True\n",
    "                    \n",
    "        for lmi in range(len(I[0])):\n",
    "            if(I[1][lmi]<=DataShape[0][0] or I[1][lmi]>=DataShape[0][1] or I[2][lmi]<=DataShape[1][0] or I[2][lmi]>=DataShape[1][1]):\n",
    "                #print(I[1][lmi],I[0][lmi])\n",
    "                if edge_cases:\n",
    "                    Cont=True\n",
    "                else:\n",
    "                    Cont=False\n",
    "                break\n",
    "                \n",
    "\n",
    "        if(Cont):\n",
    "            s = PPVStatistic(t,metadata=metadata)\n",
    "            s_radius = s.radius\n",
    "            s_v_rms = s.v_rms\n",
    "            \n",
    "            \n",
    "            if((float((s_radius*np.pi/180*dist_val/10**6/u.deg)))*10**6<max_size and (float((s_radius*np.pi/180*dist_val/10**6/u.deg)))*10**6>beam_size*beam_req and (float(s_v_rms/u.km*u.s))>.01):\n",
    "            \n",
    "            \n",
    "\n",
    "                nproj_pix=len(set(zip(*tuple(I[i] for i in [1,2]))))\n",
    "                v_IWM = np.nansum(LineData[I]*(DataVel[I[0]])/u.km*u.s)/np.nansum(LineData[I])\n",
    "                sig_Sh = np.sqrt(np.nansum(LineData[I]*((DataVel[I[0]])/u.km*u.s-v_IWM)**2)/np.nansum(LineData[I])) \n",
    "                \n",
    "                #The flux from the continuum\n",
    "                #Convert to Jansky from Jansky per beam:\n",
    "                if(ColD ==True):\n",
    "                    Cont_Flux=0\n",
    "\n",
    "                    proj = tuple(set(zip(*tuple(I[i] for i in [1,2]))))\n",
    "                    for lmi in range(len(proj)):\n",
    "\n",
    "                        Cont_Flux+=ContData[proj[lmi]]\n",
    "                    Cont_Flux=Cont_Flux/(metadata['beam_area_ratioc']*(2*np.sqrt(2*np.log(2))))*u.pix**2*u.beam/u.beam*u.Jy#SHould be input as Jansky /beam and will be converted to Jansky, then to unitless. The beam is changed from FWHM to Gaussian\n",
    "                    Dust_Column = Flux_to_Mass(Cont_Flux)*Num_per_kg/((s_radius*np.pi/180*dist_cmz.value/u.deg)**2*(3.086*10**24)**2)/np.pi*(1.989*10**30*u.kg/u.M_sun)/u.kg\n",
    "                    \n",
    "                else:\n",
    "                    Dust_Column=0\n",
    "                if(str(Dust_Column) == str(np.nan) or str(Dust_Column)==str(np.inf)):\n",
    "                    Dust_Column=0\n",
    "                lum = Flux_to_Lum(s.flux)\n",
    "                s_flux = s.flux\n",
    "\n",
    "                Index = tuple(I[i] for i in [0,1,2])\n",
    "                K_Km_s_Flux=np.nansum(LineData[Index]*metadata[\"velocity_scale\"])#Find the total flux from the structures in K km/s, assuming the input data is in K as it should be, \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                Distance = np.sqrt((float(s.x_cen/u.pix)-center_ra_pix)**2+(float(s.y_cen/u.pix)- center_dec_pix)**2)*metadata['spatial_scale']*np.pi/180*dist_cmz.value*10**6/u.deg#pc dist from barycenter\n",
    "                \n",
    "                \n",
    "                V_err= Get_V_rms_err(dend1=d_copy,idx=int(t.idx),struct=t,m=m,NF=1,iterations=5,metadata=metadata)\n",
    "                \n",
    "                \n",
    "                if(t.is_leaf):\n",
    "\n",
    "                    SizeA[0].append((float((s_radius*np.pi/180*dist_val/10**6/u.deg)))) #define size as astrodendro\n",
    "                    SigmaA[0].append((float(s_v_rms/u.km*u.s)))#\n",
    "                    CDA[0].append(float(Dust_Column))\n",
    "                    LuminA[0].append(float(lum*u.Hz*u.s/u.erg))\n",
    "                    SIDS[0].append(float(t.idx))\n",
    "                    MOM0_FLUX[0].append(float(K_Km_s_Flux*u.s/u.km))\n",
    "                    Distances[0].append(float(Distance))\n",
    "                    V_rms_err[0].append(float(V_err))\n",
    "                if(t.is_branch\t):\n",
    "\n",
    "                    SizeA[1].append((float((s_radius*np.pi/180*dist_val/10**6/u.deg)))) #define size as astrodendro\n",
    "                    SigmaA[1].append((float(s_v_rms/u.km*u.s)))#\n",
    "                    CDA[1].append(float(Dust_Column))\n",
    "                    LuminA[1].append(float(lum*u.Hz*u.s/u.erg))\n",
    "                    SIDS[1].append(float(t.idx))\n",
    "                    MOM0_FLUX[1].append(float(K_Km_s_Flux*u.s/u.km))\n",
    "                    Distances[1].append(float(Distance))\n",
    "                    V_rms_err[1].append(float(V_err))\n",
    "                del s\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "    SizeA[0] = np.array(SizeA[0],dtype=type(1.))\n",
    "    SizeA[1] = np.array(SizeA[1],dtype=type(1.))\n",
    "    SizeA[2] = np.array(SizeA[2],dtype=type(1.))\n",
    "    SizeA[3] = np.array(SizeA[3],dtype=type(1.))\n",
    "    SigmaA[0] = np.array(SigmaA[0],dtype=type(1.))\n",
    "    SigmaA[1] = np.array(SigmaA[1],dtype=type(1.))\n",
    "    SigmaA[2] = np.array(SigmaA[2],dtype=type(1.))\n",
    "    SigmaA[3] = np.array(SigmaA[3],dtype=type(1.))\n",
    "    CDA[0] = np.array(CDA[0],dtype=type(1.))\n",
    "    CDA[1] = np.array(CDA[1],dtype=type(1.))\n",
    "    LuminA[0] = np.array(LuminA[0],dtype=type(1.))\n",
    "    LuminA[1] = np.array(LuminA[1],dtype=type(1.))\n",
    "    SIDS[0] = np.array(SIDS[0],dtype=type(1.))\n",
    "    SIDS[1] = np.array(SIDS[1],dtype=type(1.))\n",
    "    MOM0_FLUX[0] = np.array(MOM0_FLUX[0],dtype=type(1.))\n",
    "    MOM0_FLUX[1] = np.array(MOM0_FLUX[1],dtype=type(1.))\n",
    "    Distances[0] = np.array(Distances[0],dtype=type(1.))\n",
    "    Distances[1] = np.array(Distances[1],dtype=type(1.))\n",
    "    V_rms_err[0] = np.array(V_rms_err[0],dtype=type(1.))\n",
    "    V_rms_err[1] = np.array(V_rms_err[1],dtype=type(1.))\n",
    "    \n",
    "    return np.array(SizeA),np.array(SigmaA),np.array(CDA),np.array(LuminA),np.array(SIDS),np.array(MOM0_FLUX),np.array(Distances),np.array(V_rms_err)\n",
    "\n",
    "#Make a function to make an image \n",
    "\n",
    "#Data to plot, minimum of color bar, maximum, WCS projection for coords, and position of the image in the larger figure\n",
    "def Make_Plot(Name,Name2,Data,vmin,vmax,WCS,rows,columns,index,show):\n",
    "    \n",
    "\n",
    "    ax = pylab.subplot(rows,columns,index,projection=WCS) \n",
    "    RA = ax.coords[0]                                                                  # \n",
    "    Dec = ax.coords[1]\n",
    "    im = pylab.imshow(Data,vmin=vmin,vmax=vmax,cmap='rainbow')\n",
    "    RA.set_ticks(size=-3)                                                                                      \n",
    "    Dec.set_ticks(size=-3) \n",
    "    RA.set_ticklabel(exclude_overlapping=True) \n",
    "    Dec.set_ticklabel(exclude_overlapping=True)                                                                                     \n",
    "    \n",
    "    if(gal==\"NGC253\"):\n",
    "        pylab.xlabel('Right Ascension',fontsize=20,labelpad=1)                               \n",
    "        pylab.ylabel('Declination',fontsize=20,labelpad=1)\n",
    "    else:\n",
    "        pylab.xlabel('Glon',fontsize=20,labelpad=1)                               \n",
    "        pylab.ylabel('Glat',fontsize=20,labelpad=1)\n",
    "    ax.tick_params(axis = 'both', which = 'major', labelsize = 15)    \n",
    "    cb=pylab.colorbar(im,fraction=0.1,pad=0.0)                                     \n",
    "    cb.set_label(label=Name,fontsize=10,rotation=270,labelpad=20) \n",
    "    cb.ax.tick_params(which = 'major', labelsize = 10)   \n",
    "    pylab.annotate(text=Name2,fontsize=10,xy=(0.02,1.05),xycoords=\"axes fraction\")  \n",
    "    if(show==True):\n",
    "        pylab.show()\n",
    "def Make_Plot_Anno(Name,Name2,Data,vmin,vmax,WCS,rows,columns,index,show,pos1,pos2):\n",
    "    \n",
    "\n",
    "    ax = pylab.subplot(rows,columns,index,projection=WCS) \n",
    "    RA = ax.coords[0]                                                                  # \n",
    "    Dec = ax.coords[1]\n",
    "    im = pylab.imshow(Data,vmin=vmin,vmax=vmax,cmap='rainbow')\n",
    "    RA.set_ticks(size=-3)                                                                                      \n",
    "    Dec.set_ticks(size=-3) \n",
    "    RA.set_ticklabel(exclude_overlapping=True) \n",
    "    Dec.set_ticklabel(exclude_overlapping=True)                                                                                     \n",
    "    if(gal==\"NGC253\"):\n",
    "        pylab.xlabel('Right Ascension',fontsize=20,labelpad=1)                               \n",
    "        pylab.ylabel('Declination',fontsize=20,labelpad=1)\n",
    "    else:\n",
    "        pylab.xlabel('Glon',fontsize=20,labelpad=1)                               \n",
    "        pylab.ylabel('Glat',fontsize=20,labelpad=1)\n",
    "    ax.tick_params(axis = 'both', which = 'major', labelsize = 15)    \n",
    "    cb=pylab.colorbar(im,fraction=.1,pad=0.0)                                     \n",
    "    cb.set_label(label=Name,fontsize=10,rotation=270,labelpad=20) \n",
    "    cb.ax.tick_params(which = 'major', labelsize = 10)   \n",
    "    pylab.annotate(text=Name2,fontsize=10,xy=(pos1,pos2),xycoords=\"axes fraction\")  \n",
    "    if(show==True):\n",
    "        pylab.show()\n",
    "        \n",
    "        \n",
    "#Put this up here for the column density map\n",
    "def Flux_to_Mass(flux):\n",
    "    J_to_e = 10**-23*u.erg/u.s/u.cm**2/u.Hz/u.Jy\n",
    "    flux_erg = flux*J_to_e\n",
    "    if(gal==\"NGC253\"):\n",
    "        L = 4*np.pi*(3.5*3.086*10**24)**2*flux_erg*u.cm**2 #Megaparsec is converted to cm\n",
    "    else:\n",
    "        L = 4*np.pi*(8.178*10**-3*3.086*10**24)**2*flux_erg*u.cm**2 #Megaparsec is converted to cm\n",
    "    \n",
    "    \n",
    "    a_850 = 6.7*10**19*u.erg/u.s/u.Hz/u.M_sun #6.7+-1.7\n",
    "    \n",
    "    M_mol = L/a_850#Just in Solar mass*1.989*10**30*u.kg/u.M_sun #Determines mass of the cont for 850 in kg\n",
    "    return M_mol\n",
    "def Flux_to_Lum(flux):\n",
    "    J_to_e = 10**-23*u.erg/u.s/u.cm**2/u.Hz/u.Jy\n",
    "    flux_erg = flux*J_to_e\n",
    "    if(gal==\"NGC253\"):\n",
    "        L = 4*np.pi*(3.5*3.086*10**24)**2*flux_erg*u.cm**2 #Megaparsec is converted to cm\n",
    "    else:\n",
    "        L = 4*np.pi*(8.178*10**-3*3.086*10**24)**2*flux_erg*u.cm**2 #Megaparsec is converted to cm\n",
    "    \n",
    "    return L\n",
    "\n",
    "\n",
    "def Get_V_rms_err(dend1,struct,idx,m,NF,iterations,metadata):\n",
    "    \n",
    "    \n",
    "    vs=[]\n",
    "    np.random.seed((99)**2*123)\n",
    "    for llll in range(iterations):\n",
    "        \n",
    "        #print(llll)\n",
    "        s = dend1.__getitem__(idx)\n",
    "        #s = struct#copy.deepcopy(struct)\n",
    "        #s2 = struct#copy.deepcopy(struct)\n",
    "        npixels = np.product(np.shape(s.values()))\n",
    "        #print(np.shape(s.values()),s.values())\n",
    "        \n",
    "        additional_noise = np.random.normal(0., m*NF, npixels)\n",
    "        additional_noise = np.reshape(additional_noise, np.shape(s.values()))\n",
    "        #add or subract noise to the values and calculate the v rms, them find the std of that array and\n",
    "        # call that the uncertainty in v rms for a structure\n",
    "        dat1P = dend1.data[s.indices()]\n",
    "        dend1.data[s.indices()]+= additional_noise\n",
    "        s = dend1.__getitem__(idx)\n",
    "        vs.append(float(PPVStatistic(s,metadata=metadata).v_rms/u.km*u.s))\n",
    "        dend1.data[s.indices()]= dat1P#reset the dend data\n",
    "        \n",
    "        dend1.data[s.indices()]-= additional_noise\n",
    "        #s._values+=additional_noise\n",
    "        #print(s.values(),s._values)\n",
    "        \n",
    "        #s2._values-=additional_noise\n",
    "        s = dend1.__getitem__(idx)\n",
    "        #print(dat1P[0],s._values[0],\"kaasl\")\n",
    "        vs.append(float(PPVStatistic(s,metadata=metadata).v_rms/u.km*u.s))\n",
    "        \n",
    "        del s\n",
    "        #del s2\n",
    "        \n",
    "    v_rms_std = np.nanstd(vs)\n",
    "    #print(v_rms_std)\n",
    "    return v_rms_std\n",
    "\n",
    "#Return a cropped cube for some ra and dec, also crops the velocity axis if needed (0 for no crop)\n",
    "def Crop(cube,WCS,Np1,Np2,BadVel,D2):\n",
    "    NraDP1 = [int(WCS.world_to_pixel(Np1)[0]),int(WCS.world_to_pixel(Np1)[1])]\n",
    "    NraDP2 = [int(WCS.world_to_pixel(Np2)[0]),int(WCS.world_to_pixel(Np2)[1])]\n",
    "    if(D2==False):\n",
    "        return cube[BadVel:np.shape(cube)[0]-BadVel,NraDP1[1]:NraDP2[1],NraDP1[0]:NraDP2[0]]\n",
    "    if(D2==True):\n",
    "        return cube[NraDP1[1]:NraDP2[1],NraDP1[0]:NraDP2[0]]\n",
    "\n",
    "    \n",
    "def Read_Clusters(FileName):\n",
    "    \n",
    "    sh= len(np.genfromtxt(FileName,usecols=0))\n",
    "    Data=[]\n",
    "    for lmi in range(50):\n",
    "        try:\n",
    "            Data.append(np.genfromtxt(FileName,usecols=lmi,dtype=type(\"2d4m\")))\n",
    "            #print(np.genfromtxt(FileName,usecols=lmi,dtype=type(\"2d4m\"),skip_header=1))\n",
    "        except:\n",
    "            pass\n",
    "    return Data\n",
    "def Find_Clusters_NGC(Data):\n",
    "    for lmi in range(len(Data)):\n",
    "        if \"ID\" in Data[lmi]:\n",
    "            IDs= Data[lmi][1:9999]\n",
    "        if \"RA\" in Data[lmi]: \n",
    "            RAs= Data[lmi][1:9999]\n",
    "        if \"Dec\" in Data[lmi]:\n",
    "            Decs= Data[lmi][1:9999]\n",
    "        if \"r_deconv\" in Data[lmi]: \n",
    "            R_deconv= Data[lmi][1:9999]#pc\n",
    "        if \"glon\" in Data[lmi]: \n",
    "            glons= Data[lmi][1:9999]#\n",
    "        if \"glat\" in Data[lmi]: \n",
    "            glats= Data[lmi][1:9999]#\n",
    "            \n",
    "    return IDs,RAs,Decs,R_deconv\n",
    "#Take the cont in Jy and find the HWHM from the structures in the catalog\n",
    "def Find_Clusters(Data,wcs,Cont_Data,header):\n",
    "    for lmi in range(len(Data)):\n",
    "        if \"ID\" in Data[lmi]:\n",
    "            IDs= Data[lmi][1:9999]\n",
    "        if \"RA\" in Data[lmi]: \n",
    "            RAs= Data[lmi][1:9999]\n",
    "        if \"Dec\" in Data[lmi]:\n",
    "            Decs= Data[lmi][1:9999]\n",
    "        if \"r_deconv\" in Data[lmi]: \n",
    "            R_deconv= Data[lmi][1:9999]#pc\n",
    "        if \"glon\" in Data[lmi]: \n",
    "            glons= Data[lmi][1:9999]#\n",
    "        if \"glat\" in Data[lmi]: \n",
    "            glats= Data[lmi][1:9999]#\n",
    "        if \"herschel_column\" in Data[lmi]: \n",
    "            CD= (Data[lmi][1:9999])#pc\n",
    "            \n",
    "        if \"flux_integrated\" in Data[lmi]: \n",
    "            Flux_1p3mm= Data[lmi][1:9999]#pc\n",
    "    #remove nan \n",
    "    for lmii in range(len(CD)):\n",
    "        try:\n",
    "            if CD[lmii]=='np.nan':\n",
    "                CD= np.delete(CD, lmii)\n",
    "                Flux_1p3mm= np.delete(Flux_1p3mm, lmii)\n",
    "                IDs= np.delete(IDs, lmii)\n",
    "                glats= np.delete(glats, lmii)\n",
    "                glons= np.delete(glons, lmii)\n",
    "                \n",
    "        except:\n",
    "            CD = np.array(CD,dtype=type(1.2**5))#float\n",
    "            break\n",
    "    glats_New=[]\n",
    "    glons_New=[]\n",
    "    CDs_New=[]\n",
    "    IDs_New=[]\n",
    "    Flux_1p3mm_New=[]\n",
    "\n",
    "    #print(CD,sorted(CD),type(CD),type(CD[0]))\n",
    "    nth = sorted(CD)[len(CD)-34]#34 most dense leaves\n",
    "    #print(nth,\"A\",CD,sorted(CD))\n",
    "    for lmj in range(len(CD)):\n",
    "        if CD[lmj]>nth:\n",
    "            glats_New.append(glats[lmj])\n",
    "            glons_New.append(glons[lmj])\n",
    "            CDs_New.append(CD[lmj])\n",
    "            IDs_New.append(int(IDs[lmj]))\n",
    "            Flux_1p3mm_New.append(Flux_1p3mm[lmj])\n",
    "    HWHM_rad = []      \n",
    "    #print(Flux_1p3mm_New,glats_New,glons_New,CDs_New,IDs_New)\n",
    "    for lmi in range(len(CDs_New)):\n",
    "        glat = glats_New[lmi]\n",
    "        glon = glons_New[lmi]\n",
    "        Flux = float(Flux_1p3mm_New[lmi])#INtegerated flux in jy\n",
    "        \n",
    "        Circle_R = 0\n",
    "        distance = 8.178*10**-3*u.Mpc\n",
    "        \n",
    "        pixel_res = abs(header['cdelt1'])*np.pi/180*distance*10**6/u.Mpc*u.pc # cdelt in deg, goes to res in pc\n",
    "        \n",
    "        #sky = SkyCoord('00h47m33.9s', '-25d17m26.8s', frame='icrs')\n",
    "        sky = SkyCoord(l=float(glon)*u.deg, b=float(glat)*u.deg, frame='galactic')\n",
    "        #center = SkyCoord(l=359.94487501*u.degree,b=-00.04391769*u.degree, frame='galactic')\n",
    "        p1,p2 = int(wcs.world_to_pixel(sky)[0]),int(wcs.world_to_pixel(sky)[1]) #Ra,dec\n",
    "        \n",
    "        while(True):\n",
    "            Circle_R += .01\n",
    "            #pixels=[(p1,p2)]\n",
    "            pixels=[(p2,p1)]#Goes lat then long for the cont data\n",
    "            #print(p1,p2)\n",
    "            #print(np.shape(Cont_Data[p2-50:p2+50]))\n",
    "            #print(np.shape(Cont_Data[50,p1-50:p1+50]))\n",
    "            for lmii in range(np.shape(Cont_Data[p2-50:p2+50])[0]):\n",
    "                for lmjj in range(np.shape(Cont_Data[p2-50+lmii,p1-50:p1+50])[0]):\n",
    "                    #Find pixels within the circle around the center (excude the center since its there already)\n",
    "                    #print(np.sqrt((lmii-50)**2+(lmjj-50)**2)*pixel_res,lmjj)\n",
    "                    if np.sqrt((lmii-50)**2+(lmjj-50)**2)*pixel_res.value < Circle_R and lmjj!=50:\n",
    "                        pixels.append((lmjj-50+p2,lmii-50+p1))#Goes lat then long\n",
    "                        \n",
    "            \n",
    "            \n",
    "            sum_flux=0\n",
    "            for lmkk in range(len(pixels)):\n",
    "                sum_flux += (Cont_Data[pixels[lmkk]])\n",
    "            #print(p1,p2,glat,glon,np.shape(Cont_Data),pixels,Cont_Data[pixels[0]],Flux,sum_flux,Circle_R)\n",
    "            if sum_flux>Flux/2:\n",
    "                HWHM_rad.append(Circle_R)#Pc\n",
    "                break\n",
    "                \n",
    "    return HWHM_rad,CDs_New,glons_New,glats_New,IDs_New\n",
    "\n",
    "#Return masked data around clusters or one pc around clusters\n",
    "def Mask_Clusters_NGC(HWHM,wcs,header,unmasked_data,ras,decs,One_Pc=False,One_Pc_Size=1,HWHM_Fac=1):\n",
    "    \n",
    "    Masked_Data=copy.deepcopy(unmasked_data)\n",
    "    for lmi in range(len(HWHM)):\n",
    "        ra = ras[lmi]\n",
    "        dec = decs[lmi]\n",
    "                \n",
    "        Circle_R = HWHM[lmi]*HWHM_Fac\n",
    "        if(One_Pc):\n",
    "            \n",
    "            Circle_R=One_Pc_Size\n",
    "        distance = 3.5*u.Mpc\n",
    "        \n",
    "        pixel_res = abs(header['cdelt1'])*np.pi/180*distance*10**6/u.Mpc*u.pc # cdelt in deg, goes to res in pc\n",
    "        \n",
    "        #sky = SkyCoord('00h47m33.9s', '-25d17m26.8s', frame='icrs')\n",
    "        sky = SkyCoord(str(ra),str(dec), frame='icrs')\n",
    "        #center = SkyCoord(l=359.94487501*u.degree,b=-00.04391769*u.degree, frame='galactic')\n",
    "        p1,p2 = int(wcs.world_to_pixel(sky)[0]),int(wcs.world_to_pixel(sky)[1]) #Ra,dec\n",
    "        \n",
    "\n",
    "\n",
    "        #pixels=[(p1,p2)]\n",
    "        pixels=[(p2,p1)]#Goes lat then long for the cont data\n",
    "        #print(p1,p2)\n",
    "        #print(np.shape(Cont_Data[p2-50:p2+50]))\n",
    "        #print(np.shape(Cont_Data[50,p1-50:p1+50]))\n",
    "        for lmii in range(np.shape(unmasked_data[0,p2-50:p2+50])[0]):\n",
    "            for lmjj in range(np.shape(unmasked_data[0,p2-50+lmii,p1-50:p1+50])[0]):\n",
    "                #Find pixels within the circle around the center (excude the center since its there already)\n",
    "                #print(np.sqrt((lmii-50)**2+(lmjj-50)**2)*pixel_res,lmjj)\n",
    "                \n",
    "                if np.sqrt((lmii-50)**2+(lmjj-50)**2)*pixel_res.value < Circle_R and lmjj!=50:\n",
    "                    pixels.append((lmjj-50+p2,lmii-50+p1))#Goes lat then long\n",
    "        \n",
    "        for lmi in range(len(unmasked_data)):\n",
    "            \n",
    "            for lmj in range(len(pixels)):\n",
    "                #print(Masked_Data[lmi,pixels[lmj][0],pixels[lmj][1]],lmi,pixels,np.shape(Masked_Data))\n",
    "                Masked_Data[lmi,pixels[lmj][0],pixels[lmj][1]]=np.nan\n",
    "                #print(Masked_Data[lmi,pixels[lmj][0],pixels[lmj][1]],lmi,pixels,np.shape(Masked_Data))\n",
    "     \n",
    "    return Masked_Data\n",
    "            \n",
    "#Make_Plot(\"Tes\",\"Test2\",Q.moment0().hdu.data,0,0,Q.wcs[:][:][0],2,2,1,True)\n",
    "#Make_Plot(\"Tes\",\"Test2\",Q.moment0().hdu.data,0,0,Q.wcs[:][:][0],2,2,2,True)\n",
    "\n",
    "\n",
    "def Mask_Clusters_CMZ(HWHM,wcs,header,unmasked_data,glons,glats,One_Pc=False,One_Pc_Size=1,HWHM_Fac=1):\n",
    "    \n",
    "    Masked_Data=copy.deepcopy(unmasked_data)\n",
    "    for lmi in range(len(HWHM)):\n",
    "        glon = glons[lmi]\n",
    "        glat = glats[lmi]\n",
    "                \n",
    "        Circle_R = HWHM[lmi]*HWHM_Fac\n",
    "        if(One_Pc):\n",
    "            \n",
    "            Circle_R=One_Pc_Size\n",
    "        distance = dist_cmz\n",
    "        \n",
    "        pixel_res = abs(header['cdelt1'])*np.pi/180*distance*10**6/u.Mpc*u.pc # cdelt in deg, goes to res in pc\n",
    "        \n",
    "        #sky = SkyCoord('00h47m33.9s', '-25d17m26.8s', frame='icrs')\n",
    "        sky = SkyCoord(float(glon)*u.deg,float(glat)*u.deg, frame='galactic')\n",
    "        #center = SkyCoord(l=359.94487501*u.degree,b=-00.04391769*u.degree, frame='galactic')\n",
    "        p1,p2 = int(wcs.world_to_pixel(sky)[0]),int(wcs.world_to_pixel(sky)[1]) #Ra,dec\n",
    "        \n",
    "\n",
    "\n",
    "        #pixels=[(p1,p2)]\n",
    "        pixels=[(p2,p1)]#Goes lat then long for the cont data\n",
    "        #print(p1,p2)\n",
    "        #print(np.shape(Cont_Data[p2-50:p2+50]))\n",
    "        #print(np.shape(Cont_Data[50,p1-50:p1+50]))\n",
    "        for lmii in range(np.shape(unmasked_data[0,p2-50:p2+50])[0]):\n",
    "            for lmjj in range(np.shape(unmasked_data[0,p2-50+lmii,p1-50:p1+50])[0]):\n",
    "                #Find pixels within the circle around the center (excude the center since its there already)\n",
    "                #print(np.sqrt((lmii-50)**2+(lmjj-50)**2)*pixel_res,lmjj)\n",
    "                \n",
    "                if np.sqrt((lmii-50)**2+(lmjj-50)**2)*pixel_res.value < Circle_R and lmjj!=50:\n",
    "                    pixels.append((lmjj-50+p2,lmii-50+p1))#Goes lat then long\n",
    "        \n",
    "        for lmi in range(len(unmasked_data)):\n",
    "            \n",
    "            for lmj in range(len(pixels)):\n",
    "                #print(Masked_Data[lmi,pixels[lmj][0],pixels[lmj][1]],lmi,pixels,np.shape(Masked_Data))\n",
    "                Masked_Data[lmi,pixels[lmj][0],pixels[lmj][1]]=np.nan\n",
    "                #print(Masked_Data[lmi,pixels[lmj][0],pixels[lmj][1]],lmi,pixels,np.shape(Masked_Data))\n",
    "     \n",
    "    return Masked_Data\n",
    "            \n",
    "#Make_Plot(\"Tes\",\"Test2\",Q.moment0().hdu.data,0,0,Q.wcs[:][:][0],2,2,1,True)\n",
    "#Make_Plot(\"Tes\",\"Test2\",Q.moment0().hdu.data,0,0,Q.wcs[:][:][0],2,2,2,True)\n",
    "\n",
    "def Crop_Nans(data):\n",
    "\n",
    "    sx,sy,ex,ey=0,0,0,0\n",
    "    for lmi in range(np.shape(data[0,:,:])[0]):\n",
    "\n",
    "        if(ey!=0 and sx!=0 and ex!=0 and sy!=0):\n",
    "            print(\"F\",lmi)\n",
    "            break\n",
    "        for lmj in range(np.shape(data[0,:,:])[1]):\n",
    "\n",
    "            if(sx==0):            \n",
    "                if(np.nanmean(data[0,lmi,:])>0 or np.nanmean(data[0,lmi,:])<0):\n",
    "                    sx=lmi\n",
    "\n",
    "\n",
    "            if(sy==0):\n",
    "                if(np.nanmean(data[0,:,lmj])>0 or np.nanmean(data[0,:,lmj])<0):\n",
    "                    sy=lmj\n",
    "\n",
    "            if(ex==0):\n",
    "                if(np.nanmean(data[0,np.shape(datn[0,:,:])[0]-lmi-1,:])>0 or np.nanmean(data[0,np.shape(data[0,:,:])[0]-lmi-1,:])<0):\n",
    "                    ex=np.shape(data[0,:,:])[0]-lmi-1\n",
    "\n",
    "            if(ey==0):\n",
    "                if(np.nanmean(data[0,:,np.shape(data[0,:,:])[1]-lmj-1])>0 or np.nanmean(data[0,:,np.shape(data[0,:,:])[1]-lmj-1])<0):\n",
    "                    ey=np.shape(data[0,:,:])[1]-lmj-1\n",
    "\n",
    "            if(ey!=0 and ex!=0 and sx!=0 and sy!=0):\n",
    "                break\n",
    "    print(sx,ex,sy,ey)\n",
    "    return sx,ex,sy,ey\n",
    "\n",
    "\n",
    "from astropy.utils import NumpyRNGContext\n",
    "def gaussian_beam(f, beam_gauss_width):\n",
    "    '''\n",
    "    Fourier transform of a Gaussian beam. NOT the power spectrum (multiply exp\n",
    "    argument by 2 for power spectrum).\n",
    "    Parameters\n",
    "    ----------\n",
    "    f : np.ndarray\n",
    "        Frequencies to evaluate beam at.\n",
    "    beam_gauss_width : float\n",
    "        Beam size. Should be the Gaussian rms, not FWHM.\n",
    "    '''\n",
    "    return np.exp(-f**2 * np.pi**2 * 2 * beam_gauss_width**2)\n",
    "\n",
    "def gauss_correlated_noise_2D(shape, sigma, beam_gauss_width,\n",
    "                              randomseed=327485749):\n",
    "    \n",
    "    '''\n",
    "    Generate correlated Gaussian noise with sigma, smoothed by a\n",
    "    Gaussian kernel.\n",
    "    '''\n",
    "\n",
    "    # Making a real signal. Only need real part of FFT\n",
    "    freqs_yy, freqs_xx = np.meshgrid(np.fft.fftfreq(shape[0]),\n",
    "                                     np.fft.rfftfreq(shape[1]), indexing=\"ij\")\n",
    "\n",
    "    freqs = np.sqrt(freqs_yy**2 + freqs_xx**2)\n",
    "    # freqs[freqs == 0.] = np.NaN\n",
    "    # freqs[freqs == 0.] = 1.\n",
    "\n",
    "    imsize = shape[0]\n",
    "\n",
    "    Np1 = (imsize - 1) // 2 if imsize % 2 != 0 else imsize // 2\n",
    "    \n",
    "    with NumpyRNGContext(randomseed):\n",
    "\n",
    "        angles = np.random.uniform(0, 2 * np.pi,\n",
    "                                   size=freqs.shape)\n",
    "\n",
    "    noise = np.cos(angles) + 1j * np.sin(angles)\n",
    "\n",
    "    if imsize % 2 == 0:\n",
    "        noise[1:Np1, 0] = np.conj(noise[imsize:Np1:-1, 0])\n",
    "        noise[1:Np1, -1] = np.conj(noise[imsize:Np1:-1, -1])\n",
    "        noise[Np1, 0] = noise[Np1, 0].real + 1j * 0.0\n",
    "        noise[Np1, -1] = noise[Np1, -1].real + 1j * 0.0\n",
    "\n",
    "    else:\n",
    "        noise[1:Np1 + 1, 0] = np.conj(noise[imsize:Np1:-1, 0])\n",
    "        noise[1:Np1 + 1, -1] = np.conj(noise[imsize:Np1:-1, -1])\n",
    "\n",
    "    # Zero freq components must have no imaginary part to be own conjugate\n",
    "    noise[0, -1] = noise[0, -1].real + 1j * 0.0\n",
    "    noise[0, 0] = noise[0, 0].real + 1j * 0.0\n",
    "\n",
    "    corr_field = np.fft.irfft2(noise *\n",
    "                               gaussian_beam(freqs, beam_gauss_width))\n",
    "\n",
    "    norm = (np.sqrt(np.sum(corr_field**2)) / np.sqrt(corr_field.size)) / sigma\n",
    "\n",
    "    corr_field /= norm\n",
    "    \n",
    "    return corr_field\n",
    "restfreq = 345.79598990 * u.GHz\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#For the ngc253 data we need another function\n",
    "\n",
    "def Dendro_Arrays_NGC(Dendrogram,LineData,DataVel,ContData,metadata,ColD = True,beam_size=999,beam_req = 999999,Edge_Cases=True,Trunks=True,max_size=1):\n",
    "    SizeA,SigmaA,LuminA,CDA,SIDS,MOM0_FLUX,Distances,V_rms_err = [[],[],[],[]],[[],[],[],[]],[[],[]],[[],[]],[[],[]],[[],[]],[[],[]],[[],[]]\n",
    "    print(metadata)\n",
    "    \n",
    "    d_copy= Dendrogram\n",
    "    #catalog = astrodendro.ppv_catalog(d, metadata)\n",
    "    center = SkyCoord('00h47m33.14s' ,'-25d17m17.52s',frame='icrs')\n",
    "    center_ra_pix,center_dec_pix = int(metadata['wcsu'][:][:][0].world_to_pixel(center)[0]),int(metadata['wcsu'][:][:][0].world_to_pixel(center)[1])\n",
    "    sliced= LineData[12]\n",
    "    CubeShape = np.shape(sliced)\n",
    "    for t in Dendrogram.all_structures: \n",
    "\n",
    "        I = t.indices()\n",
    "        Cont = True\n",
    "        if t.is_branch:\n",
    "                if t.parent==None:\n",
    "                    if Trunks:\n",
    "                        Cont=True\n",
    "                    else:\n",
    "                        Cont=False\n",
    "                else:\n",
    "                    Cont = True\n",
    "        \n",
    "        for lmi in range(len(I[0])):\n",
    "            NansNE=0\n",
    "            NansSE=0\n",
    "            NansNW=0\n",
    "            NansSW=0\n",
    "            Length = 10\n",
    "            #I[1][lmi+10]>\n",
    "            for lmj in range(Length):\n",
    "                #Check four 45 degree prongs from each point and see if they have at least 7 nans in 10 pixels. If that happens its too close to the boundary\n",
    "                try:\n",
    "\n",
    "                    if(sliced[I[1][lmi]+lmj,I[2][lmi]-lmj]>0 or sliced[I[1][lmi]+lmj,I[2][lmi]-lmj]<0 ):\n",
    "                        pass\n",
    "                    else:\n",
    "                        NansSE+=1\n",
    "                    if(sliced[I[1][lmi]-lmj,I[2][lmi]-lmj]>0 or sliced[I[1][lmi]-lmj,I[2][lmi]-lmj]<0 ):\n",
    "                        pass\n",
    "                    else:\n",
    "                        NansSW+=1\n",
    "                    if(sliced[I[1][lmi]-lmj,I[2][lmi]+lmj]>0 or sliced[I[1][lmi]-lmj,I[2][lmi]+lmj]<0 ):\n",
    "                        pass\n",
    "                    else:\n",
    "                        NansNW+=1\n",
    "                    if(sliced[I[1][lmi]+lmj,I[2][lmi]+lmj]>0 or sliced[I[1][lmi]+lmj,I[2][lmi]+lmj]<0 ):\n",
    "                        pass\n",
    "                    else:\n",
    "                        NansNE+=1\n",
    "                except:\n",
    "                    #only fails if the I goes close to the boundary of the cube and tries to get a pixel outside the cube\n",
    "                    if not Edge_Cases:\n",
    "                        Cont = False\n",
    "            if(NansNE>Length-3 or NansNW>Length-3 or NansSE>Length-3 or NansSW>Length-3):\n",
    "                if not Edge_Cases:\n",
    "                    Cont = False\n",
    "                \n",
    "                break\n",
    "\n",
    "        if(Cont):\n",
    "            s = PPVStatistic(t,metadata=metadata)\n",
    "            s_radius = s.radius\n",
    "            s_v_rms = s.v_rms\n",
    "            if((float((s_radius*np.pi/180*3.5/u.deg)))*10**6<max_size and (float((s_radius*np.pi/180*3.5/u.deg)))*10**6>beam_size*beam_req and (float(s_v_rms/u.km*u.s))>.01):\n",
    "            \n",
    "            \n",
    "\n",
    "                nproj_pix=len(set(zip(*tuple(I[i] for i in [1,2]))))\n",
    "                v_IWM = np.nansum(LineData[I]*(DataVel[I[0]])/u.km*u.s)/np.nansum(LineData[I])\n",
    "                sig_Sh = np.sqrt(np.nansum(LineData[I]*((DataVel[I[0]])/u.km*u.s-v_IWM)**2)/np.nansum(LineData[I])) \n",
    "                \n",
    "                #The flux from the continuum\n",
    "                #Convert to Jansky from Jansky per beam:\n",
    "                if(ColD ==True):\n",
    "                    Cont_Flux=0\n",
    "\n",
    "                    proj = tuple(set(zip(*tuple(I[i] for i in [1,2]))))\n",
    "                    for lmi in range(len(proj)):\n",
    "\n",
    "                        Cont_Flux+=ContData[proj[lmi]]\n",
    "                    Cont_Flux=Cont_Flux/(metadata['beam_area_ratioc']*(2*np.sqrt(2*np.log(2))))*u.pix**2*u.beam/u.beam*u.Jy#SHould be input as Jansky /beam and will be converted to Jansky, then to unitless. The beam is changed from FWHM to Gaussian\n",
    "                    Dust_Column = Flux_to_Mass(Cont_Flux)*Num_per_kg/((s_radius*np.pi/180*3.5/u.deg)**2*(3.086*10**24)**2)/np.pi*(1.989*10**30*u.kg/u.M_sun)/u.kg\n",
    "                else:\n",
    "                    Dust_Column=0\n",
    "                if(str(Dust_Column) == str(np.nan) or str(Dust_Column)==str(np.inf)):\n",
    "                    Dust_Column=0\n",
    "                lum = Flux_to_Lum(s.flux)\n",
    "                s_flux = s.flux\n",
    "\n",
    "                Index = tuple(I[i] for i in [0,1,2])\n",
    "                K_Km_s_Flux=np.nansum(LineData[Index]*metadata[\"velocity_scale\"])#Find the total flux from the structures in K km/s, assuming the input data is in K as it should be, \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                Distance = np.sqrt((float(s.x_cen/u.pix)-center_ra_pix)**2+(float(s.y_cen/u.pix)- center_dec_pix)**2)*metadata['spatial_scale']*np.pi/180*3.5*10**6/u.deg#pc dist from barycenter\n",
    "                \n",
    "                \n",
    "                V_err= Get_V_rms_err(dend1=d_copy,idx=int(t.idx),struct=t,m=m,NF=1,iterations=5,metadata=metadata)\n",
    "                \n",
    "                \n",
    "                if(t.is_leaf):\n",
    "\n",
    "                    SizeA[0].append((float((s_radius*np.pi/180*3.5/u.deg)))) #define size as astrodendro\n",
    "                    SigmaA[0].append((float(s_v_rms/u.km*u.s)))#\n",
    "                    CDA[0].append(float(Dust_Column))\n",
    "                    LuminA[0].append(float(lum*u.Hz*u.s/u.erg))\n",
    "                    SIDS[0].append(float(t.idx))\n",
    "                    MOM0_FLUX[0].append(float(K_Km_s_Flux*u.s/u.km))\n",
    "                    Distances[0].append(float(Distance))\n",
    "                    V_rms_err[0].append(float(V_err))\n",
    "                if(t.is_branch\t):\n",
    "\n",
    "                    SizeA[1].append((float((s_radius*np.pi/180*3.5/u.deg)))) #define size as astrodendro\n",
    "                    SigmaA[1].append((float(s_v_rms/u.km*u.s)))#\n",
    "                    CDA[1].append(float(Dust_Column))\n",
    "                    LuminA[1].append(float(lum*u.Hz*u.s/u.erg))\n",
    "                    SIDS[1].append(float(t.idx))\n",
    "                    MOM0_FLUX[1].append(float(K_Km_s_Flux*u.s/u.km))\n",
    "                    Distances[1].append(float(Distance))\n",
    "                    V_rms_err[1].append(float(V_err))\n",
    "                del s\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "    SizeA[0] = np.array(SizeA[0],dtype=type(1.))\n",
    "    SizeA[1] = np.array(SizeA[1],dtype=type(1.))\n",
    "    SizeA[2] = np.array(SizeA[2],dtype=type(1.))\n",
    "    SizeA[3] = np.array(SizeA[3],dtype=type(1.))\n",
    "    SigmaA[0] = np.array(SigmaA[0],dtype=type(1.))\n",
    "    SigmaA[1] = np.array(SigmaA[1],dtype=type(1.))\n",
    "    SigmaA[2] = np.array(SigmaA[2],dtype=type(1.))\n",
    "    SigmaA[3] = np.array(SigmaA[3],dtype=type(1.))\n",
    "    CDA[0] = np.array(CDA[0],dtype=type(1.))\n",
    "    CDA[1] = np.array(CDA[1],dtype=type(1.))\n",
    "    LuminA[0] = np.array(LuminA[0],dtype=type(1.))\n",
    "    LuminA[1] = np.array(LuminA[1],dtype=type(1.))\n",
    "    SIDS[0] = np.array(SIDS[0],dtype=type(1.))\n",
    "    SIDS[1] = np.array(SIDS[1],dtype=type(1.))\n",
    "    MOM0_FLUX[0] = np.array(MOM0_FLUX[0],dtype=type(1.))\n",
    "    MOM0_FLUX[1] = np.array(MOM0_FLUX[1],dtype=type(1.))\n",
    "    Distances[0] = np.array(Distances[0],dtype=type(1.))\n",
    "    Distances[1] = np.array(Distances[1],dtype=type(1.))\n",
    "    V_rms_err[0] = np.array(V_rms_err[0],dtype=type(1.))\n",
    "    V_rms_err[1] = np.array(V_rms_err[1],dtype=type(1.))\n",
    "    \n",
    "    return np.array(SizeA),np.array(SigmaA),np.array(CDA),np.array(LuminA),np.array(SIDS),np.array(MOM0_FLUX),np.array(Distances),np.array(V_rms_err)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import corner\n",
    "\n",
    "import pylab                                \n",
    "import matplotlib \n",
    "import matplotlib.gridspec as gridspec                                                                                             \n",
    "import scipy\n",
    "\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib import pyplot as plt\n",
    "# Suppress warnings we don't care about:\n",
    "from matplotlib.patches import Rectangle\n",
    "#%matplotlib widget\n",
    "import matplotlib.gridspec as gridspec\n",
    "################\n",
    "# MCMC FITTING #\n",
    "################\n",
    "\n",
    "###################################################################################################\n",
    "\n",
    "# import required modules\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from scipy.optimize import curve_fit\n",
    "import scipy.optimize as op\n",
    "import emcee\n",
    "import corner\n",
    "\n",
    "\n",
    "###################################################################################################\n",
    "\n",
    "# linear fitting function, i.e. two parameter dimensions\n",
    "def linear(x,a,c):\n",
    "    return a*x+c\n",
    "\n",
    "# equivalent power law function\n",
    "def powlaw(x,a,b):\n",
    "    return b*np.power(x,a)\n",
    "\n",
    "# log likelihood\n",
    "# according to https://ixkael.github.io/fitting-a-line-to-data-a-quick-tutorial/\n",
    "def lnlikelihood(x, y, xerr, yerr, a, c):\n",
    "\n",
    "    # only y errors:\n",
    "    model = linear(x,a,c)\n",
    "    return -0.5*(np.sum((y-model)**2/yerr**2 - np.log(yerr**2)))\n",
    "\n",
    "    # # both x and y errors:\n",
    "    # xyerr = np.sqrt(xerr**2. + yerr**2.)\n",
    "    # model = linear(x, a, c)\n",
    "    # return np.sum(-0.5*((y-model)/xyerr)**2 - 0.5*np.log(2*np.pi)-np.log(xyerr))\n",
    "\n",
    "# negative log likelihood (required to fit maximum likelihood)\n",
    "# according to https://ixkael.github.io/fitting-a-line-to-data-a-quick-tutorial/\n",
    "def neg_lnlikelihood(params, x, y, xerr, yerr):\n",
    "    a, c = params\n",
    "    return -lnlikelihood(x, y, xerr, yerr, a, c)\n",
    "\n",
    "# log prior\n",
    "# simple flat priors on slope and intercept, large range but exclude rediculous values\n",
    "def lnprior(a,c):\n",
    "    if ( 0<a<10 ) and ( -10<c<10 ):\n",
    "        return 0.0\n",
    "    return -np.inf\n",
    "\n",
    "# log probability function\n",
    "# according to https://ixkael.github.io/fitting-a-line-to-data-a-quick-tutorial/\n",
    "def lnprobability(params, x, y, xerr, yerr):\n",
    "    a, c = params\n",
    "    lp = lnprior(a,c)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + lnlikelihood(x, y, xerr, yerr, a, c)\n",
    "\n",
    "\n",
    "####################################################################################################\n",
    "# a class to the actual work and fitting\n",
    "####################################################################################################\n",
    "\n",
    "class MCMC_fit:\n",
    "\n",
    "    def __init__(self, x, y, x_err, y_err):\n",
    "        self.source = None\n",
    "        self.line   = None\n",
    "        self.fit    = False\n",
    "        self.fit_range = [None,None]\n",
    "        self.x      = np.array(x)\n",
    "        self.y      = np.array(y)\n",
    "        self.x_err  = np.array(x_err)\n",
    "        self.y_err  = np.array(y_err)\n",
    "        self.ndim = 2\n",
    "        self.a    = {'ls': None, 'ml': None, 'MCMC': None, 'perc': None}\n",
    "        self.c    = {'ls': None, 'ml': None, 'MCMC': None, 'perc': None}\n",
    "        self.nwalkers = 50\n",
    "        self.nburnin  = 500\n",
    "        self.nsteps   = 5000\n",
    "        self.sampler  = None\n",
    "        self.samples  = None\n",
    "        self.xlabel   = 'x'\n",
    "        self.ylabel   = 'y'\n",
    "        self.figsize  = (6,6)\n",
    "        self.plotcolor = None\n",
    "        self.savepath = None\n",
    "\n",
    "    def mask_bad_values(self):\n",
    "        print(\"masking bad values ...\")\n",
    "        good_vals = np.isfinite(self.x) & np.isfinite(self.y) & np.isfinite(self.x_err) & np.isfinite(self.y_err)\n",
    "        self.x     = self.x[good_vals]\n",
    "        self.y     = self.y[good_vals]\n",
    "        self.x_err = self.x_err[good_vals]\n",
    "        self.y_err = self.y_err[good_vals]\n",
    "\n",
    "    def restrict_range(self, fit_range=[None,None]):\n",
    "        self.fit_range = fit_range\n",
    "        print(\"restricting fit to \"+str(self.fit_range)+\" ...\")\n",
    "        if not ( fit_range[0] == None ):\n",
    "            in_range = self.x > self.fit_range[0]\n",
    "            self.x     = self.x[in_range]\n",
    "            self.y     = self.y[in_range]\n",
    "            self.x_err = self.x_err[in_range]\n",
    "            self.y_err = self.y_err[in_range]\n",
    "        if not ( fit_range[1] == None ):\n",
    "            in_range = self.x < self.fit_range[1]\n",
    "            self.x     = self.x[in_range]\n",
    "            self.y     = self.y[in_range]\n",
    "            self.x_err = self.x_err[in_range]\n",
    "            self.y_err = self.y_err[in_range]\n",
    "\n",
    "    # least squares fit\n",
    "    def least_squares_fit(self):\n",
    "        print(\"least squares fitting ...\")\n",
    "        coeff, covar = curve_fit(linear, self.x, self.y, sigma=self.y_err, p0=[1, 1])\n",
    "        a, c  = coeff\n",
    "        a_err = covar[0][0]\n",
    "        c_err = covar[1][1]\n",
    "        self.a['ls'] = [a,a_err]\n",
    "        self.c['ls'] = [c,c_err]\n",
    "\n",
    "    # maximum likelihood fit\n",
    "    def maximum_likelihood_fit(self):\n",
    "        print(\"maximum likelihood fitting ...\")\n",
    "        result = op.minimize(neg_lnlikelihood, [self.a['ls'][0], self.c['ls'][0]], args=(self.x, self.y, self.x_err, self.y_err))\n",
    "        self.a['ml'], self.c['ml'] = result[\"x\"]\n",
    "\n",
    "    # run MCMC fit\n",
    "    def MCMC_fit(self):\n",
    "        print(\"Bayesian MCMC fitting ...\")\n",
    "        # initial values for walkers from least squares and maximum likelihood fits\n",
    "        init_pos = [np.array([self.a['ml'], self.c['ml']]) +1e-2*np.random.randn(self.ndim) for i in range(self.nwalkers)]\n",
    "        # run MCMC\n",
    "        self.sampler = emcee.EnsembleSampler(self.nwalkers, self.ndim, lnprobability, args=(self.x, self.y, self.x_err, self.y_err))\n",
    "        self.sampler.run_mcmc(init_pos, self.nsteps)\n",
    "        self.samples = self.sampler.chain[:, 50:, :].reshape((-1, self.ndim))\n",
    "        a_percentiles, c_percentiles = np.percentile(self.samples, [16, 50, 84], axis=0).T\n",
    "        self.a['MCMC'] = [a_percentiles[1], a_percentiles[2]-a_percentiles[1], a_percentiles[1]-a_percentiles[0]]\n",
    "        self.c['MCMC'] = [c_percentiles[1], c_percentiles[2]-c_percentiles[1], c_percentiles[1]-c_percentiles[0]]\n",
    "        self.a['perc'] = [a_percentiles[0], a_percentiles[1], a_percentiles[2]]\n",
    "        self.c['perc'] = [c_percentiles[0], c_percentiles[1], c_percentiles[2]]\n",
    "\n",
    "    # plot walkers\n",
    "    def plot_walkers(self):\n",
    "        print(\"plotting walkers ...\")\n",
    "        fig,ax = plt.subplots(2, sharex=True)\n",
    "        for w in np.arange(self.nwalkers):\n",
    "            ax[0].plot(self.sampler.chain[w,:,0], color='k', linestyle='-', alpha=0.1)\n",
    "            ax[1].plot(self.sampler.chain[w,:,1], color='k', linestyle='-', alpha=0.1)\n",
    "        ax[1].set_xlabel('step')\n",
    "        ax[0].set_ylabel('slope a')\n",
    "        ax[1].set_ylabel('intercept c')\n",
    "        ax[1].set_xlim(0,self.nsteps)\n",
    "        mkdir(escape_filename(self.savepath))\n",
    "        fig.savefig(os.path.join(self.savepath, self.source+'.'+self.line+'.walkers.png'), dpi=300, bbox_inches='tight')\n",
    "\n",
    "    # corner plot\n",
    "    def corner_plot(self):\n",
    "        print(\"plotting parameter distributions ...\")\n",
    "        fig = corner.corner(self.samples, labels=['a', 'c'], quantiles=[0.16, 0.5, 0.84], show_titles=True)\n",
    "        mkdir(escape_filename(self.savepath))\n",
    "        fig.savefig(os.path.join(self.savepath, self.source+'.'+self.line+'.corner.png'), dpi=300, bbox_inches='tight')\n",
    "\n",
    "    # plot x - y relation\n",
    "    def plot_x_y(self):\n",
    "        print(\"plotting x - y relation ...\")\n",
    "        fig,ax = plt.subplots(figsize=self.figsize)\n",
    "        ax.scatter(np.power(10,self.x), np.power(10,self.y), marker='.', color='k', label='data', s=1, alpha=0.5, zorder=0)\n",
    "        x = np.logspace(np.min(self.x)-np.log10(1.5), np.max(self.x)+np.log10(1.5), 100)\n",
    "\n",
    "        # plot most likely\n",
    "        ax.plot(x, powlaw(x,self.a['MCMC'][0],np.power(10,self.c['MCMC'][0])), lw=1, color=\"r\", zorder=2, label='50 percentile fit')\n",
    "\n",
    "        # plot random samples\n",
    "        a, c = self.samples[np.random.randint(len(self.samples), size=1)][0]\n",
    "        b = np.power(10,c)\n",
    "        ax.plot(x, powlaw(x,a,b), color=\"k\", alpha=0.1, zorder=2, label='random samples')\n",
    "        for a, c in self.samples[np.random.randint(len(self.samples), size=10)]:\n",
    "            b = np.power(10,c)\n",
    "            ax.plot(x, powlaw(x,a,b), color=\"k\", lw=1, alpha=0.1, zorder=1)\n",
    "\n",
    "        ax.legend()\n",
    "        ax.set_xlabel(self.xlabel)\n",
    "        ax.set_ylabel(self.ylabel)\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_yscale('log')\n",
    "        ax.set_xlim([0.75*np.power(10,np.min(self.x)),1.5*np.power(10,np.max(self.x))])\n",
    "        ax.set_ylim([0.75*np.power(10,np.min(self.y)),  1.5*np.power(10,np.max(self.y))])\n",
    "        mkdir(escape_filename(self.savepath))\n",
    "        fig.savefig(os.path.join(self.savepath, self.source+'.'+self.line+'.xy.png'), dpi=300, bbox_inches='tight')\n",
    "\n",
    "    def list_results(self):\n",
    "        print(\"\\n\\n\")\n",
    "        print(self.source+\" \"+self.line)\n",
    "        print(\"  \"+'{:>10}{:>10}{:>10}'.format('least sq','max like','MCMC'))\n",
    "        print(\"a \"+'{:10.6f}{:10.6f}{:10.6f}'.format(self.a['ls'][0], self.a['ml'], self.a['MCMC'][0]))\n",
    "        print(\"a-\"+'{:10.6f}{:>10}{:10.6f}'.format(  self.a['ls'][1], \"\",           self.a['MCMC'][1]))\n",
    "        print(\"a+\"+'{:10.6f}{:>10}{:10.6f}'.format(  self.a['ls'][1], \"\",           self.a['MCMC'][2]))\n",
    "        print(\"c \"+'{:10.6f}{:10.6f}{:10.6f}'.format(self.c['ls'][0], self.c['ml'], self.c['MCMC'][0]))\n",
    "        print(\"c-\"+'{:10.6f}{:>10}{:10.6f}'.format(  self.c['ls'][1], \"\",           self.c['MCMC'][1]))\n",
    "        print(\"c+\"+'{:10.6f}{:>10}{:10.6f}'.format(  self.c['ls'][1], \"\",           self.c['MCMC'][2]))\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "    def get_y10(self):\n",
    "        \"\"\"Calculate y for a scale of 10. This is more meaningful than the intercept (scale=1).\"\"\"\n",
    "        # MCMC\n",
    "        a  = self.a['perc'][1]\n",
    "        am = self.a['perc'][0]\n",
    "        ap = self.a['perc'][2]\n",
    "        c  = self.c['perc'][1]\n",
    "        cm = self.c['perc'][0]\n",
    "        cp = self.c['perc'][2]\n",
    "        # least squares\n",
    "        a_ls     = self.a['ls'][0]\n",
    "        a_ls_err = self.a['ls'][1]\n",
    "        c_ls     = self.c['ls'][0]\n",
    "        c_ls_err = self.c['ls'][1]\n",
    "        y10_ls     = powlaw(10, a_ls, np.power(10,c_ls))\n",
    "        y10_ls_err = np.log(10)*np.power(10,a_ls+c_ls) *np.sqrt(a_ls_err**2+c_ls_err**2)\n",
    "\n",
    "        # best fit sigma10\n",
    "        self.y10 = {'MCMC': [powlaw(10, a, np.power(10,c)), powlaw(10, am, np.power(10,cm)), powlaw(10, ap, np.power(10,cp))],\n",
    "                    'ls':   [y10_ls, y10_ls_err]}\n",
    "\n",
    "        # distribution of sigma10\n",
    "        self.y10s = {'MCMC': [powlaw(10, a, np.power(10,c)) for a, c in self.samples[np.random.randint(len(self.samples), size=100)]]}\n",
    "\n",
    "\n",
    "####################################################################################################\n",
    "# fit and plot meta function\n",
    "####################################################################################################\n",
    "\n",
    "def fit_MCMC(log_x, log_y, log_x_err, log_y_err, source, line, savepath, xlabel=None, ylabel=None, plotcolor='r', fit_range=[None,None]):\n",
    "    MCMC = MCMC_fit(log_x, log_y, log_x_err, log_y_err)\n",
    "    MCMC.savepath = savepath\n",
    "    MCMC.source   = source\n",
    "    MCMC.line     = line\n",
    "    MCMC.plotcolor = plotcolor\n",
    "    MCMC.xlabel   = xlabel\n",
    "    MCMC.ylabel   = ylabel\n",
    "\n",
    "    MCMC.mask_bad_values()\n",
    "    MCMC.restrict_range(fit_range)\n",
    "    MCMC.least_squares_fit()\n",
    "    MCMC.maximum_likelihood_fit()\n",
    "    MCMC.MCMC_fit()\n",
    "    MCMC.plot_walkers()\n",
    "    MCMC.corner_plot()\n",
    "    MCMC.plot_x_y()\n",
    "    MCMC.get_y10()\n",
    "    MCMC.fit = True\n",
    "    MCMC.list_results()\n",
    "\n",
    "    return MCMC\n",
    "\n",
    "\n",
    "####################################################################################################\n",
    "# print formatted slopes and intercepts\n",
    "####################################################################################################\n",
    "\n",
    "def print_formatted(MCMC_list, datatype):\n",
    "    print(datatype)\n",
    "    print('{:>8} & {:>10} & {:>6} & {:>6} & {:>6} & {:>6} & {:>6} & {:>6} & {:>8} & {:>8} & {:>8}'.format('source','line','a_16','a_50','a_84','c_16','c_50','c_84','y10','y10 -','y10 +'))\n",
    "    for m in MCMC_list:\n",
    "        try:\n",
    "            print('{:>8} & {:>10} & {:6.2f} & {:6.2f} & {:6.2f} & {:6.2f} & {:6.2f} & {:6.2f} & {:8.1f} & {:8.1f} & {:8.1f}'.format(m.source, m.line, m.a['perc'][0], m.a['perc'][1], m.a['perc'][2], m.c['perc'][0], m.c['perc'][1], m.c['perc'][2], m.y10[0], m.y10[1], m.y10[2]))\n",
    "        except:\n",
    "            print('{:>8} & {:>10} & {:<10}'.format(m.source, m.line, 'no fit'))\n",
    "            \n",
    "def mkdir(path):\n",
    "    \"\"\"mkdir\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        Path to directory to create\n",
    "    \"\"\"\n",
    "    import os\n",
    "    if ' ' in path:\n",
    "        raise Exception(\"Path contains spaces! This will most probably not create the directory you want!\")\n",
    "    if not os.path.exists(path):\n",
    "        os.system('mkdir -p '+path)\n",
    "        print(\"Created \"+path)\n",
    "        \n",
    "def escape_filename(str):\n",
    "    \"\"\"Escape the most often used characters in a string to be used as a file name.\n",
    "    Parameters\n",
    "    ----------\n",
    "    str : str\n",
    "        Input string to be escaped.\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        String with escaped '(', ')'; replaced ' ' by '_' and removed '$'.\n",
    "        \n",
    "    \"\"\"\n",
    "    str = str.replace('(',r'\\(')\n",
    "    str = str.replace(')',r'\\)')\n",
    "    str = str.replace(' ',r'_')\n",
    "    str = str.replace('$','')\n",
    "    return str\n",
    "\n",
    "\n",
    "def filter_window(x,y,window_min,window_max):\n",
    "    \"\"\"select values in the window\"\"\"\n",
    "    x_window = x[(window_min<x) & (x<window_max)]\n",
    "    y_window = y[(window_min<x) & (x<window_max)]\n",
    "    return x_window,y_window\n",
    "\n",
    "\n",
    "def crossmatch(*args):\n",
    "    \"\"\"Crossmatch lists for non-finite values.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : list\n",
    "    y : list\n",
    "    ...\n",
    "    Returns\n",
    "    -------\n",
    "    list, list\n",
    "        Lists in input order with the non-finite (infinite and NaN) values removed from the list and\n",
    "        also the corresponding element of the other list.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "\n",
    "    lists = []\n",
    "    for list in args:\n",
    "        lists.append( np.array(list) )\n",
    "\n",
    "    selection = np.isfinite(lists[0])\n",
    "    for list in lists[1:]:\n",
    "        selection = selection & np.isfinite(list)\n",
    "\n",
    "    matched_lists = []\n",
    "    for list in lists:\n",
    "        matched_lists.append( list[selection] )\n",
    "\n",
    "    return matched_lists\n",
    "def get_binned_percentiles(x_measure, y_measure, x_step, xdata, ydata):\n",
    "\n",
    "    from astropy.table import Table\n",
    "    \n",
    "    \n",
    "\n",
    "    def filter_window(x,y,window_min,window_max):\n",
    "        \"\"\"select values in the window\"\"\"\n",
    "        x_window = x[(window_min<x) & (x<window_max)]\n",
    "        y_window = y[(window_min<x) & (x<window_max)]\n",
    "        return x_window,y_window\n",
    "\n",
    "\n",
    "    # binned percentiles table\n",
    "    bin_perc = Table(names = ['window min','window center','window max','x 16th','x median','x 84th','y 16th','y median','y 84th'],\n",
    "                     meta = {'x': x_measure, 'y': y_measure, 'x_step': x_step}\n",
    "                    )\n",
    "\n",
    "    x_matched, y_matched = crossmatch(xdata,ydata)\n",
    "\n",
    "    x_min = np.nanmin(x_matched)\n",
    "    x_max = np.nanmax(x_matched)\n",
    "    y_min = np.nanmin(y_matched)\n",
    "    y_max = np.nanmax(y_matched)\n",
    "\n",
    "    for log_window_cen in np.arange(np.log10(x_min), np.log10(x_max)+x_step, x_step):\n",
    "        log_window_min = log_window_cen-x_step/2.\n",
    "        log_window_max = log_window_cen+x_step/2.\n",
    "        window_min = np.power(10,log_window_min)\n",
    "        window_cen = np.power(10,log_window_cen)\n",
    "        window_max = np.power(10,log_window_max)\n",
    "        x_window,y_window = filter_window(x_matched,y_matched,window_min,window_max)\n",
    "\n",
    "        # percentiles only make sense when at least two measurements are available\n",
    "        if len(x_window)>1:\n",
    "            x_perc = np.percentile(x_window, [16,50,84])\n",
    "            y_perc = np.percentile(y_window, [16,50,84])\n",
    "            bin_perc.add_row( flatten([window_min,window_cen,window_max,x_perc,y_perc]) )\n",
    "\n",
    "    return bin_perc\n",
    "\n",
    "    \n",
    "    \n",
    "def flatten(x):\n",
    "    \"\"\"Flatten list of lists.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : list,tuple\n",
    "        List of lists of lists of ...\n",
    "        Can contain a mixture of lists and values.\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        Flattened list.\n",
    "    \"\"\"\n",
    "    import collections\n",
    "    if isinstance(x, collections.Iterable):\n",
    "        return [a for i in x for a in flatten(i)]\n",
    "    else:\n",
    "        return [x]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb485da6-5fef-46d6-8ec0-a17cea616799",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Part 6: Reprojection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9de00d-516c-4604-8d73-33675ffeee69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just Using CO 3-2 right now\n",
    "\n",
    "files = [\"12CO_GC_359-000_mosaic.fit\"]\n",
    "#files=[\"Pre-Smoothed.fits\"]\n",
    "\n",
    "\n",
    "\n",
    "sc = SpectralCube.read(files[0])  \n",
    "Cube_Name = files[0]+\"Header_Fix.fits\"\n",
    "print(1)\n",
    "sc.allow_huge_operations=True\n",
    "sc = sc.with_spectral_unit(u.km/u.s,velocity_convention=\"radio\").to(u.K) # Change units from Hz to km/s\n",
    "new = SpectralCube(data=sc.hdu.data,wcs =WCS(sc.header),mask=sc.mask)\n",
    "new.allow_huge_operations=True\n",
    "new=new*sc[0][0][0].unit\n",
    "print(2)\n",
    "del sc\n",
    "sc=new\n",
    "print(3)\n",
    "del new\n",
    "\n",
    "sc.write(Cube_Name,overwrite=True)\n",
    "print(4)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80262ab5-3f5a-416b-a7f7-f701a5f35cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just Using CO 3-2 right now\n",
    "\n",
    "files = [\"12CO_GC_359-000_mosaic.fit\"+\"Header_Fix.fits\"]\n",
    "\n",
    "#files=[\"Pre-Smoothed.fits\"]\n",
    "      \n",
    "#FOV = [400,800]#pc\n",
    "FOV = [70,360]#pc\n",
    "gal=\"GC\"\n",
    "Min_res=4.3*u.pc#Smallest resolution\n",
    "\n",
    "\n",
    "iterations = 6\n",
    "Line_Name = '_CMZ_CO_J3_2_4.3_start'\n",
    "Side=\"RH\"\n",
    "ovs = 3 #over sample factor for beam\n",
    "min_vel = 3.3#km/s\n",
    "#Beam_Sizes = np.linspace(Smallest_beam,Smallest_beam*iterations, np.diff(Smallest_beam,Smallest_beam*iterations)/iterations)\n",
    "iter_factor = 1/5\n",
    "Smoothe_4 = False\n",
    "Match_to_HCO = False\n",
    "if(Smoothe_4):\n",
    "    Smoothe_title=\"G_width_4\"\n",
    "else:\n",
    "    Smoothe_title=''\n",
    "    if(Match_to_HCO):\n",
    "        Smoothe_title='Smoothe_to_3.3'\n",
    "Smoothe_2_5 =True\n",
    "if(Smoothe_2_5):\n",
    "    Smoothe_title=\"Smoothe_to_2.5\"\n",
    "    \n",
    "    \n",
    "for kl in range(5,6):\n",
    "    Prime_Beam = Min_res*((kl*iter_factor+1))#Beam_Sizes[kl]\n",
    "    if(kl==5):\n",
    "        Prime_Beam = 3*u.pc#Nico\n",
    "        ovs=5\n",
    "        FOVp=[200,800]\n",
    "    else:\n",
    "        ovs=3\n",
    "        FOVp=FOV\n",
    "    #Need to break it up into 30-wide vel slices to do the reprojection (ram-draw too high)\n",
    "    \n",
    "\n",
    "    print(kl)\n",
    "    Cube_Name = str(Prime_Beam.value)+\"pc_beam_\"+Line_Name+str(FOVp[0])+\"x\"+str(FOVp[1])+Side+'pc_NEW.fits'\n",
    "    sc = SpectralCube.read(files[0])  \n",
    "\n",
    "\n",
    "    Nres=4.3*u.pc\n",
    "    dist=8.178*10**3#pc\n",
    "    res=  Nres/(dist)*180/np.pi*u.deg/u.pc#deg corresponding to ~3 pc\n",
    "    print(res,\"A\")\n",
    "\n",
    "\n",
    "\n",
    "    sc = sc[:,:,:]# Make a subcube\n",
    "\n",
    "    \n",
    "    #Put in the right system\n",
    "    sc.allow_huge_operations=True\n",
    "    sc_kms = sc#.with_spectral_unit(u.km/u.s,velocity_convention=\"radio\").to(u.K) # Change units from Hz to km/s\n",
    "\n",
    "    vel,RA,Dec = sc_kms.world[:,0,0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    try:\n",
    "\n",
    "\n",
    "        sc = sc_kms.spectral_slab(-325. *u.km / u.s, 326. *u.km / u.s)  # Crop out velocities we don't care about  \n",
    "\n",
    "        del sc_kms\n",
    "\n",
    "        HI = sc.header\n",
    "        Nres=Prime_Beam\n",
    "        if(gal==\"NGC253\"):\n",
    "            dist=3.5*10**6\n",
    "        if(gal==\"GC\"):\n",
    "            dist=8.178*10**3#pc\n",
    "        res=  Nres/(dist)*180/np.pi*u.deg/u.pc#deg corresponding to ~3 pc\n",
    "\n",
    "        beam = radio_beam.Beam(major=res, minor=res, pa=0*u.deg)\n",
    "\n",
    "\n",
    "        sc.allow_huge_operations=True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #Now that we have a circular beam, this can be done easily:\n",
    "\n",
    "        if(gal == 'GC'):\n",
    "\n",
    "            cdelt_x = u.Quantity(str(np.abs(sc.header['cdelt1']))+sc.header['cunit1'])\n",
    "            cdelt_y = u.Quantity(str(np.abs(sc.header['cdelt2']))+sc.header['cunit2'])\n",
    "            #center = SkyCoord('0359d56m39.24s', '-00d02m46.176s', frame='galactic')\n",
    "            center = SkyCoord('-00d03m20.76s  ', '-00d02m46.176s', frame='galactic')\n",
    "            center_ra_pix,center_dec_pix = int(sc.wcs[:][:][0].world_to_pixel(center)[0]),int(sc.wcs[:][:][0].world_to_pixel(center)[1])\n",
    "\n",
    "            print(center_dec_pix,center_ra_pix)\n",
    "\n",
    "            print((sc.wcs[:][:][0].pixel_to_world(center_dec_pix,center_ra_pix)),center_dec_pix,center_ra_pix)\n",
    "            PixFov = [int(FOVp[0]/(cdelt_x/u.deg*np.pi/180*8.178*10**3))/2,int(FOVp[1]/(cdelt_y/u.deg*np.pi/180*8.178*10**3))/2]\n",
    "\n",
    "\n",
    "            pixels = np.zeros(np.shape(sc))           \n",
    "            for lmi in range(np.shape(sc)[0]):\n",
    "                for lmj in range(np.shape(sc)[1]):\n",
    "                    for lmk in range(np.shape(sc)[2]):\n",
    "\n",
    "                        up_pixels = abs(lmj-center_dec_pix)#Should not be over the fov in the upwards direction (relative to 0 degrees)\n",
    "                        side_pixels = abs(lmk-center_ra_pix)#Should not be over the fov in the side-side direction (relative to 0 degrees)\n",
    "\n",
    "                        if(up_pixels<PixFov[0] and side_pixels<PixFov[1]):\n",
    "                            #print(lmj,lmk,np.shape(sc))\n",
    "                            pixels[lmi][lmj][lmk] = 1#good\n",
    "                    #print(\"Up pix\",up_pixels,\"Up pix fov\",PixFov[0],\"side pix\",side_pixels,\"side pix fov\",PixFov[1],\"lmj (dec)\",lmj,\"lmk (ra)\",lmk,\"center dec pix\",center_dec_pix,\"center ra pix\",center_ra_pix,cdelt_x_pc,cdelt_y_pc)\n",
    "\n",
    "            bp = np.where(pixels!=1)\n",
    "            #print(pixels)\n",
    "\n",
    "            #Mask teh pixels outside the fov\n",
    "            scCopy = sc.hdu\n",
    "            #sc.hdu.data[bp]=9999#np.nan\n",
    "            scCopy.data[bp]=np.nan\n",
    "            sc = SpectralCube.read(scCopy)\n",
    "            del scCopy\n",
    "\n",
    "        sc.allow_huge_operations=True\n",
    "\n",
    "        \n",
    "        try:\n",
    "            sc = sc.convolve_to(beam)#Smoothe to circular beam at 3 pc by 3 pc\n",
    "        except:\n",
    "            cdelt_x = u.Quantity(str(np.abs(sc.header['cdelt1']))+sc.header['cunit1'])\n",
    "            cdelt_y = u.Quantity(str(np.abs(sc.header['cdelt2']))+sc.header['cunit2'])\n",
    "            if(cdelt_x>cdelt_y):\n",
    "                majorBase=cdelt_x\n",
    "                minorBase=cdelt_y\n",
    "            elif(cdelt_x<cdelt_y):\n",
    "                majorBase=cdelt_y\n",
    "                minorBase=cdelt_x\n",
    "            elif(cdelt_x==cdelt_y):\n",
    "                majorBase=cdelt_x\n",
    "                minorBase=cdelt_x\n",
    "            BaseBeam = radio_beam.Beam(major=majorBase, minor=minorBase, pa=0*u.deg)\n",
    "\n",
    "            sc = sc.with_beam(BaseBeam)\n",
    "\n",
    "            beam = radio_beam.Beam(major=res, minor=res, pa=0*u.deg)\n",
    "            print(BaseBeam,beam,\"C\")\n",
    "            sc.allow_huge_operations=True\n",
    "            print(sc.shape,np.nanmax(sc.hdu.data),'EA')\n",
    "            #Requires me to edit convolve.py and set allow_huge =True\n",
    "            sc = sc.convolve_to(beam)#Smoothe to circular beam at 3 pc by 3 pc\n",
    "            print(np.shape(sc),\"B\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        reheader = copy.deepcopy(sc.hdu.header)\n",
    "\n",
    "\n",
    "        if(gal==\"NGC253\"):\n",
    "            ## Find the number of expected pixels for the new resolution and the location of the left/right, up/down sides \n",
    "            if sc.header['cdelt1']>0:\n",
    "                pix_x    = (res/ovs).to(u.degree).value\n",
    "                origin_x = sc.longitude_extrema[1].to(u.degree).value if gal=='GC' else sc.longitude_extrema[0].to(u.degree).value\n",
    "\n",
    "            else:\n",
    "                pix_x    = -1.*(res/ovs).to(u.degree).value\n",
    "                origin_x = (sc.longitude_extrema[0]).to(u.degree).value if gal=='GC' else (sc.longitude_extrema[1]).to(u.degree).value\n",
    "\n",
    "            if sc.header['cdelt2']>0:\n",
    "                pix_y    = (res/ovs).to(u.degree).value\n",
    "                origin_y = sc.latitude_extrema[0].to(u.degree).value\n",
    "            else:\n",
    "                pix_y    = -1.*(res/ovs).to(u.degree).value\n",
    "                origin_y = sc.latitude_extrema[1].to(u.degree).value\n",
    "\n",
    "            if gal=='NGC253':\n",
    "                npix_x   = int(np.ceil(np.diff(sc.longitude_extrema, n=1)[0]/np.abs(pix_x)).value)\n",
    "                npix_y   = int(np.ceil(np.diff(sc.latitude_extrema, n=1)[0]/np.abs(pix_y)).value)\n",
    "\n",
    "        elif gal=='GC':\n",
    "            ## Find the number of expected pixels for the new resolution and the location of the left/right, up/down sides \n",
    "\n",
    "            if sc.header['cdelt1']>0:\n",
    "                #pix_x    = sc.header['cdelt1']/5#(res/5.).to(u.degree).value*10\n",
    "                pix_x    = (res/ovs).to(u.degree).value\n",
    "                origin_x = 358.5#sc.longitude_extrema[1].to(u.degree).value if gal=='GC' else sc.longitude_extrema[0].to(u.degree).value\n",
    "                if(Line_Name == '_CMZ_CO_J3_2_4.3_start' and kl==5):\n",
    "                    #pix_x    = .55/3*res.to(u.degree).value\n",
    "                    origin_x = 358.6#sc.longitude_extrema[1].to(u.degree).value if gal=='GC' else sc.longitude_extrema[0].to(u.degree).value\n",
    "                    \n",
    "                #origin_x = sc.longitude_extrema[1].to(u.degree).value if gal=='GC' else sc.longitude_extrema[0].to(u.degree).value\n",
    "\n",
    "            else:\n",
    "                #pix_x    = sc.header['cdelt1']/5#-1.*(res/5.).to(u.degree).value*10\n",
    "                pix_x    = -(res/ovs).to(u.degree).value\n",
    "                origin_x = 1.5#(sc.longitude_extrema[0]).to(u.degree).value if gal=='GC' else (sc.longitude_extrema[1]).to(u.degree).value\n",
    "                #origin_x = (sc.longitude_extrema[0]).to(u.degree).value if gal=='GC' else (sc.longitude_extrema[1]).to(u.degree).value\n",
    "                if(Line_Name == '_CMZ_CO_J3_2_4.3_start' and kl==5):\n",
    "                    #pix_x    = -.55/3*res.to(u.degree).value\n",
    "                    origin_x = .9\n",
    "\n",
    "            if sc.header['cdelt2']>0:\n",
    "                #pix_y    = sc.header['cdelt2']/5#(res/5.).to(u.degree).value*10\n",
    "                pix_y    = (res/ovs).to(u.degree).value\n",
    "                origin_y = -.5#sc.latitude_extrema[0].to(u.degree).value\n",
    "                #origin_y = sc.latitude_extrema[0].to(u.degree).value\n",
    "                if(Line_Name == '_CMZ_CO_J3_2_4.3_start' and kl==5):\n",
    "                    #pix_y    = .55/3*res.to(u.degree).value\n",
    "                    origin_y = -0.6#sc.longitude_extrema[1].to(u.degree).value if gal=='GC' else sc.longitude_extrema[0].to(u.degree).value\n",
    "\n",
    "            else:\n",
    "                #pix_y    = sc.header['cdelt2']/5#-1.*(res/5.).to(u.degree).value*10\n",
    "                pix_y    = -(res/ovs).to(u.degree).value\n",
    "                origin_y = .5#sc.latitude_extrema[1].to(u.degree).value\n",
    "                #origin_y = sc.latitude_extrema[1].to(u.degree).value\n",
    "                if(Line_Name == '_CMZ_CO_J3_2_4.3_start' and kl==5):\n",
    "                    #pix_y    = -.55/3*res.to(u.degree).value\n",
    "                    origin_y = 0.6#sc.longitude_extrema[1].to(u.degree).value if gal=='GC' else sc.longitude_extrema[0].to(u.degree).value\n",
    "\n",
    "\n",
    "\n",
    "            if gal=='GC':\n",
    "                #manually put in the size to correct for the 360->0 difference and just because it doesnt seem to work\n",
    "                print(\"LA\",((sc.longitude_extrema[0])),(sc.longitude_extrema[1]-360*u.degree),np.abs(pix_x))\n",
    "                print(\"MA\",sc.latitude_extrema,np.abs(pix_y))\n",
    "                #npix_x   =int(np.ceil((sc.longitude_extrema[0]-(sc.longitude_extrema[1]-360*u.degree))/np.abs(pix_x)).value)\n",
    "                #npix_y   =int(np.ceil(np.diff(sc.latitude_extrema, n=1)[0]/np.abs(pix_y)).value)\n",
    "                npix_x   =int(2.5/np.abs(pix_x))\n",
    "                npix_y   =int(1.2/np.abs(pix_y))\n",
    "                if(Line_Name == '_CMZ_CO_J3_2_4.3_start' and kl==5):\n",
    "                    npix_x   =int(2.3/np.abs(pix_x))\n",
    "                    npix_y   =int(1.2/np.abs(pix_y))\n",
    "\n",
    "                print(npix_x,npix_y)\n",
    "\n",
    "\n",
    "        #Correct the header to the expected pixels for the new res\n",
    "\n",
    "        reheader['cdelt1'] = pix_x\n",
    "        reheader['cdelt2'] = pix_y\n",
    "\n",
    "        reheader['naxis1'] = npix_x\n",
    "        reheader['naxis2'] = npix_y\n",
    "\n",
    "        reheader['crval1'] = origin_x\n",
    "        reheader['crval2'] = origin_y\n",
    "\n",
    "        reheader['crpix1'] = 0\n",
    "        reheader['crpix2'] = 0\n",
    "        \n",
    "        reheader['CTYPE1'] = \"GLON-SIN\"\n",
    "        reheader['CTYPE2'] = \"GLAT-SIN\"\n",
    "        try:\n",
    "            del reheader['lonpole']\n",
    "            del reheader['latpole']\n",
    "            del reheader['wcsaxes']#Dont need these anymore, maybe?\n",
    "            \n",
    "            del reheader['LBOUND1']\n",
    "            del reheader['LBOUND2']\n",
    "            del reheader['LBOUND3']\n",
    "            del reheader.cards['LBOUND1']\n",
    "            del reheader.cards['LBOUND2']\n",
    "            del reheader.cards['LBOUND3']\n",
    "            \n",
    "            reheader['LBOUND1']=0\n",
    "            reheader['LBOUND2']=0\n",
    "            reheader['LBOUND3']=0\n",
    "            \n",
    "            print(\"12312412\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "            print(\"Failed\")\n",
    "            print(\"-\"*60)\n",
    "            traceback.print_exc(file=sys.stdout)\n",
    "        \n",
    "        # regrid cube to target pixel size\n",
    "        \n",
    "        \n",
    "        \n",
    "        #Cube_Name_Load_HCN = \"Cropped_\"+str(Prime_Beam.value)+\"pc_beam_\"+'_CMZ_HCN_J1_0_4.3_start'+str(FOV[0])+\"x\"+str(FOV[1])+'pc_'+str(3.3)+'_vel_res.fits'\n",
    "        #del reheader\n",
    "        #reheader = SpectralCube.read(Cube_Name_Load_HCN).hdu.header\n",
    "        #reheader[\"CTYPE3\"] = \"VRAD\"\n",
    "        \n",
    "        sc_K_kms = sc.reproject(reheader, order='bilinear', use_memmap=True, filled=True)\n",
    "        del sc\n",
    "        #new = SpectralCube(data=sc_K_kms.hdu.data,wcs = WCS(sc_K_kms.header),header=sc_K_kms.header)\n",
    "        new = SpectralCube(data=sc_K_kms.hdu.data,wcs =WCS(sc_K_kms.header),header=sc_K_kms.header,mask=sc_K_kms.mask)\n",
    "        new.allow_huge_operations=True\n",
    "        new = new*sc_K_kms[0][0][0].unit\n",
    "        #do this because scs dont like being modified\n",
    "        del sc_K_kms\n",
    "        sc_K_kms = new\n",
    "        del new\n",
    "\n",
    "        print(np.nanmax(sc_K_kms),np.shape(sc_K_kms))#These should be a non zero float and the shape of the cube (30,~1000,~1000)\n",
    "        \n",
    "\n",
    "        NGC_CO_J3_2 = sc_K_kms\n",
    "        del sc_K_kms\n",
    "        NGC_CO_J3_2.allow_huge_operations=True\n",
    "\n",
    "        #do this again to crop the extra pixels off\n",
    "\n",
    "        sc=NGC_CO_J3_2\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        #Write the intermediary cubes that will then be spliced together\n",
    "        del NGC_CO_J3_2\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        fwhm_factor = np.sqrt(8*np.log(2))\n",
    "\n",
    "        vel,RA,Dec =sc.world[:,0,0]\n",
    "        for km in range(5,6):\n",
    "            scWsc_copy = sc\n",
    "            vel_prime = min_vel*((km*iter_factor+1))\n",
    "            if(km==5):\n",
    "                vel_prime=2.5\n",
    "            Cube_Name_Save = str(Prime_Beam.value)+\"pc_beam_\"+Line_Name+str(FOVp[0])+\"x\"+str(FOVp[1])+'pc_'+str(vel_prime)+Side+'_vel_res_NEW'+Smoothe_title+'.fits'\n",
    "            if(gal==\"GC\"):\n",
    "                vel = np.arange(-300,301,vel_prime)*u.km/u.s    \n",
    "            else:\n",
    "                vel = np.arange(0,501,vel_prime)*u.km/u.s    \n",
    "\n",
    "            G_width = np.sqrt(2.5**2-1**2)\n",
    "            if(km==5):\n",
    "                #G_width = 4\n",
    "                G_width = np.sqrt(2.5**2-1**2)\n",
    "                if(Match_to_HCO):\n",
    "                    G_width = np.sqrt(3.3**2-1**2)\n",
    "            if(km==5 and Smoothe_4):\n",
    "                G_width = 4\n",
    "            if(km==5 and Smoothe_2_5):\n",
    "                G_width = 2.5/1#G_width = 2.5/1\n",
    "                \n",
    "            scWsc_copy = scWsc_copy.spectral_smooth(Gaussian1DKernel(G_width/fwhm_factor))#Preserves information from the pixels lost in downsampling\n",
    "            scWsc_copy = scWsc_copy.with_spectral_unit(u.km / u.s, velocity_convention='optical', rest_value=restfreq)\n",
    "            scWsc_copy = scWsc_copy.spectral_interpolate(spectral_grid=vel) # Match velocities to -250 251 range  \n",
    "\n",
    "\n",
    "\n",
    "            scWsc_copy.write(Cube_Name_Save,overwrite=True)\n",
    "            gc.collect()\n",
    "            #scWsc.write(\"NGC_Spliced_Reprojected_Whole_CO_32.fits\",overwrite=True)\n",
    "        del scWsc_copy\n",
    "        \n",
    "        del sc\n",
    "        \n",
    "        gc.collect()######################################################################\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(kl)\n",
    "        print(\"Failed\")\n",
    "        print(\"-\"*60)\n",
    "        traceback.print_exc(file=sys.stdout)\n",
    "\n",
    "\n",
    "      \n",
    "    \n",
    "print(\"done\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6e5caf-f855-4f6a-a231-10d3bf4a9ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just Using CO 3-2 right now\n",
    "\n",
    "files = [\"12CO_GC_001-002_mosaic.fit\"]\n",
    "#files=[\"Pre-Smoothed.fits\"]\n",
    "\n",
    "\n",
    "\n",
    "sc = SpectralCube.read(files[0])  \n",
    "Cube_Name = files[0]+\"Header_Fix.fits\"\n",
    "print(1)\n",
    "sc.allow_huge_operations=True\n",
    "sc = sc.with_spectral_unit(u.km/u.s,velocity_convention=\"radio\").to(u.K) # Change units from Hz to km/s\n",
    "new = SpectralCube(data=sc.hdu.data,wcs =WCS(sc.header),mask=sc.mask)\n",
    "new.allow_huge_operations=True\n",
    "new=new*sc[0][0][0].unit\n",
    "print(2)\n",
    "del sc\n",
    "sc=new\n",
    "print(3)\n",
    "del new\n",
    "\n",
    "sc.write(Cube_Name,overwrite=True)\n",
    "print(4)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26efa8f8-ad25-4ffa-8020-5d3841a96043",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(np.shape(bp))\n",
    "#np.savetxt(\"bp.txt\",np.array(bp[1][999999:9999999],dtype=int))\n",
    "#np.savetxt(\"bp2.txt\",np.array(bp[2][0:99999],dtype=int))\n",
    "#Just Using CO 3-2 right now\n",
    "#files = [\"12CO_GC_359-000_mosaic.fit\"]\n",
    "files = [\"12CO_GC_001-002_mosaic.fit\"]\n",
    "files = [files[0]+\"Header_Fix.fits\"]\n",
    "      \n",
    "#files=[\"Pre-Smoothed.fits\"]\n",
    "      \n",
    "#FOV = [400,800]#pc\n",
    "FOV = [70,360]#pc\n",
    "gal=\"GC\"\n",
    "Min_res=4.3*u.pc#Smallest resolution\n",
    "\n",
    "\n",
    "iterations = 6\n",
    "Line_Name = '_CMZ_CO_J3_2_4.3_start'\n",
    "Side=\"LH\"\n",
    "ovs = 3 #over sample factor for beam\n",
    "min_vel = 3.3#km/s\n",
    "#Beam_Sizes = np.linspace(Smallest_beam,Smallest_beam*iterations, np.diff(Smallest_beam,Smallest_beam*iterations)/iterations)\n",
    "iter_factor = 1/5\n",
    "Smoothe_4 = False\n",
    "Match_to_HCO = False\n",
    "if(Smoothe_4):\n",
    "    Smoothe_title=\"G_width_4\"\n",
    "else:\n",
    "    Smoothe_title=''\n",
    "    if(Match_to_HCO):\n",
    "        Smoothe_title='Smoothe_to_3.3'\n",
    "Smoothe_2_5 =True\n",
    "if(Smoothe_2_5):\n",
    "    Smoothe_title=\"Smoothe_to_2.5\"\n",
    "for kl in range(5,6):\n",
    "    Prime_Beam = Min_res*((kl*iter_factor+1))#Beam_Sizes[kl]\n",
    "    if(kl==5):\n",
    "        Prime_Beam = 3*u.pc#Nico\n",
    "        ovs=5\n",
    "        FOVp=[200,800]\n",
    "    else:\n",
    "        ovs=3\n",
    "        FOVp=FOV\n",
    "    #Need to break it up into 30-wide vel slices to do the reprojection (ram-draw too high)\n",
    "    \n",
    "\n",
    "    print(kl)\n",
    "    Cube_Name = str(Prime_Beam.value)+\"pc_beam_\"+Line_Name+str(FOVp[0])+\"x\"+str(FOVp[1])+Side+'pc_NEW.fits'\n",
    "    sc = SpectralCube.read(files[0])  \n",
    "\n",
    "\n",
    "    Nres=4.3*u.pc\n",
    "    dist=8.178*10**3#pc\n",
    "    res=  Nres/(dist)*180/np.pi*u.deg/u.pc#deg corresponding to ~3 pc\n",
    "    print(res,\"A\")\n",
    "\n",
    "\n",
    "\n",
    "    sc = sc[:,:,:]# Make a subcube\n",
    "\n",
    "    \n",
    "    #Put in the right system\n",
    "    sc.allow_huge_operations=True\n",
    "    sc_kms = sc#.with_spectral_unit(u.km/u.s,velocity_convention=\"radio\").to(u.K) # Change units from Hz to km/s\n",
    "\n",
    "    vel,RA,Dec = sc_kms.world[:,0,0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    try:\n",
    "\n",
    "\n",
    "        sc = sc_kms.spectral_slab(-325. *u.km / u.s, 326. *u.km / u.s)  # Crop out velocities we don't care about  \n",
    "\n",
    "        del sc_kms\n",
    "\n",
    "        HI = sc.header\n",
    "        Nres=Prime_Beam\n",
    "        if(gal==\"NGC253\"):\n",
    "            dist=3.5*10**6\n",
    "        if(gal==\"GC\"):\n",
    "            dist=8.178*10**3#pc\n",
    "        res=  Nres/(dist)*180/np.pi*u.deg/u.pc#deg corresponding to ~3 pc\n",
    "\n",
    "        beam = radio_beam.Beam(major=res, minor=res, pa=0*u.deg)\n",
    "\n",
    "\n",
    "        sc.allow_huge_operations=True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #Now that we have a circular beam, this can be done easily:\n",
    "\n",
    "        if(gal == 'GC'):\n",
    "\n",
    "            cdelt_x = u.Quantity(str(np.abs(sc.header['cdelt1']))+sc.header['cunit1'])\n",
    "            cdelt_y = u.Quantity(str(np.abs(sc.header['cdelt2']))+sc.header['cunit2'])\n",
    "            #center = SkyCoord('0359d56m39.24s', '-00d02m46.176s', frame='galactic')\n",
    "            center = SkyCoord('-00d03m20.76s  ', '-00d02m46.176s', frame='galactic')\n",
    "            center_ra_pix,center_dec_pix = int(sc.wcs[:][:][0].world_to_pixel(center)[0]),int(sc.wcs[:][:][0].world_to_pixel(center)[1])\n",
    "\n",
    "            print(center_dec_pix,center_ra_pix)\n",
    "\n",
    "            print((sc.wcs[:][:][0].pixel_to_world(center_dec_pix,center_ra_pix)),center_dec_pix,center_ra_pix)\n",
    "            PixFov = [int(FOVp[0]/(cdelt_x/u.deg*np.pi/180*8.178*10**3))/2,int(FOVp[1]/(cdelt_y/u.deg*np.pi/180*8.178*10**3))/2]\n",
    "\n",
    "\n",
    "            pixels = np.zeros(np.shape(sc))           \n",
    "            for lmi in range(np.shape(sc)[0]):\n",
    "                for lmj in range(np.shape(sc)[1]):\n",
    "                    for lmk in range(np.shape(sc)[2]):\n",
    "\n",
    "                        up_pixels = abs(lmj-center_dec_pix)#Should not be over the fov in the upwards direction (relative to 0 degrees)\n",
    "                        side_pixels = abs(lmk-center_ra_pix)#Should not be over the fov in the side-side direction (relative to 0 degrees)\n",
    "\n",
    "                        if(up_pixels<PixFov[0] and side_pixels<PixFov[1]):\n",
    "                            #print(lmj,lmk,np.shape(sc))\n",
    "                            pixels[lmi][lmj][lmk] = 1#good\n",
    "                    #print(\"Up pix\",up_pixels,\"Up pix fov\",PixFov[0],\"side pix\",side_pixels,\"side pix fov\",PixFov[1],\"lmj (dec)\",lmj,\"lmk (ra)\",lmk,\"center dec pix\",center_dec_pix,\"center ra pix\",center_ra_pix,cdelt_x_pc,cdelt_y_pc)\n",
    "\n",
    "            bp = np.where(pixels!=1)\n",
    "            #print(pixels)\n",
    "\n",
    "            #Mask teh pixels outside the fov\n",
    "            scCopy = sc.hdu\n",
    "            #sc.hdu.data[bp]=9999#np.nan\n",
    "            scCopy.data[bp]=np.nan\n",
    "            sc = SpectralCube.read(scCopy)\n",
    "            del scCopy\n",
    "\n",
    "        sc.allow_huge_operations=True\n",
    "\n",
    "        \n",
    "        try:\n",
    "            sc = sc.convolve_to(beam)#Smoothe to circular beam at 3 pc by 3 pc\n",
    "        except:\n",
    "            cdelt_x = u.Quantity(str(np.abs(sc.header['cdelt1']))+sc.header['cunit1'])\n",
    "            cdelt_y = u.Quantity(str(np.abs(sc.header['cdelt2']))+sc.header['cunit2'])\n",
    "            if(cdelt_x>cdelt_y):\n",
    "                majorBase=cdelt_x\n",
    "                minorBase=cdelt_y\n",
    "            elif(cdelt_x<cdelt_y):\n",
    "                majorBase=cdelt_y\n",
    "                minorBase=cdelt_x\n",
    "            elif(cdelt_x==cdelt_y):\n",
    "                majorBase=cdelt_x\n",
    "                minorBase=cdelt_x\n",
    "            BaseBeam = radio_beam.Beam(major=majorBase, minor=minorBase, pa=0*u.deg)\n",
    "\n",
    "            sc = sc.with_beam(BaseBeam)\n",
    "\n",
    "            beam = radio_beam.Beam(major=res, minor=res, pa=0*u.deg)\n",
    "            print(BaseBeam,beam,\"C\")\n",
    "            sc.allow_huge_operations=True\n",
    "            print(sc.shape,np.nanmax(sc.hdu.data),'EA')\n",
    "            #Requires me to edit convolve.py and set allow_huge =True\n",
    "            sc = sc.convolve_to(beam)#Smoothe to circular beam at 3 pc by 3 pc\n",
    "            print(np.shape(sc),\"B\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        reheader = copy.deepcopy(sc.hdu.header)\n",
    "\n",
    "\n",
    "        if(gal==\"NGC253\"):\n",
    "            ## Find the number of expected pixels for the new resolution and the location of the left/right, up/down sides \n",
    "            if sc.header['cdelt1']>0:\n",
    "                pix_x    = (res/ovs).to(u.degree).value\n",
    "                origin_x = sc.longitude_extrema[1].to(u.degree).value if gal=='GC' else sc.longitude_extrema[0].to(u.degree).value\n",
    "\n",
    "            else:\n",
    "                pix_x    = -1.*(res/ovs).to(u.degree).value\n",
    "                origin_x = (sc.longitude_extrema[0]).to(u.degree).value if gal=='GC' else (sc.longitude_extrema[1]).to(u.degree).value\n",
    "\n",
    "            if sc.header['cdelt2']>0:\n",
    "                pix_y    = (res/ovs).to(u.degree).value\n",
    "                origin_y = sc.latitude_extrema[0].to(u.degree).value\n",
    "            else:\n",
    "                pix_y    = -1.*(res/ovs).to(u.degree).value\n",
    "                origin_y = sc.latitude_extrema[1].to(u.degree).value\n",
    "\n",
    "            if gal=='NGC253':\n",
    "                npix_x   = int(np.ceil(np.diff(sc.longitude_extrema, n=1)[0]/np.abs(pix_x)).value)\n",
    "                npix_y   = int(np.ceil(np.diff(sc.latitude_extrema, n=1)[0]/np.abs(pix_y)).value)\n",
    "\n",
    "        elif gal=='GC':\n",
    "            ## Find the number of expected pixels for the new resolution and the location of the left/right, up/down sides \n",
    "\n",
    "            if sc.header['cdelt1']>0:\n",
    "                #pix_x    = sc.header['cdelt1']/5#(res/5.).to(u.degree).value*10\n",
    "                pix_x    = (res/ovs).to(u.degree).value\n",
    "                origin_x = 358.5#sc.longitude_extrema[1].to(u.degree).value if gal=='GC' else sc.longitude_extrema[0].to(u.degree).value\n",
    "                if(Line_Name == '_CMZ_CO_J3_2_4.3_start' and kl==5):\n",
    "                    #pix_x    = .55/3*res.to(u.degree).value\n",
    "                    origin_x = 357.2#sc.longitude_extrema[1].to(u.degree).value if gal=='GC' else sc.longitude_extrema[0].to(u.degree).value\n",
    "                    \n",
    "                #origin_x = sc.longitude_extrema[1].to(u.degree).value if gal=='GC' else sc.longitude_extrema[0].to(u.degree).value\n",
    "\n",
    "            else:\n",
    "                #pix_x    = sc.header['cdelt1']/5#-1.*(res/5.).to(u.degree).value*10\n",
    "                pix_x    = -(res/ovs).to(u.degree).value\n",
    "                origin_x = 1.5#(sc.longitude_extrema[0]).to(u.degree).value if gal=='GC' else (sc.longitude_extrema[1]).to(u.degree).value\n",
    "                #origin_x = (sc.longitude_extrema[0]).to(u.degree).value if gal=='GC' else (sc.longitude_extrema[1]).to(u.degree).value\n",
    "                if(Line_Name == '_CMZ_CO_J3_2_4.3_start' and kl==5):\n",
    "                    #pix_x    = -.55/3*res.to(u.degree).value\n",
    "                    origin_x = 2.8\n",
    "\n",
    "            if sc.header['cdelt2']>0:\n",
    "                #pix_y    = sc.header['cdelt2']/5#(res/5.).to(u.degree).value*10\n",
    "                pix_y    = (res/ovs).to(u.degree).value\n",
    "                origin_y = -.5#sc.latitude_extrema[0].to(u.degree).value\n",
    "                #origin_y = sc.latitude_extrema[0].to(u.degree).value\n",
    "                if(Line_Name == '_CMZ_CO_J3_2_4.3_start' and kl==5):\n",
    "                    #pix_y    = .55/3*res.to(u.degree).value\n",
    "                    origin_y = -0.55#sc.longitude_extrema[1].to(u.degree).value if gal=='GC' else sc.longitude_extrema[0].to(u.degree).value\n",
    "\n",
    "            else:\n",
    "                #pix_y    = sc.header['cdelt2']/5#-1.*(res/5.).to(u.degree).value*10\n",
    "                pix_y    = -(res/ovs).to(u.degree).value\n",
    "                origin_y = .5#sc.latitude_extrema[1].to(u.degree).value\n",
    "                #origin_y = sc.latitude_extrema[1].to(u.degree).value\n",
    "                if(Line_Name == '_CMZ_CO_J3_2_4.3_start' and kl==5):\n",
    "                    #pix_y    = -.55/3*res.to(u.degree).value\n",
    "                    origin_y = 0.55#sc.longitude_extrema[1].to(u.degree).value if gal=='GC' else sc.longitude_extrema[0].to(u.degree).value\n",
    "\n",
    "\n",
    "\n",
    "            if gal=='GC':\n",
    "                #manually put in the size to correct for the 360->0 difference and just because it doesnt seem to work\n",
    "                print(\"LA\",((sc.longitude_extrema[0])),(sc.longitude_extrema[1]-360*u.degree),np.abs(pix_x))\n",
    "                print(\"MA\",sc.latitude_extrema,np.abs(pix_y))\n",
    "                #npix_x   =int(np.ceil((sc.longitude_extrema[0]-(sc.longitude_extrema[1]-360*u.degree))/np.abs(pix_x)).value)\n",
    "                #npix_y   =int(np.ceil(np.diff(sc.latitude_extrema, n=1)[0]/np.abs(pix_y)).value)\n",
    "                npix_x   =int(3/np.abs(pix_x))\n",
    "                npix_y   =int(1.2/np.abs(pix_y))\n",
    "                if(Line_Name == '_CMZ_CO_J3_2_4.3_start' and kl==5):\n",
    "                    npix_x   =int(2.5/np.abs(pix_x))\n",
    "                    npix_y   =int(1.1/np.abs(pix_y))\n",
    "\n",
    "                print(npix_x,npix_y)\n",
    "\n",
    "\n",
    "        #Correct the header to the expected pixels for the new res\n",
    "\n",
    "        reheader['cdelt1'] = pix_x\n",
    "        reheader['cdelt2'] = pix_y\n",
    "\n",
    "        reheader['naxis1'] = npix_x\n",
    "        reheader['naxis2'] = npix_y\n",
    "\n",
    "        reheader['crval1'] = origin_x\n",
    "        reheader['crval2'] = origin_y\n",
    "\n",
    "        reheader['crpix1'] = 0\n",
    "        reheader['crpix2'] = 0\n",
    "        \n",
    "        reheader['CTYPE1'] = \"GLON-SIN\"\n",
    "        reheader['CTYPE2'] = \"GLAT-SIN\"\n",
    "        try:\n",
    "            del reheader['lonpole']\n",
    "            del reheader['latpole']\n",
    "            del reheader['wcsaxes']#Dont need these anymore, maybe?\n",
    "            \n",
    "            del reheader['LBOUND1']\n",
    "            del reheader['LBOUND2']\n",
    "            del reheader['LBOUND3']\n",
    "            del reheader.cards['LBOUND1']\n",
    "            del reheader.cards['LBOUND2']\n",
    "            del reheader.cards['LBOUND3']\n",
    "            \n",
    "            reheader['LBOUND1']=0\n",
    "            reheader['LBOUND2']=0\n",
    "            reheader['LBOUND3']=0\n",
    "            \n",
    "            print(\"12312412\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "            print(\"Failed\")\n",
    "            print(\"-\"*60)\n",
    "            traceback.print_exc(file=sys.stdout)\n",
    "        \n",
    "        # regrid cube to target pixel size\n",
    "        \n",
    "        \n",
    "        \n",
    "        #Cube_Name_Load_HCN = \"Cropped_\"+str(Prime_Beam.value)+\"pc_beam_\"+'_CMZ_HCN_J1_0_4.3_start'+str(FOV[0])+\"x\"+str(FOV[1])+'pc_'+str(3.3)+'_vel_res.fits'\n",
    "        #del reheader\n",
    "        #reheader = SpectralCube.read(Cube_Name_Load_HCN).hdu.header\n",
    "        #reheader[\"CTYPE3\"] = \"VRAD\"\n",
    "        \n",
    "        sc_K_kms = sc.reproject(reheader, order='bilinear', use_memmap=True, filled=True)\n",
    "        del sc\n",
    "        #new = SpectralCube(data=sc_K_kms.hdu.data,wcs = WCS(sc_K_kms.header),header=sc_K_kms.header)\n",
    "        new = SpectralCube(data=sc_K_kms.hdu.data,wcs =WCS(sc_K_kms.header),header=sc_K_kms.header,mask=sc_K_kms.mask)\n",
    "        new.allow_huge_operations=True\n",
    "        new = new*sc_K_kms[0][0][0].unit\n",
    "        #do this because scs dont like being modified\n",
    "        del sc_K_kms\n",
    "        sc_K_kms = new\n",
    "        del new\n",
    "\n",
    "        print(np.nanmax(sc_K_kms),np.shape(sc_K_kms))#These should be a non zero float and the shape of the cube (30,~1000,~1000)\n",
    "        \n",
    "\n",
    "        NGC_CO_J3_2 = sc_K_kms\n",
    "        del sc_K_kms\n",
    "        NGC_CO_J3_2.allow_huge_operations=True\n",
    "\n",
    "        #do this again to crop the extra pixels off\n",
    "\n",
    "        sc=NGC_CO_J3_2\n",
    "\n",
    "        sc = sc.convolve_to(beam)#Smoothe to circular beam at 3 pc by 3 pc\n",
    "\n",
    "\n",
    "        #Write the intermediary cubes that will then be spliced together\n",
    "        del NGC_CO_J3_2\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        fwhm_factor = np.sqrt(8*np.log(2))\n",
    "\n",
    "        vel,RA,Dec =sc.world[:,0,0]\n",
    "        for km in range(5,6):\n",
    "            scWsc_copy = sc\n",
    "            vel_prime = min_vel*((km*iter_factor+1))\n",
    "            if(km==5):\n",
    "                vel_prime=2.5\n",
    "            Cube_Name_Save = str(Prime_Beam.value)+\"pc_beam_\"+Line_Name+str(FOVp[0])+\"x\"+str(FOVp[1])+'pc_'+str(vel_prime)+Side+'_vel_res_NEW'+Smoothe_title+'.fits'\n",
    "            if(gal==\"GC\"):\n",
    "                vel = np.arange(-300,301,vel_prime)*u.km/u.s    \n",
    "            else:\n",
    "                vel = np.arange(0,501,vel_prime)*u.km/u.s    \n",
    "\n",
    "            G_width = np.sqrt(2.5**2-1**2)\n",
    "            if(km==5):\n",
    "                #G_width = 4\n",
    "                G_width = np.sqrt(2.5**2-1**2)\n",
    "                if(Match_to_HCO):\n",
    "                    G_width = np.sqrt(3.3**2-1**2)\n",
    "            if(km==5 and Smoothe_4):\n",
    "                G_width = 4\n",
    "            if(km==5 and Smoothe_2_5):\n",
    "                G_width = 2.5/1#G_width = 2.5/1\n",
    "                \n",
    "            scWsc_copy = scWsc_copy.spectral_smooth(Gaussian1DKernel(G_width/fwhm_factor))#Preserves information from the pixels lost in downsampling\n",
    "            scWsc_copy = scWsc_copy.with_spectral_unit(u.km / u.s, velocity_convention='optical', rest_value=restfreq)\n",
    "            scWsc_copy = scWsc_copy.spectral_interpolate(spectral_grid=vel) # Match velocities to -250 251 range \n",
    "\n",
    "\n",
    "\n",
    "            scWsc_copy.write(Cube_Name_Save,overwrite=True)\n",
    "            gc.collect()\n",
    "            #scWsc.write(\"NGC_Spliced_Reprojected_Whole_CO_32.fits\",overwrite=True)\n",
    "        del scWsc_copy\n",
    "        \n",
    "        del sc\n",
    "        \n",
    "        gc.collect()######################################################################\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(kl)\n",
    "        print(\"Failed\")\n",
    "        print(\"-\"*60)\n",
    "        traceback.print_exc(file=sys.stdout)\n",
    "\n",
    "\n",
    "      \n",
    "    \n",
    "print(\"done\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00730a2-22ad-4f65-a28d-df801a3d5a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just Using CO 3-2 right now\n",
    "\n",
    "files = [\"12CO_GC_357-358_mosaic.fit\"]\n",
    "#files=[\"Pre-Smoothed.fits\"]\n",
    "\n",
    "\n",
    "\n",
    "sc = SpectralCube.read(files[0])  \n",
    "Cube_Name = files[0]+\"Header_Fix.fits\"\n",
    "print(1)\n",
    "sc.allow_huge_operations=True\n",
    "sc = sc.with_spectral_unit(u.km/u.s,velocity_convention=\"radio\").to(u.K) # Change units from Hz to km/s\n",
    "new = SpectralCube(data=sc.hdu.data,wcs =WCS(sc.header),mask=sc.mask)\n",
    "new.allow_huge_operations=True\n",
    "new=new*sc[0][0][0].unit\n",
    "print(2)\n",
    "del sc\n",
    "sc=new\n",
    "print(3)\n",
    "del new\n",
    "\n",
    "sc.write(Cube_Name,overwrite=True)\n",
    "print(4)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2ea07d-8dbf-491f-837f-9d4278c6aab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(np.shape(bp))\n",
    "#np.savetxt(\"bp.txt\",np.array(bp[1][999999:9999999],dtype=int))\n",
    "#np.savetxt(\"bp2.txt\",np.array(bp[2][0:99999],dtype=int))\n",
    "#Just Using CO 3-2 right now\n",
    "#files = [\"12CO_GC_359-000_mosaic.fit\"]\n",
    "files = [\"12CO_GC_357-358_mosaic.fit\"]\n",
    "files = [files[0]+\"Header_Fix.fits\"]\n",
    "      \n",
    "\n",
    "#files=[\"Pre-Smoothed.fits\"]\n",
    "      \n",
    "#FOV = [400,800]#pc\n",
    "FOV = [70,360]#pc\n",
    "gal=\"GC\"\n",
    "Min_res=4.3*u.pc#Smallest resolution\n",
    "\n",
    "\n",
    "iterations = 6\n",
    "Line_Name = '_CMZ_CO_J3_2_4.3_start'\n",
    "Side=\"FRH\"\n",
    "ovs = 3 #over sample factor for beam\n",
    "min_vel = 3.3#km/s\n",
    "#Beam_Sizes = np.linspace(Smallest_beam,Smallest_beam*iterations, np.diff(Smallest_beam,Smallest_beam*iterations)/iterations)\n",
    "iter_factor = 1/5\n",
    "Smoothe_4 = False\n",
    "Match_to_HCO = False\n",
    "if(Smoothe_4):\n",
    "    Smoothe_title=\"G_width_4\"\n",
    "else:\n",
    "    Smoothe_title=''\n",
    "    if(Match_to_HCO):\n",
    "        Smoothe_title='Smoothe_to_3.3'\n",
    "Smoothe_2_5 =True\n",
    "if(Smoothe_2_5):\n",
    "    Smoothe_title=\"Smoothe_to_2.5\"\n",
    "for kl in range(5,6):\n",
    "    Prime_Beam = Min_res*((kl*iter_factor+1))#Beam_Sizes[kl]\n",
    "    if(kl==5):\n",
    "        Prime_Beam = 3*u.pc#Nico\n",
    "        ovs=5\n",
    "        FOVp=[200,800]\n",
    "    else:\n",
    "        ovs=3\n",
    "        FOVp=FOV\n",
    "    #Need to break it up into 30-wide vel slices to do the reprojection (ram-draw too high)\n",
    "    \n",
    "\n",
    "    print(kl)\n",
    "    Cube_Name = str(Prime_Beam.value)+\"pc_beam_\"+Line_Name+str(FOVp[0])+\"x\"+str(FOVp[1])+Side+'pc_NEW.fits'\n",
    "    sc = SpectralCube.read(files[0])  \n",
    "\n",
    "\n",
    "    Nres=4.3*u.pc\n",
    "    dist=8.178*10**3#pc\n",
    "    res=  Nres/(dist)*180/np.pi*u.deg/u.pc#deg corresponding to ~3 pc\n",
    "    print(res,\"A\")\n",
    "\n",
    "\n",
    "\n",
    "    sc = sc[:,:,:]# Make a subcube\n",
    "\n",
    "    \n",
    "    #Put in the right system\n",
    "    sc.allow_huge_operations=True\n",
    "    sc_kms = sc#.with_spectral_unit(u.km/u.s,velocity_convention=\"radio\").to(u.K) # Change units from Hz to km/s\n",
    "\n",
    "    vel,RA,Dec = sc_kms.world[:,0,0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    try:\n",
    "\n",
    "\n",
    "        sc = sc_kms.spectral_slab(-325. *u.km / u.s, 326. *u.km / u.s)  # Crop out velocities we don't care about  \n",
    "\n",
    "        del sc_kms\n",
    "\n",
    "        HI = sc.header\n",
    "        Nres=Prime_Beam\n",
    "        if(gal==\"NGC253\"):\n",
    "            dist=3.5*10**6\n",
    "        if(gal==\"GC\"):\n",
    "            dist=8.178*10**3#pc\n",
    "        res=  Nres/(dist)*180/np.pi*u.deg/u.pc#deg corresponding to ~3 pc\n",
    "\n",
    "        beam = radio_beam.Beam(major=res, minor=res, pa=0*u.deg)\n",
    "\n",
    "\n",
    "        sc.allow_huge_operations=True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #Now that we have a circular beam, this can be done easily:\n",
    "\n",
    "        if(gal == 'GC'):\n",
    "\n",
    "            cdelt_x = u.Quantity(str(np.abs(sc.header['cdelt1']))+sc.header['cunit1'])\n",
    "            cdelt_y = u.Quantity(str(np.abs(sc.header['cdelt2']))+sc.header['cunit2'])\n",
    "            #center = SkyCoord('0359d56m39.24s', '-00d02m46.176s', frame='galactic')\n",
    "            center = SkyCoord('-00d03m20.76s  ', '-00d02m46.176s', frame='galactic')\n",
    "            center_ra_pix,center_dec_pix = int(sc.wcs[:][:][0].world_to_pixel(center)[0]),int(sc.wcs[:][:][0].world_to_pixel(center)[1])\n",
    "\n",
    "            print(center_dec_pix,center_ra_pix)\n",
    "\n",
    "            print((sc.wcs[:][:][0].pixel_to_world(center_dec_pix,center_ra_pix)),center_dec_pix,center_ra_pix)\n",
    "            PixFov = [int(FOVp[0]/(cdelt_x/u.deg*np.pi/180*8.178*10**3))/2,int(FOVp[1]/(cdelt_y/u.deg*np.pi/180*8.178*10**3))/2]\n",
    "\n",
    "\n",
    "            pixels = np.zeros(np.shape(sc))           \n",
    "            for lmi in range(np.shape(sc)[0]):\n",
    "                for lmj in range(np.shape(sc)[1]):\n",
    "                    for lmk in range(np.shape(sc)[2]):\n",
    "\n",
    "                        up_pixels = abs(lmj-center_dec_pix)#Should not be over the fov in the upwards direction (relative to 0 degrees)\n",
    "                        side_pixels = abs(lmk-center_ra_pix)#Should not be over the fov in the side-side direction (relative to 0 degrees)\n",
    "\n",
    "                        if(up_pixels<PixFov[0] and side_pixels<PixFov[1]):\n",
    "                            #print(lmj,lmk,np.shape(sc))\n",
    "                            pixels[lmi][lmj][lmk] = 1#good\n",
    "                    #print(\"Up pix\",up_pixels,\"Up pix fov\",PixFov[0],\"side pix\",side_pixels,\"side pix fov\",PixFov[1],\"lmj (dec)\",lmj,\"lmk (ra)\",lmk,\"center dec pix\",center_dec_pix,\"center ra pix\",center_ra_pix,cdelt_x_pc,cdelt_y_pc)\n",
    "\n",
    "            bp = np.where(pixels!=1)\n",
    "            #print(pixels)\n",
    "\n",
    "            #Mask teh pixels outside the fov\n",
    "            scCopy = sc.hdu\n",
    "            #sc.hdu.data[bp]=9999#np.nan\n",
    "            scCopy.data[bp]=np.nan\n",
    "            sc = SpectralCube.read(scCopy)\n",
    "            del scCopy\n",
    "\n",
    "        sc.allow_huge_operations=True\n",
    "\n",
    "        \n",
    "        try:\n",
    "            sc = sc.convolve_to(beam)#Smoothe to circular beam at 3 pc by 3 pc\n",
    "        except:\n",
    "            cdelt_x = u.Quantity(str(np.abs(sc.header['cdelt1']))+sc.header['cunit1'])\n",
    "            cdelt_y = u.Quantity(str(np.abs(sc.header['cdelt2']))+sc.header['cunit2'])\n",
    "            if(cdelt_x>cdelt_y):\n",
    "                majorBase=cdelt_x\n",
    "                minorBase=cdelt_y\n",
    "            elif(cdelt_x<cdelt_y):\n",
    "                majorBase=cdelt_y\n",
    "                minorBase=cdelt_x\n",
    "            elif(cdelt_x==cdelt_y):\n",
    "                majorBase=cdelt_x\n",
    "                minorBase=cdelt_x\n",
    "            BaseBeam = radio_beam.Beam(major=majorBase, minor=minorBase, pa=0*u.deg)\n",
    "\n",
    "            sc = sc.with_beam(BaseBeam)\n",
    "\n",
    "            beam = radio_beam.Beam(major=res, minor=res, pa=0*u.deg)\n",
    "            print(BaseBeam,beam,\"C\")\n",
    "            sc.allow_huge_operations=True\n",
    "            print(sc.shape,np.nanmax(sc.hdu.data),'EA')\n",
    "            #Requires me to edit convolve.py and set allow_huge =True\n",
    "            sc = sc.convolve_to(beam)#Smoothe to circular beam at 3 pc by 3 pc\n",
    "            print(np.shape(sc),\"B\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        reheader = copy.deepcopy(sc.hdu.header)\n",
    "\n",
    "\n",
    "        if(gal==\"NGC253\"):\n",
    "            ## Find the number of expected pixels for the new resolution and the location of the left/right, up/down sides \n",
    "            if sc.header['cdelt1']>0:\n",
    "                pix_x    = (res/ovs).to(u.degree).value\n",
    "                origin_x = sc.longitude_extrema[1].to(u.degree).value if gal=='GC' else sc.longitude_extrema[0].to(u.degree).value\n",
    "\n",
    "            else:\n",
    "                pix_x    = -1.*(res/ovs).to(u.degree).value\n",
    "                origin_x = (sc.longitude_extrema[0]).to(u.degree).value if gal=='GC' else (sc.longitude_extrema[1]).to(u.degree).value\n",
    "\n",
    "            if sc.header['cdelt2']>0:\n",
    "                pix_y    = (res/ovs).to(u.degree).value\n",
    "                origin_y = sc.latitude_extrema[0].to(u.degree).value\n",
    "            else:\n",
    "                pix_y    = -1.*(res/ovs).to(u.degree).value\n",
    "                origin_y = sc.latitude_extrema[1].to(u.degree).value\n",
    "\n",
    "            if gal=='NGC253':\n",
    "                npix_x   = int(np.ceil(np.diff(sc.longitude_extrema, n=1)[0]/np.abs(pix_x)).value)\n",
    "                npix_y   = int(np.ceil(np.diff(sc.latitude_extrema, n=1)[0]/np.abs(pix_y)).value)\n",
    "\n",
    "        elif gal=='GC':\n",
    "            ## Find the number of expected pixels for the new resolution and the location of the left/right, up/down sides \n",
    "\n",
    "            if sc.header['cdelt1']>0:\n",
    "                #pix_x    = sc.header['cdelt1']/5#(res/5.).to(u.degree).value*10\n",
    "                pix_x    = (res/ovs).to(u.degree).value\n",
    "                origin_x = 358.5#sc.longitude_extrema[1].to(u.degree).value if gal=='GC' else sc.longitude_extrema[0].to(u.degree).value\n",
    "                if(Line_Name == '_CMZ_CO_J3_2_4.3_start' and kl==5):\n",
    "                    #pix_x    = .55/3*res.to(u.degree).value\n",
    "                    origin_x = 357#sc.longitude_extrema[1].to(u.degree).value if gal=='GC' else sc.longitude_extrema[0].to(u.degree).value\n",
    "                    \n",
    "                #origin_x = sc.longitude_extrema[1].to(u.degree).value if gal=='GC' else sc.longitude_extrema[0].to(u.degree).value\n",
    "\n",
    "            else:\n",
    "                #pix_x    = sc.header['cdelt1']/5#-1.*(res/5.).to(u.degree).value*10\n",
    "                pix_x    = -(res/ovs).to(u.degree).value\n",
    "                origin_x = 1.5#(sc.longitude_extrema[0]).to(u.degree).value if gal=='GC' else (sc.longitude_extrema[1]).to(u.degree).value\n",
    "                #origin_x = (sc.longitude_extrema[0]).to(u.degree).value if gal=='GC' else (sc.longitude_extrema[1]).to(u.degree).value\n",
    "                if(Line_Name == '_CMZ_CO_J3_2_4.3_start' and kl==5):\n",
    "                    #pix_x    = -.55/3*res.to(u.degree).value\n",
    "                    origin_x = 359\n",
    "\n",
    "            if sc.header['cdelt2']>0:\n",
    "                #pix_y    = sc.header['cdelt2']/5#(res/5.).to(u.degree).value*10\n",
    "                pix_y    = (res/ovs).to(u.degree).value\n",
    "                origin_y = -.5#sc.latitude_extrema[0].to(u.degree).value\n",
    "                #origin_y = sc.latitude_extrema[0].to(u.degree).value\n",
    "                if(Line_Name == '_CMZ_CO_J3_2_4.3_start' and kl==5):\n",
    "                    #pix_y    = .55/3*res.to(u.degree).value\n",
    "                    origin_y = -0.55#sc.longitude_extrema[1].to(u.degree).value if gal=='GC' else sc.longitude_extrema[0].to(u.degree).value\n",
    "\n",
    "            else:\n",
    "                #pix_y    = sc.header['cdelt2']/5#-1.*(res/5.).to(u.degree).value*10\n",
    "                pix_y    = -(res/ovs).to(u.degree).value\n",
    "                origin_y = .5#sc.latitude_extrema[1].to(u.degree).value\n",
    "                #origin_y = sc.latitude_extrema[1].to(u.degree).value\n",
    "                if(Line_Name == '_CMZ_CO_J3_2_4.3_start' and kl==5):\n",
    "                    #pix_y    = -.55/3*res.to(u.degree).value/3*res\n",
    "                    origin_y = 0.55#sc.longitude_extrema[1].to(u.degree).value if gal=='GC' else sc.longitude_extrema[0].to(u.degree).value\n",
    "\n",
    "\n",
    "\n",
    "            if gal=='GC':\n",
    "                #manually put in the size to correct for the 360->0 difference and just because it doesnt seem to work\n",
    "                print(\"LA\",((sc.longitude_extrema[0])),(sc.longitude_extrema[1]-360*u.degree),np.abs(pix_x))\n",
    "                print(\"MA\",sc.latitude_extrema,np.abs(pix_y))\n",
    "                #npix_x   =int(np.ceil((sc.longitude_extrema[0]-(sc.longitude_extrema[1]-360*u.degree))/np.abs(pix_x)).value)\n",
    "                #npix_y   =int(np.ceil(np.diff(sc.latitude_extrema, n=1)[0]/np.abs(pix_y)).value)\n",
    "                npix_x   =int(3/np.abs(pix_x))\n",
    "                npix_y   =int(1.2/np.abs(pix_y))\n",
    "                if(Line_Name == '_CMZ_CO_J3_2_4.3_start' and kl==5):\n",
    "                    npix_x   =int(2/np.abs(pix_x))\n",
    "                    npix_y   =int(1.1/np.abs(pix_y))\n",
    "\n",
    "                print(npix_x,npix_y)\n",
    "\n",
    "\n",
    "        #Correct the header to the expected pixels for the new res\n",
    "\n",
    "        reheader['cdelt1'] = pix_x\n",
    "        reheader['cdelt2'] = pix_y\n",
    "\n",
    "        reheader['naxis1'] = npix_x\n",
    "        reheader['naxis2'] = npix_y\n",
    "\n",
    "        reheader['crval1'] = origin_x\n",
    "        reheader['crval2'] = origin_y\n",
    "\n",
    "        reheader['crpix1'] = 0\n",
    "        reheader['crpix2'] = 0\n",
    "        \n",
    "        reheader['CTYPE1'] = \"GLON-SIN\"\n",
    "        reheader['CTYPE2'] = \"GLAT-SIN\"\n",
    "        try:\n",
    "            del reheader['lonpole']\n",
    "            del reheader['latpole']\n",
    "            del reheader['wcsaxes']#Dont need these anymore, maybe?\n",
    "            \n",
    "            del reheader['LBOUND1']\n",
    "            del reheader['LBOUND2']\n",
    "            del reheader['LBOUND3']\n",
    "            del reheader.cards['LBOUND1']\n",
    "            del reheader.cards['LBOUND2']\n",
    "            del reheader.cards['LBOUND3']\n",
    "            \n",
    "            reheader['LBOUND1']=0\n",
    "            reheader['LBOUND2']=0\n",
    "            reheader['LBOUND3']=0\n",
    "            \n",
    "            print(\"12312412\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "            print(\"Failed\")\n",
    "            print(\"-\"*60)\n",
    "            traceback.print_exc(file=sys.stdout)\n",
    "        \n",
    "        # regrid cube to target pixel size\n",
    "        \n",
    "        \n",
    "        \n",
    "        #Cube_Name_Load_HCN = \"Cropped_\"+str(Prime_Beam.value)+\"pc_beam_\"+'_CMZ_HCN_J1_0_4.3_start'+str(FOV[0])+\"x\"+str(FOV[1])+'pc_'+str(3.3)+'_vel_res.fits'\n",
    "        #del reheader\n",
    "        #reheader = SpectralCube.read(Cube_Name_Load_HCN).hdu.header\n",
    "        #reheader[\"CTYPE3\"] = \"VRAD\"\n",
    "        \n",
    "        sc_K_kms = sc.reproject(reheader, order='bilinear', use_memmap=True, filled=True)\n",
    "        del sc\n",
    "        #new = SpectralCube(data=sc_K_kms.hdu.data,wcs = WCS(sc_K_kms.header),header=sc_K_kms.header)\n",
    "        new = SpectralCube(data=sc_K_kms.hdu.data,wcs =WCS(sc_K_kms.header),header=sc_K_kms.header,mask=sc_K_kms.mask)\n",
    "        new.allow_huge_operations=True\n",
    "        new = new*sc_K_kms[0][0][0].unit\n",
    "        #do this because scs dont like being modified\n",
    "        del sc_K_kms\n",
    "        sc_K_kms = new\n",
    "        del new\n",
    "\n",
    "        print(np.nanmax(sc_K_kms),np.shape(sc_K_kms))#These should be a non zero float and the shape of the cube (30,~1000,~1000)\n",
    "        \n",
    "\n",
    "        NGC_CO_J3_2 = sc_K_kms\n",
    "        del sc_K_kms\n",
    "        NGC_CO_J3_2.allow_huge_operations=True\n",
    "\n",
    "        #do this again to crop the extra pixels off\n",
    "\n",
    "        sc=NGC_CO_J3_2\n",
    "\n",
    "        sc = sc.convolve_to(beam)#Smoothe to circular beam at 3 pc by 3 pc\n",
    "\n",
    "\n",
    "        #Write the intermediary cubes that will then be spliced together\n",
    "        del NGC_CO_J3_2\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        fwhm_factor = np.sqrt(8*np.log(2))\n",
    "\n",
    "        vel,RA,Dec =sc.world[:,0,0]\n",
    "        for km in range(5,6):\n",
    "            scWsc_copy = sc\n",
    "            vel_prime = min_vel*((km*iter_factor+1))\n",
    "            if(km==5):\n",
    "                vel_prime=2.5\n",
    "            Cube_Name_Save = str(Prime_Beam.value)+\"pc_beam_\"+Line_Name+str(FOVp[0])+\"x\"+str(FOVp[1])+'pc_'+str(vel_prime)+Side+'_vel_res_NEW'+Smoothe_title+'.fits'\n",
    "            if(gal==\"GC\"):\n",
    "                vel = np.arange(-300,301,vel_prime)*u.km/u.s    \n",
    "            else:\n",
    "                vel = np.arange(0,501,vel_prime)*u.km/u.s    \n",
    "\n",
    "            G_width = np.sqrt(2.5**2-1**2)\n",
    "            if(km==5):\n",
    "                #G_width = 4\n",
    "                G_width = np.sqrt(2.5**2-1**2)\n",
    "                if(Match_to_HCO):\n",
    "                    G_width = np.sqrt(3.3**2-1**2)\n",
    "            if(km==5 and Smoothe_4):\n",
    "                G_width = 4\n",
    "            if(km==5 and Smoothe_2_5):\n",
    "                G_width = 2.5/1#G_width = 2.5/1\n",
    "                \n",
    "            scWsc_copy = scWsc_copy.spectral_smooth(Gaussian1DKernel(G_width/fwhm_factor))#Preserves information from the pixels lost in downsampling\n",
    "            scWsc_copy = scWsc_copy.with_spectral_unit(u.km / u.s, velocity_convention='optical', rest_value=restfreq)\n",
    "            scWsc_copy = scWsc_copy.spectral_interpolate(spectral_grid=vel) # Match velocities to -250 251 range \n",
    "\n",
    "\n",
    "\n",
    "            scWsc_copy.write(Cube_Name_Save,overwrite=True)\n",
    "            gc.collect()\n",
    "            #scWsc.write(\"NGC_Spliced_Reprojected_Whole_CO_32.fits\",overwrite=True)\n",
    "        del scWsc_copy\n",
    "        \n",
    "        del sc\n",
    "        \n",
    "        gc.collect()######################################################################\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(kl)\n",
    "        print(\"Failed\")\n",
    "        print(\"-\"*60)\n",
    "        traceback.print_exc(file=sys.stdout)\n",
    "\n",
    "\n",
    "      \n",
    "    \n",
    "print(\"done\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325b7c04-5f3f-4933-99aa-639445288d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just Using CO 3-2 right now\n",
    "\n",
    "files = [\"12CO_GC_003-005_mosaic.fit\"]\n",
    "#files=[\"Pre-Smoothed.fits\"]\n",
    "\n",
    "\n",
    "\n",
    "sc = SpectralCube.read(files[0])  \n",
    "Cube_Name = files[0]+\"Header_Fix.fits\"\n",
    "print(1)\n",
    "sc.allow_huge_operations=True\n",
    "sc = sc.with_spectral_unit(u.km/u.s,velocity_convention=\"radio\").to(u.K) # Change units from Hz to km/s\n",
    "new = SpectralCube(data=sc.hdu.data,wcs =WCS(sc.header),mask=sc.mask)\n",
    "new.allow_huge_operations=True\n",
    "new=new*sc[0][0][0].unit\n",
    "print(2)\n",
    "del sc\n",
    "sc=new\n",
    "print(3)\n",
    "del new\n",
    "\n",
    "sc.write(Cube_Name,overwrite=True)\n",
    "print(4)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c7e402-f21d-4758-82df-cf7331a5540f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(np.shape(bp))\n",
    "#np.savetxt(\"bp.txt\",np.array(bp[1][999999:9999999],dtype=int))\n",
    "#np.savetxt(\"bp2.txt\",np.array(bp[2][0:99999],dtype=int))\n",
    "#Just Using CO 3-2 right now\n",
    "#files = [\"12CO_GC_359-000_mosaic.fit\"]\n",
    "files = [\"12CO_GC_003-005_mosaic.fit\"]\n",
    "files = [files[0]+\"Header_Fix.fits\"]\n",
    "      \n",
    "\n",
    "#files=[\"Pre-Smoothed.fits\"]\n",
    "      \n",
    "#FOV = [400,800]#pc\n",
    "FOV = [70,360]#pc\n",
    "gal=\"GC\"\n",
    "Min_res=4.3*u.pc#Smallest resolution\n",
    "\n",
    "\n",
    "iterations = 6\n",
    "Line_Name = '_CMZ_CO_J3_2_4.3_start'\n",
    "Side=\"FLRH\"\n",
    "ovs = 3 #over sample factor for beam\n",
    "min_vel = 3.3#km/s\n",
    "#Beam_Sizes = np.linspace(Smallest_beam,Smallest_beam*iterations, np.diff(Smallest_beam,Smallest_beam*iterations)/iterations)\n",
    "iter_factor = 1/5\n",
    "Smoothe_4 = False\n",
    "Match_to_HCO = False\n",
    "if(Smoothe_4):\n",
    "    Smoothe_title=\"G_width_4\"\n",
    "else:\n",
    "    Smoothe_title=''\n",
    "    if(Match_to_HCO):\n",
    "        Smoothe_title='Smoothe_to_3.3'\n",
    "Smoothe_2_5 =True\n",
    "if(Smoothe_2_5):\n",
    "    Smoothe_title=\"Smoothe_to_2.5\"\n",
    "for kl in range(5,6):\n",
    "    Prime_Beam = Min_res*((kl*iter_factor+1))#Beam_Sizes[kl]\n",
    "    if(kl==5):\n",
    "        Prime_Beam = 3*u.pc#Nico\n",
    "        ovs=5\n",
    "        FOVp=[200,800]\n",
    "    else:\n",
    "        ovs=3\n",
    "        FOVp=FOV\n",
    "    #Need to break it up into 30-wide vel slices to do the reprojection (ram-draw too high)\n",
    "    \n",
    "\n",
    "    print(kl)\n",
    "    Cube_Name = str(Prime_Beam.value)+\"pc_beam_\"+Line_Name+str(FOVp[0])+\"x\"+str(FOVp[1])+Side+'pc_NEW.fits'\n",
    "    sc = SpectralCube.read(files[0])  \n",
    "\n",
    "\n",
    "    Nres=4.3*u.pc\n",
    "    dist=8.178*10**3#pc\n",
    "    res=  Nres/(dist)*180/np.pi*u.deg/u.pc#deg corresponding to ~3 pc\n",
    "    print(res,\"A\")\n",
    "\n",
    "\n",
    "\n",
    "    sc = sc[:,:,:]# Make a subcube\n",
    "\n",
    "    \n",
    "    #Put in the right system\n",
    "    sc.allow_huge_operations=True\n",
    "    sc_kms = sc#.with_spectral_unit(u.km/u.s,velocity_convention=\"radio\").to(u.K) # Change units from Hz to km/s\n",
    "\n",
    "    vel,RA,Dec = sc_kms.world[:,0,0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    try:\n",
    "\n",
    "\n",
    "        sc = sc_kms.spectral_slab(-325. *u.km / u.s, 326. *u.km / u.s)  # Crop out velocities we don't care about  \n",
    "\n",
    "        del sc_kms\n",
    "\n",
    "        HI = sc.header\n",
    "        Nres=Prime_Beam\n",
    "        if(gal==\"NGC253\"):\n",
    "            dist=3.5*10**6\n",
    "        if(gal==\"GC\"):\n",
    "            dist=8.178*10**3#pc\n",
    "        res=  Nres/(dist)*180/np.pi*u.deg/u.pc#deg corresponding to ~3 pc\n",
    "\n",
    "        beam = radio_beam.Beam(major=res, minor=res, pa=0*u.deg)\n",
    "\n",
    "\n",
    "        sc.allow_huge_operations=True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #Now that we have a circular beam, this can be done easily:\n",
    "\n",
    "        if(gal == 'GC'):\n",
    "\n",
    "            cdelt_x = u.Quantity(str(np.abs(sc.header['cdelt1']))+sc.header['cunit1'])\n",
    "            cdelt_y = u.Quantity(str(np.abs(sc.header['cdelt2']))+sc.header['cunit2'])\n",
    "            #center = SkyCoord('0359d56m39.24s', '-00d02m46.176s', frame='galactic')\n",
    "            center = SkyCoord('-00d03m20.76s  ', '-00d02m46.176s', frame='galactic')\n",
    "            center_ra_pix,center_dec_pix = int(sc.wcs[:][:][0].world_to_pixel(center)[0]),int(sc.wcs[:][:][0].world_to_pixel(center)[1])\n",
    "\n",
    "            print(center_dec_pix,center_ra_pix)\n",
    "\n",
    "            print((sc.wcs[:][:][0].pixel_to_world(center_dec_pix,center_ra_pix)),center_dec_pix,center_ra_pix)\n",
    "            PixFov = [int(FOVp[0]/(cdelt_x/u.deg*np.pi/180*8.178*10**3))/2,int(FOVp[1]/(cdelt_y/u.deg*np.pi/180*8.178*10**3))/2]\n",
    "\n",
    "\n",
    "            pixels = np.zeros(np.shape(sc))           \n",
    "            for lmi in range(np.shape(sc)[0]):\n",
    "                for lmj in range(np.shape(sc)[1]):\n",
    "                    for lmk in range(np.shape(sc)[2]):\n",
    "\n",
    "                        up_pixels = abs(lmj-center_dec_pix)#Should not be over the fov in the upwards direction (relative to 0 degrees)\n",
    "                        side_pixels = abs(lmk-center_ra_pix)#Should not be over the fov in the side-side direction (relative to 0 degrees)\n",
    "\n",
    "                        if(up_pixels<PixFov[0] and side_pixels<PixFov[1]):\n",
    "                            #print(lmj,lmk,np.shape(sc))\n",
    "                            pixels[lmi][lmj][lmk] = 1#good\n",
    "                    #print(\"Up pix\",up_pixels,\"Up pix fov\",PixFov[0],\"side pix\",side_pixels,\"side pix fov\",PixFov[1],\"lmj (dec)\",lmj,\"lmk (ra)\",lmk,\"center dec pix\",center_dec_pix,\"center ra pix\",center_ra_pix,cdelt_x_pc,cdelt_y_pc)\n",
    "\n",
    "            bp = np.where(pixels!=1)\n",
    "            #print(pixels)\n",
    "\n",
    "            #Mask teh pixels outside the fov\n",
    "            scCopy = sc.hdu\n",
    "            #sc.hdu.data[bp]=9999#np.nan\n",
    "            scCopy.data[bp]=np.nan\n",
    "            sc = SpectralCube.read(scCopy)\n",
    "            del scCopy\n",
    "\n",
    "        sc.allow_huge_operations=True\n",
    "\n",
    "        \n",
    "        try:\n",
    "            sc = sc.convolve_to(beam)#Smoothe to circular beam at 3 pc by 3 pc\n",
    "        except:\n",
    "            cdelt_x = u.Quantity(str(np.abs(sc.header['cdelt1']))+sc.header['cunit1'])\n",
    "            cdelt_y = u.Quantity(str(np.abs(sc.header['cdelt2']))+sc.header['cunit2'])\n",
    "            if(cdelt_x>cdelt_y):\n",
    "                majorBase=cdelt_x\n",
    "                minorBase=cdelt_y\n",
    "            elif(cdelt_x<cdelt_y):\n",
    "                majorBase=cdelt_y\n",
    "                minorBase=cdelt_x\n",
    "            elif(cdelt_x==cdelt_y):\n",
    "                majorBase=cdelt_x\n",
    "                minorBase=cdelt_x\n",
    "            BaseBeam = radio_beam.Beam(major=majorBase, minor=minorBase, pa=0*u.deg)\n",
    "\n",
    "            sc = sc.with_beam(BaseBeam)\n",
    "\n",
    "            beam = radio_beam.Beam(major=res, minor=res, pa=0*u.deg)\n",
    "            print(BaseBeam,beam,\"C\")\n",
    "            sc.allow_huge_operations=True\n",
    "            print(sc.shape,np.nanmax(sc.hdu.data),'EA')\n",
    "            #Requires me to edit convolve.py and set allow_huge =True\n",
    "            sc = sc.convolve_to(beam)#Smoothe to circular beam at 3 pc by 3 pc\n",
    "            print(np.shape(sc),\"B\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        reheader = copy.deepcopy(sc.hdu.header)\n",
    "\n",
    "\n",
    "        if(gal==\"NGC253\"):\n",
    "            ## Find the number of expected pixels for the new resolution and the location of the left/right, up/down sides \n",
    "            if sc.header['cdelt1']>0:\n",
    "                pix_x    = (res/ovs).to(u.degree).value\n",
    "                origin_x = sc.longitude_extrema[1].to(u.degree).value if gal=='GC' else sc.longitude_extrema[0].to(u.degree).value\n",
    "\n",
    "            else:\n",
    "                pix_x    = -1.*(res/ovs).to(u.degree).value\n",
    "                origin_x = (sc.longitude_extrema[0]).to(u.degree).value if gal=='GC' else (sc.longitude_extrema[1]).to(u.degree).value\n",
    "\n",
    "            if sc.header['cdelt2']>0:\n",
    "                pix_y    = (res/ovs).to(u.degree).value\n",
    "                origin_y = sc.latitude_extrema[0].to(u.degree).value\n",
    "            else:\n",
    "                pix_y    = -1.*(res/ovs).to(u.degree).value\n",
    "                origin_y = sc.latitude_extrema[1].to(u.degree).value\n",
    "\n",
    "            if gal=='NGC253':\n",
    "                npix_x   = int(np.ceil(np.diff(sc.longitude_extrema, n=1)[0]/np.abs(pix_x)).value)\n",
    "                npix_y   = int(np.ceil(np.diff(sc.latitude_extrema, n=1)[0]/np.abs(pix_y)).value)\n",
    "\n",
    "        elif gal=='GC':\n",
    "            ## Find the number of expected pixels for the new resolution and the location of the left/right, up/down sides \n",
    "\n",
    "            if sc.header['cdelt1']>0:\n",
    "                #pix_x    = sc.header['cdelt1']/5#(res/5.).to(u.degree).value*10\n",
    "                pix_x    = (res/ovs).to(u.degree).value\n",
    "                origin_x = 358.5#sc.longitude_extrema[1].to(u.degree).value if gal=='GC' else sc.longitude_extrema[0].to(u.degree).value\n",
    "                if(Line_Name == '_CMZ_CO_J3_2_4.3_start' and kl==5):\n",
    "                    #pix_x    = .55/3*res.to(u.degree).value\n",
    "                    origin_x = 2#sc.longitude_extrema[1].to(u.degree).value if gal=='GC' else sc.longitude_extrema[0].to(u.degree).value\n",
    "                    \n",
    "                #origin_x = sc.longitude_extrema[1].to(u.degree).value if gal=='GC' else sc.longitude_extrema[0].to(u.degree).value\n",
    "\n",
    "            else:\n",
    "                #pix_x    = sc.header['cdelt1']/5#-1.*(res/5.).to(u.degree).value*10\n",
    "                pix_x    = -(res/ovs).to(u.degree).value\n",
    "                origin_x = 1.5#(sc.longitude_extrema[0]).to(u.degree).value if gal=='GC' else (sc.longitude_extrema[1]).to(u.degree).value\n",
    "                #origin_x = (sc.longitude_extrema[0]).to(u.degree).value if gal=='GC' else (sc.longitude_extrema[1]).to(u.degree).value\n",
    "                if(Line_Name == '_CMZ_CO_J3_2_4.3_start' and kl==5):\n",
    "                    #pix_x    = -.55/3*res.to(u.degree).value\n",
    "                    origin_x = 4\n",
    "\n",
    "            if sc.header['cdelt2']>0:\n",
    "                #pix_y    = sc.header['cdelt2']/5#(res/5.).to(u.degree).value*10\n",
    "                pix_y    = (res/ovs).to(u.degree).value\n",
    "                origin_y = -.5#sc.latitude_extrema[0].to(u.degree).value\n",
    "                #origin_y = sc.latitude_extrema[0].to(u.degree).value\n",
    "                if(Line_Name == '_CMZ_CO_J3_2_4.3_start' and kl==5):\n",
    "                    #pix_y    = .55/3*res.to(u.degree).value\n",
    "                    origin_y = -0.55#sc.longitude_extrema[1].to(u.degree).value if gal=='GC' else sc.longitude_extrema[0].to(u.degree).value\n",
    "\n",
    "            else:\n",
    "                #pix_y    = sc.header['cdelt2']/5#-1.*(res/5.).to(u.degree).value*10\n",
    "                pix_y    = -(res/ovs).to(u.degree).value\n",
    "                origin_y = .5#sc.latitude_extrema[1].to(u.degree).value\n",
    "                #origin_y = sc.latitude_extrema[1].to(u.degree).value\n",
    "                if(Line_Name == '_CMZ_CO_J3_2_4.3_start' and kl==5):\n",
    "                    #pix_y    = -.55/3*res.to(u.degree).value/3*res\n",
    "                    origin_y = 0.55#sc.longitude_extrema[1].to(u.degree).value if gal=='GC' else sc.longitude_extrema[0].to(u.degree).value\n",
    "\n",
    "\n",
    "\n",
    "            if gal=='GC':\n",
    "                #manually put in the size to correct for the 360->0 difference and just because it doesnt seem to work\n",
    "                print(\"LA\",((sc.longitude_extrema[0])),(sc.longitude_extrema[1]-360*u.degree),np.abs(pix_x))\n",
    "                print(\"MA\",sc.latitude_extrema,np.abs(pix_y))\n",
    "                #npix_x   =int(np.ceil((sc.longitude_extrema[0]-(sc.longitude_extrema[1]-360*u.degree))/np.abs(pix_x)).value)\n",
    "                #npix_y   =int(np.ceil(np.diff(sc.latitude_extrema, n=1)[0]/np.abs(pix_y)).value)\n",
    "                npix_x   =int(3/np.abs(pix_x))\n",
    "                npix_y   =int(1.2/np.abs(pix_y))\n",
    "                if(Line_Name == '_CMZ_CO_J3_2_4.3_start' and kl==5):\n",
    "                    npix_x   =int(2/np.abs(pix_x))\n",
    "                    npix_y   =int(1.1/np.abs(pix_y))\n",
    "\n",
    "                print(npix_x,npix_y)\n",
    "\n",
    "\n",
    "        #Correct the header to the expected pixels for the new res\n",
    "\n",
    "        reheader['cdelt1'] = pix_x\n",
    "        reheader['cdelt2'] = pix_y\n",
    "\n",
    "        reheader['naxis1'] = npix_x\n",
    "        reheader['naxis2'] = npix_y\n",
    "\n",
    "        reheader['crval1'] = origin_x\n",
    "        reheader['crval2'] = origin_y\n",
    "\n",
    "        reheader['crpix1'] = 0\n",
    "        reheader['crpix2'] = 0\n",
    "        \n",
    "        reheader['CTYPE1'] = \"GLON-SIN\"\n",
    "        reheader['CTYPE2'] = \"GLAT-SIN\"\n",
    "        try:\n",
    "            del reheader['lonpole']\n",
    "            del reheader['latpole']\n",
    "            del reheader['wcsaxes']#Dont need these anymore, maybe?\n",
    "            \n",
    "            del reheader['LBOUND1']\n",
    "            del reheader['LBOUND2']\n",
    "            del reheader['LBOUND3']\n",
    "            del reheader.cards['LBOUND1']\n",
    "            del reheader.cards['LBOUND2']\n",
    "            del reheader.cards['LBOUND3']\n",
    "            \n",
    "            reheader['LBOUND1']=0\n",
    "            reheader['LBOUND2']=0\n",
    "            reheader['LBOUND3']=0\n",
    "            \n",
    "            print(\"12312412\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "            print(\"Failed\")\n",
    "            print(\"-\"*60)\n",
    "            traceback.print_exc(file=sys.stdout)\n",
    "        \n",
    "        # regrid cube to target pixel size\n",
    "        \n",
    "        \n",
    "        \n",
    "        #Cube_Name_Load_HCN = \"Cropped_\"+str(Prime_Beam.value)+\"pc_beam_\"+'_CMZ_HCN_J1_0_4.3_start'+str(FOV[0])+\"x\"+str(FOV[1])+'pc_'+str(3.3)+'_vel_res.fits'\n",
    "        #del reheader\n",
    "        #reheader = SpectralCube.read(Cube_Name_Load_HCN).hdu.header\n",
    "        #reheader[\"CTYPE3\"] = \"VRAD\"\n",
    "        \n",
    "        sc_K_kms = sc.reproject(reheader, order='bilinear', use_memmap=True, filled=True)\n",
    "        del sc\n",
    "        #new = SpectralCube(data=sc_K_kms.hdu.data,wcs = WCS(sc_K_kms.header),header=sc_K_kms.header)\n",
    "        new = SpectralCube(data=sc_K_kms.hdu.data,wcs =WCS(sc_K_kms.header),header=sc_K_kms.header,mask=sc_K_kms.mask)\n",
    "        new.allow_huge_operations=True\n",
    "        new = new*sc_K_kms[0][0][0].unit\n",
    "        #do this because scs dont like being modified\n",
    "        del sc_K_kms\n",
    "        sc_K_kms = new\n",
    "        del new\n",
    "\n",
    "        print(np.nanmax(sc_K_kms),np.shape(sc_K_kms))#These should be a non zero float and the shape of the cube (30,~1000,~1000)\n",
    "        \n",
    "\n",
    "        NGC_CO_J3_2 = sc_K_kms\n",
    "        del sc_K_kms\n",
    "        NGC_CO_J3_2.allow_huge_operations=True\n",
    "\n",
    "        #do this again to crop the extra pixels off\n",
    "\n",
    "        sc=NGC_CO_J3_2\n",
    "\n",
    "        sc = sc.convolve_to(beam)#Smoothe to circular beam at 3 pc by 3 pc\n",
    "\n",
    "\n",
    "        #Write the intermediary cubes that will then be spliced together\n",
    "        del NGC_CO_J3_2\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        fwhm_factor = np.sqrt(8*np.log(2))\n",
    "\n",
    "        vel,RA,Dec =sc.world[:,0,0]\n",
    "        for km in range(5,6):\n",
    "            scWsc_copy = sc\n",
    "            vel_prime = min_vel*((km*iter_factor+1))\n",
    "            if(km==5):\n",
    "                vel_prime=2.5\n",
    "            Cube_Name_Save = str(Prime_Beam.value)+\"pc_beam_\"+Line_Name+str(FOVp[0])+\"x\"+str(FOVp[1])+'pc_'+str(vel_prime)+Side+'_vel_res_NEW'+Smoothe_title+'.fits'\n",
    "            if(gal==\"GC\"):\n",
    "                vel = np.arange(-300,301,vel_prime)*u.km/u.s    \n",
    "            else:\n",
    "                vel = np.arange(0,501,vel_prime)*u.km/u.s    \n",
    "\n",
    "            G_width = np.sqrt(2.5**2-1**2)\n",
    "            if(km==5):\n",
    "                #G_width = 4\n",
    "                G_width = np.sqrt(2.5**2-1**2)\n",
    "                if(Match_to_HCO):\n",
    "                    G_width = np.sqrt(3.3**2-1**2)\n",
    "            if(km==5 and Smoothe_4):\n",
    "                G_width = 4\n",
    "            if(km==5 and Smoothe_2_5):\n",
    "                G_width = 2.5/1#G_width = 2.5/1\n",
    "                \n",
    "            scWsc_copy = scWsc_copy.spectral_smooth(Gaussian1DKernel(G_width/fwhm_factor))#Preserves information from the pixels lost in downsampling\n",
    "            scWsc_copy = scWsc_copy.with_spectral_unit(u.km / u.s, velocity_convention='optical', rest_value=restfreq)\n",
    "            scWsc_copy = scWsc_copy.spectral_interpolate(spectral_grid=vel) # Match velocities to -250 251 range \n",
    "\n",
    "\n",
    "\n",
    "            scWsc_copy.write(Cube_Name_Save,overwrite=True)\n",
    "            gc.collect()\n",
    "            #scWsc.write(\"NGC_Spliced_Reprojected_Whole_CO_32.fits\",overwrite=True)\n",
    "        del scWsc_copy\n",
    "        \n",
    "        del sc\n",
    "        \n",
    "        gc.collect()######################################################################\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(kl)\n",
    "        print(\"Failed\")\n",
    "        print(\"-\"*60)\n",
    "        traceback.print_exc(file=sys.stdout)\n",
    "\n",
    "\n",
    "      \n",
    "    \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fafe8e3-b0de-4f05-92b8-f9daaea5f855",
   "metadata": {},
   "source": [
    "# 6.1 Splicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8154a8d-ad30-4997-8287-29140014d14e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Splice right and left\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Splice CO\n",
    "gal=\"GC\"\n",
    "Min_res=4.3*u.pc#Smallest resolution\n",
    "\n",
    "\n",
    "iterations = 6\n",
    "Line_Name = '_CMZ_CO_J3_2_4.3_start'\n",
    "\n",
    "ovs = 3 #over sample factor for beam\n",
    "min_vel = 3.3#km/s\n",
    "iter_factor = 1/5\n",
    "\n",
    "\n",
    "FOV = [70,360]#pc\n",
    "Min_res=4.3*u.pc#Smallest resolution\n",
    "\n",
    "Smoothe_4 = False\n",
    "Match_to_HCO = False\n",
    "if(Smoothe_4):\n",
    "    Smoothe_title=\"G_width_4\"\n",
    "else:\n",
    "    Smoothe_title=''\n",
    "    if(Match_to_HCO):\n",
    "        Smoothe_title='Smoothe_to_3.3'\n",
    "Smoothe_2_5 =True\n",
    "if(Smoothe_2_5):\n",
    "    Smoothe_title=\"Smoothe_to_2.5\"\n",
    "    \n",
    "    \n",
    "if(Line_Name == '_CMZ_CO_J3_2_4.3_start'):\n",
    "\n",
    "    for kl in range(5,6):\n",
    "      \n",
    "        Prime_Beam = Min_res*((kl*iter_factor+1))#\n",
    "        if(kl==5):\n",
    "            Prime_Beam = 3*u.pc#Nico\n",
    "            FOVp=[200,800]\n",
    "        else:\n",
    "            FOVp=FOV\n",
    "            \n",
    "        print(Prime_Beam)\n",
    "    \n",
    "        for km in range(5,6):\n",
    "            vel_prime = min_vel*((km*iter_factor+1))\n",
    "            if(km==5):\n",
    "                vel_prime=2.5\n",
    "                ovs=5\n",
    "                \n",
    "            \n",
    "            Side=\"LH\"\n",
    "            Cube_Name_Load_LH = str(Prime_Beam.value)+\"pc_beam_\"+Line_Name+str(FOVp[0])+\"x\"+str(FOVp[1])+'pc_'+str(vel_prime)+Side+'_vel_res_NEW'+Smoothe_title+'.fits'\n",
    "            Side=\"RH\"\n",
    "            Cube_Name_Load_RH =str(Prime_Beam.value)+\"pc_beam_\"+Line_Name+str(FOVp[0])+\"x\"+str(FOVp[1])+'pc_'+str(vel_prime)+Side+'_vel_res_NEW'+Smoothe_title+'.fits'\n",
    "            Side=\"FRH\"\n",
    "            Cube_Name_Load_FRH = str(Prime_Beam.value)+\"pc_beam_\"+Line_Name+str(FOVp[0])+\"x\"+str(FOVp[1])+'pc_'+str(vel_prime)+Side+'_vel_res_NEW'+Smoothe_title+'.fits'\n",
    "            Side=\"FLRH\"\n",
    "            Cube_Name_Load_FLH = str(Prime_Beam.value)+\"pc_beam_\"+Line_Name+str(FOVp[0])+\"x\"+str(FOVp[1])+'pc_'+str(vel_prime)+Side+'_vel_res_NEW'+Smoothe_title+'.fits'\n",
    "\n",
    "            Cube_Name_Save = str(Prime_Beam.value)+\"pc_beam_\"+Line_Name+str(FOVp[0])+\"x\"+str(FOVp[1])+'pc_'+str(vel_prime)+'_vel_res_NEW'+Smoothe_title+'.fits'\n",
    "\n",
    "            SCR = SpectralCube.read(Cube_Name_Load_RH)\n",
    "            SCR = SCR.with_spectral_unit(u.km / u.s, velocity_convention='radio', rest_value=restfreq)\n",
    "            vel,RA,Dec = SCR.world[:,0,0]\n",
    "            print(vel)\n",
    "            SCL=SpectralCube.read(Cube_Name_Load_LH)\n",
    "            SCL = SCL.with_spectral_unit(u.km / u.s, velocity_convention='radio', rest_value=restfreq)\n",
    "            vel,RA,Dec = SCL.world[:,0,0]\n",
    "            \n",
    "            SCFR=SpectralCube.read(Cube_Name_Load_FRH)\n",
    "            SCFR = SCFR.with_spectral_unit(u.km / u.s, velocity_convention='radio', rest_value=restfreq)\n",
    "            vel,RA,Dec = SCFR.world[:,0,0]\n",
    "            \n",
    "            SCFL=SpectralCube.read(Cube_Name_Load_FLH)\n",
    "            SCFL = SCFL.with_spectral_unit(u.km / u.s, velocity_convention='radio', rest_value=restfreq)\n",
    "            vel,RA,Dec = SCFL.world[:,0,0]\n",
    "            \n",
    "\n",
    "            print(SCR[0][200][200],SCFR[0][200][200],SCL[0][200][200],SCFL[0][200][200])\n",
    "           \n",
    "            \n",
    "            \n",
    "            if gal=='GC' and Line_Name=='_CMZ_CO_J3_2_4.3_start' and kl==5:\n",
    "                reheader = copy.deepcopy(SCFR.hdu.header)\n",
    "                \n",
    "                dist=8.178*10**3#pc\n",
    "                res=  Prime_Beam/(dist)*180/np.pi*u.deg/u.pc#deg corresponding to ~3 pc\n",
    "                ## Find the number of expected pixels for the new resolution and the location of the left/right, up/down sides \n",
    "\n",
    "                if reheader['cdelt1']>0:\n",
    "                    #pix_x    = sc.header['cdelt1']/5#(res/5.).to(u.degree).value*10\n",
    "                    pix_x    = (res/ovs).to(u.degree).value\n",
    "                    origin_x = 357\n",
    "                    #pix_x    = .55/3*res.to(u.degree).value\n",
    "               \n",
    "\n",
    "                else:\n",
    "                    #pix_x    = sc.header['cdelt1']/5#-1.*(res/5.).to(u.degree).value*10\n",
    "                    pix_x    = -(res/ovs).to(u.degree).value\n",
    "                    origin_x = 3\n",
    "                    #pix_x    = -.55/3*res.to(u.degree).value\n",
    "\n",
    "                if reheader['cdelt2']>0:\n",
    "                    #pix_y    = sc.header['cdelt2']/5#(res/5.).to(u.degree).value*10\n",
    "                    pix_y    = (res/ovs).to(u.degree).value\n",
    "                    origin_y = -.5#sc.latitude_extrema[0].to(u.degree).value\n",
    "                    #origin_y = sc.latitude_extrema[0].to(u.degree).value\n",
    "                    if(Line_Name == '_CMZ_CO_J3_2_4.3_start' and kl==5):\n",
    "                        #pix_y    = .55/3*res.to(u.degree).value\n",
    "                        origin_y = -0.6#sc.longitude_extrema[1].to(u.degree).value if gal=='GC' else sc.longitude_extrema[0].to(u.degree).value\n",
    "\n",
    "                else:\n",
    "                    #pix_y    = sc.header['cdelt2']/5#-1.*(res/5.).to(u.degree).value*10\n",
    "                    pix_y    = -(res/ovs).to(u.degree).value\n",
    "                    #pix_y    = -.55/3*res.to(u.degree).value\n",
    "                    origin_y = .5#sc.latitude_extrema[1].to(u.degree).value\n",
    "                    #origin_y = sc.latitude_extrema[1].to(u.degree).value\n",
    "                    origin_y = 0.6#sc.longitude_extrema[1].to(u.degree).value if gal=='GC' else sc.longitude_extrema[0].to(u.degree).value\n",
    "\n",
    "\n",
    "\n",
    "                if gal=='GC':\n",
    "                    \n",
    "                    #npix_x   =int(np.ceil((sc.longitude_extrema[0]-(sc.longitude_extrema[1]-360*u.degree))/np.abs(pix_x)).value)\n",
    "                    #npix_y   =int(np.ceil(np.diff(sc.latitude_extrema, n=1)[0]/np.abs(pix_y)).value)\n",
    "                    npix_x   =int(3/np.abs(pix_x))\n",
    "                    npix_y   =int(1.2/np.abs(pix_y))\n",
    "                    if(Line_Name == '_CMZ_CO_J3_2_4.3_start' and kl==5):\n",
    "                        npix_x   =int(6/np.abs(pix_x))\n",
    "                        npix_y   =int(1.2/np.abs(pix_y))\n",
    "\n",
    "                    print(npix_x,npix_y)\n",
    "\n",
    "\n",
    "                #Correct the header to the expected pixels for the new res\n",
    "\n",
    "                reheader['cdelt1'] = pix_x\n",
    "                reheader['cdelt2'] = pix_y\n",
    "\n",
    "                reheader['naxis1'] = npix_x\n",
    "                reheader['naxis2'] = npix_y\n",
    "\n",
    "                reheader['crval1'] = origin_x\n",
    "                reheader['crval2'] = origin_y\n",
    "\n",
    "                reheader['crpix1'] = 0\n",
    "                reheader['crpix2'] = 0\n",
    "\n",
    "                reheader['CTYPE1'] = \"GLON-SIN\"\n",
    "                reheader['CTYPE2'] = \"GLAT-SIN\"\n",
    "                try:\n",
    "                    del reheader['lonpole']\n",
    "                    del reheader['latpole']\n",
    "                    del reheader['wcsaxes']#Dont need these anymore, maybe?\n",
    "\n",
    "                    del reheader['LBOUND1']\n",
    "                    del reheader['LBOUND2']\n",
    "                    del reheader['LBOUND3']\n",
    "                    del reheader.cards['LBOUND1']\n",
    "                    del reheader.cards['LBOUND2']\n",
    "                    del reheader.cards['LBOUND3']\n",
    "\n",
    "                    reheader['LBOUND1']=0\n",
    "                    reheader['LBOUND2']=0\n",
    "                    reheader['LBOUND3']=0\n",
    "\n",
    "                    print(\"12312412\")\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "\n",
    "                    print(\"Failed\")\n",
    "                    print(\"-\"*60)\n",
    "                    traceback.print_exc(file=sys.stdout)\n",
    "\n",
    "\n",
    "                    # regrid cube to target pixel size\n",
    "\n",
    "\n",
    "\n",
    "                #Cube_Name_Load_HCN = \"Cropped_\"+str(Prime_Beam.value)+\"pc_beam_\"+'_CMZ_HCN_J1_0_4.3_start'+str(FOV[0])+\"x\"+str(FOV[1])+'pc_'+str(3.3)+'_vel_res.fits'\n",
    "                #del reheader\n",
    "                #reheader = SpectralCube.read(Cube_Name_Load_HCN).hdu.header\n",
    "                #reheader[\"CTYPE3\"] = \"VRAD\"\n",
    "                \n",
    "                \n",
    "                SCR.write(\"test1.fits\",overwrite=True)\n",
    "                \n",
    "                SCR.write(\"test8.fits\",overwrite=True)\n",
    "                SCRN = SCR.reproject(reheader, order='bilinear', use_memmap=True, filled=True)\n",
    "                SCRN.write(\"test2.fits\",overwrite=True)\n",
    "                del SCR\n",
    "                #new = SpectralCube(data=sc_K_kms.hdu.data,wcs = WCS(sc_K_kms.header),header=sc_K_kms.header)\n",
    "                SCR = SpectralCube(data=SCRN.hdu.data,wcs =WCS(SCRN.header),header=SCRN.header,mask=SCRN.mask)\n",
    "                SCR.allow_huge_operations=True\n",
    "                SCR = SCR*SCRN[0][0][0].unit\n",
    "                SCR.write(\"test3.fits\",overwrite=True)\n",
    "                \n",
    "                del SCRN\n",
    "                SCLN = SCL.reproject(reheader, order='bilinear', use_memmap=True, filled=True)\n",
    "                del SCL\n",
    "                #new = SpectralCube(data=sc_K_kms.hdu.data,wcs = WCS(sc_K_kms.header),header=sc_K_kms.header)\n",
    "                SCL = SpectralCube(data=SCLN.hdu.data,wcs =WCS(SCLN.header),header=SCLN.header,mask=SCLN.mask)\n",
    "                SCL.allow_huge_operations=True\n",
    "                SCL = SCL*SCLN[0][0][0].unit\n",
    "                del SCLN\n",
    "                SCFRN = SCFR.reproject(reheader, order='bilinear', use_memmap=True, filled=True)\n",
    "                del SCFR\n",
    "                #new = SpectralCube(data=sc_K_kms.hdu.data,wcs = WCS(sc_K_kms.header),header=sc_K_kms.header)\n",
    "                SCFR = SpectralCube(data=SCFRN.hdu.data,wcs =WCS(SCFRN.header),header=SCFRN.header,mask=SCFRN.mask)\n",
    "                SCFR.allow_huge_operations=True\n",
    "                SCFR = SCFR*SCFRN[0][0][0].unit\n",
    "                del SCFRN\n",
    "                SCFLN = SCFL.reproject(reheader, order='bilinear', use_memmap=True, filled=True)\n",
    "                del SCFL\n",
    "                #new = SpectralCube(data=sc_K_kms.hdu.data,wcs = WCS(sc_K_kms.header),header=sc_K_kms.header)\n",
    "                SCFL = SpectralCube(data=SCFLN.hdu.data,wcs =WCS(SCFLN.header),header=SCFLN.header,mask=SCFLN.mask)\n",
    "                SCFL.allow_huge_operations=True\n",
    "                SCFL = SCFL*SCFLN[0][0][0].unit\n",
    "                del SCFLN\n",
    "            \n",
    "            \n",
    "            \n",
    "            #Get right shape\n",
    "            \n",
    "            datn = SCR.hdu.data\n",
    "            sx0,ex0,sy0,ey0=Crop_Nans(datn)\n",
    "            \n",
    "            SCR = SCR[:,sx0:ex0,:]\n",
    "            \n",
    "            SCR_Hdu=SCR.hdu\n",
    "            zeros=((SCR_Hdu.data[:,:,:]==0))\n",
    "            bp = np.where(zeros)\n",
    "            SCR_Hdu.data[bp]=np.nan\n",
    "            \n",
    "            for lmi in range(len(datn)):\n",
    "                SCR_Hdu.data[lmi,:,sy0-3:sy0+3]=np.nan\n",
    "                SCR_Hdu.data[lmi,:,ey0-3:ey0+3]=np.nan\n",
    "                #SCR_Hdu.data[lmi,:,ey:ey]=np.nan\n",
    "            datn=SCR_Hdu.data\n",
    "            sx,ex,sy,ey=Crop_Nans(datn)\n",
    "            \n",
    "            SCR = SpectralCube.read(SCR_Hdu)\n",
    "            \n",
    "            datn = SCL.hdu.data\n",
    "            sx2,ex2,sy2,ey2=Crop_Nans(datn)\n",
    "            \n",
    "            \n",
    "            \n",
    "            SCL=SCL[:,sx0:ex0,:]\n",
    "            \n",
    "            SCL_Hdu=SCL.hdu\n",
    "            zeros=((SCL_Hdu.data[:,:,:]==0))\n",
    "            bp = np.where(zeros)\n",
    "            SCL_Hdu.data[bp]=np.nan\n",
    "            \n",
    "            for lmi in range(len(datn)):\n",
    "                #SCL_Hdu.data[lmi,:,sy-5:sy+5]=np.nan\n",
    "                \n",
    "                #SCL_Hdu.data[lmi,:,sy2-3:sy2+3]=np.nan\n",
    "                SCL_Hdu.data[lmi,:,ey2-3:ey2+3]=np.nan\n",
    "                \n",
    "                SCL_Hdu.data[lmi,:,ey2:ey]=np.nan\n",
    "                \n",
    "            SCL = SpectralCube.read(SCL_Hdu)\n",
    "            \n",
    "            \n",
    "            datn = SCFR.hdu.data\n",
    "            sx3,ex3,sy3,ey3=Crop_Nans(datn)\n",
    "            \n",
    "            \n",
    "            \n",
    "            SCFR=SCFR[:,sx0:ex0,:]\n",
    "            \n",
    "            SCFR_Hdu=SCFR.hdu\n",
    "            zeros=((SCFR_Hdu.data[:,:,:]==0))\n",
    "            bp = np.where(zeros)\n",
    "            SCFR_Hdu.data[bp]=np.nan\n",
    "            \n",
    "            \n",
    "            for lmi in range(len(datn)):\n",
    "                \n",
    "                SCFR_Hdu.data[lmi,:,sy3-3:sy3+3]=np.nan\n",
    "                SCFR_Hdu.data[lmi,:,ey3-3:ey3+3]=np.nan\n",
    "                \n",
    "                \n",
    "                SCFR_Hdu.data[lmi,:,sy:sy3]=np.nan\n",
    "                #SCFR_Hdu.data[lmi,:,ey-5:ey+5]=np.nan#Takes care of the cube edges\n",
    "                \n",
    "                \n",
    "            SCFR = SpectralCube.read(SCFR_Hdu)\n",
    "                        \n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            datn = SCFL.hdu.data\n",
    "            sx4,ex4,sy4,ey4=Crop_Nans(datn)\n",
    "            \n",
    "            \n",
    "            \n",
    "            SCFL=SCFL[:,sx0:ex0,:]\n",
    "            \n",
    "            SCFL_Hdu=SCFL.hdu\n",
    "            zeros=((SCFL_Hdu.data[:,:,:]==0))\n",
    "            bp = np.where(zeros)\n",
    "            SCFL_Hdu.data[bp]=np.nan\n",
    "            \n",
    "            \n",
    "            for lmi in range(len(datn)):\n",
    "                pass\n",
    "                #SCFL_Hdu.data[lmi,:,sy4-3:sy4+3]=np.nan\n",
    "                #SCFL_Hdu.data[lmi,:,ey4-3:ey4+3]=np.nan\n",
    "                \n",
    "                \n",
    "                #SCFL_Hdu.data[lmi,:,sy2:sy4]=np.nan\n",
    "                #SCFR_Hdu.data[lmi,:,ey-5:ey+5]=np.nan#Takes care of the cube edges\n",
    "                \n",
    "                \n",
    "            SCFL = SpectralCube.read(SCFL_Hdu)\n",
    "            #SCR.write(\"test4.fits\",overwrite=True)\n",
    "            #SCL.write(\"test5.fits\",overwrite=True)\n",
    "            #SCFR.write(\"test6.fits\",overwrite=True)\n",
    "\n",
    "\n",
    "            RD = SCR.hdu.data\n",
    "            LD=SCL.hdu.data\n",
    "            FRD = SCFR.hdu.data\n",
    "            FLD = SCFL.hdu.data\n",
    "            print(np.shape(RD),len(RD))\n",
    "            print(np.shape(LD))\n",
    "            print(np.shape(FRD))\n",
    "            print(np.shape(FLD))\n",
    "            C = np.copy(LD)\n",
    "            wcs = SCR.wcs\n",
    "            header=SCR.hdu.header\n",
    "            hdu=SCR.hdu\n",
    "            world=SCR.world\n",
    "\n",
    "\n",
    "            for lmi in range(len(RD)):\n",
    "                for lmj in range(len(RD[lmi])):\n",
    "                    for lmk in range(len(RD[lmi][lmj])):\n",
    "                        if((RD[lmi][lmj][lmk]> 0 or RD[lmi][lmj][lmk]< 0) and (LD[lmi][lmj][lmk]> 0 or LD[lmi][lmj][lmk]< 0)):\n",
    "                            C[lmi][lmj][lmk] = np.nanmean([RD[lmi][lmj][lmk],LD[lmi][lmj][lmk]])\n",
    "                        elif((RD[lmi][lmj][lmk]> 0 or RD[lmi][lmj][lmk]< 0) and (FRD[lmi][lmj][lmk]> 0 or FRD[lmi][lmj][lmk]< 0)):\n",
    "                            C[lmi][lmj][lmk] = np.nanmean([RD[lmi][lmj][lmk],FRD[lmi][lmj][lmk]])\n",
    "                        elif((LD[lmi][lmj][lmk]> 0 or LD[lmi][lmj][lmk]< 0) and (FLD[lmi][lmj][lmk]> 0 or FLD[lmi][lmj][lmk]< 0)):\n",
    "                            C[lmi][lmj][lmk] = np.nanmean([LD[lmi][lmj][lmk],FLD[lmi][lmj][lmk]])\n",
    "                        elif(RD[lmi][lmj][lmk]>0 or RD[lmi][lmj][lmk]<0):\n",
    "                            C[lmi][lmj][lmk] =RD[lmi][lmj][lmk]\n",
    "                        elif(FRD[lmi][lmj][lmk]>0 or FRD[lmi][lmj][lmk]<0):\n",
    "                            C[lmi][lmj][lmk] =FRD[lmi][lmj][lmk]\n",
    "                            #print(\"Ye\",lmi,lmj,lmk)\n",
    "                        elif(LD[lmi][lmj][lmk]>0 or LD[lmi][lmj][lmk]<0):\n",
    "                            C[lmi][lmj][lmk] =LD[lmi][lmj][lmk]\n",
    "                        elif(FLD[lmi][lmj][lmk]>0 or FLD[lmi][lmj][lmk]<0):\n",
    "                            C[lmi][lmj][lmk] =FLD[lmi][lmj][lmk]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                print(np.nanmean(C[lmi]))\n",
    "                print(lmi)\n",
    "\n",
    "\n",
    "            Comb = SpectralCube(data=C, wcs=wcs,header=header)\n",
    "            Comb.allow_huge_operations=True\n",
    "            Comb = Comb*SCL[0][0][0].unit\n",
    "\n",
    "\n",
    "\n",
    "            Comb.write(Cube_Name_Save,overwrite=True)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6676a29d-4c1e-4e4e-be55-bf8ccee124e0",
   "metadata": {},
   "source": [
    "# 6.2 NAN fixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cebb3410-e607-4f13-9096-488a04891c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0 pc\n",
      "1 1174 1 1362\n",
      "5 5 ready\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#Fix the Nans\n",
    "\n",
    "#Splice CO\n",
    "gal=\"GC\"\n",
    "Min_res=4.3*u.pc#Smallest resolution\n",
    "\n",
    "\n",
    "iterations = 6\n",
    "Line_Name = '_CMZ_CO_J3_2_4.3_start'\n",
    "\n",
    "ovs = 3 #over sample factor for beam\n",
    "min_vel = 3.3#km/s\n",
    "iter_factor = 1/5\n",
    "\n",
    "\n",
    "FOV = [70,360]#pc\n",
    "Min_res=4.3*u.pc#Smallest resolution\n",
    "\n",
    "\n",
    "Smoothe_4 = False\n",
    "Match_to_HCO = False\n",
    "if(Smoothe_4):\n",
    "    Smoothe_title=\"G_width_4\"\n",
    "else:\n",
    "    Smoothe_title=''\n",
    "    if(Match_to_HCO):\n",
    "        Smoothe_title='Smoothe_to_3.3'\n",
    "Smoothe_2_5 =True\n",
    "if(Smoothe_2_5):\n",
    "    Smoothe_title=\"Smoothe_to_2.5\"\n",
    "    \n",
    "if(Line_Name == '_CMZ_CO_J3_2_4.3_start'):\n",
    "\n",
    "    for kl in range(5,6):\n",
    "      \n",
    "        Prime_Beam = Min_res*((kl*iter_factor+1))#\n",
    "        if(kl==5):\n",
    "            Prime_Beam = 3*u.pc#Nico\n",
    "            FOVp=[200,800]\n",
    "        else:\n",
    "            FOVp=FOV\n",
    "        print(Prime_Beam)\n",
    "    \n",
    "        for km in range(5,6):\n",
    "            vel_prime = min_vel*((km*iter_factor+1))\n",
    "            if(km==5):\n",
    "                vel_prime=2.5\n",
    "            \n",
    "            Cube_Name_Save = str(Prime_Beam.value)+\"pc_beam_\"+Line_Name+str(FOVp[0])+\"x\"+str(FOVp[1])+'pc_'+str(vel_prime)+'_vel_res_NEW'+Smoothe_title+'.fits'\n",
    "            Cube_Name_Load = str(Prime_Beam.value)+\"pc_beam_\"+Line_Name+str(FOVp[0])+\"x\"+str(FOVp[1])+'pc_'+str(vel_prime)+'_vel_res_NEW'+Smoothe_title+'.fits'\n",
    "            \n",
    "            Cube_Name_Save=str(\"Cropped_\"+Cube_Name_Load)\n",
    "            print(Cube_Name_Load)\n",
    "            sc = SpectralCube.read(Cube_Name_Load)\n",
    "            sc.write(\"test7.fits\",overwrite=True)\n",
    "            datn = sc.hdu.data\n",
    "            \n",
    "            #Get right shape\n",
    "            sx,sy,ex,ey=0,0,0,0\n",
    "            for lmi in range(np.shape(datn[0,:,:])[0]):\n",
    "\n",
    "                if(ey!=0 and sx!=0 and ex!=0 and sy!=0):\n",
    "                    print(\"F\",lmi)\n",
    "                    break\n",
    "                for lmj in range(np.shape(datn[0,:,:])[1]):\n",
    "\n",
    "                    if(sx==0):            \n",
    "                        if(np.nanmean(datn[0,lmi,:])>0 or np.nanmean(datn[0,lmi,:])<0):\n",
    "                            sx=lmi\n",
    "\n",
    "\n",
    "                    if(sy==0):\n",
    "                        if(np.nanmean(datn[0,:,lmj])>0 or np.nanmean(datn[0,:,lmj])<0):\n",
    "                            sy=lmj\n",
    "\n",
    "                    if(ex==0):\n",
    "                        if(np.nanmean(datn[0,np.shape(datn[0,:,:])[0]-lmi-1,:])>0 or np.nanmean(datn[0,np.shape(datn[0,:,:])[0]-lmi-1,:])<0):\n",
    "                            ex=np.shape(datn[0,:,:])[0]-lmi-1\n",
    "\n",
    "                    if(ey==0):\n",
    "                        if(np.nanmean(datn[0,:,np.shape(datn[0,:,:])[1]-lmj-1])>0 or np.nanmean(datn[0,:,np.shape(datn[0,:,:])[1]-lmj-1])<0):\n",
    "                            ey=np.shape(datn[0,:,:])[1]-lmj-1\n",
    "\n",
    "                    if(ey!=0 and ex!=0 and sx!=0 and sy!=0):\n",
    "                        break\n",
    "            print(sx,ex,sy,ey)\n",
    "            \n",
    "            \n",
    "            sc = sc[:,sx:ex,sy:ey]\n",
    "            \n",
    "            sc_Hdu=sc.hdu\n",
    "            zeros=((sc_Hdu.data[:,:,:]==0))\n",
    "            bp = np.where(zeros)\n",
    "            sc_Hdu.data[bp]=np.nan\n",
    "            sc = SpectralCube.read(sc_Hdu)\n",
    "            sc.write(\"test8.fits\",overwrite=True)\n",
    "            \n",
    "            #Crop vel axis if needed\n",
    "            \n",
    "            sp=0\n",
    "            for lmi in range(len(sc)):\n",
    "                #Check to see if the slice has been repeated by the interpolation function\n",
    "                if(np.round(np.nanmean(sc[lmi].hdu.data),5)==np.round(np.nanmean(sc[lmi+1].hdu.data),5)):\n",
    "\n",
    "                    sp = lmi+1\n",
    "                else:\n",
    "                    print(\"A\")\n",
    "                    print(lmi,np.nanmean(sc[lmi].hdu.data),np.nanmean(sc[lmi+1].hdu.data))\n",
    "                    break\n",
    "            l = len(sc)-1\n",
    "            ep=l\n",
    "            for lmi in range(l):\n",
    "\n",
    "                if(np.round(np.nanmean(sc[l-lmi].hdu.data),5)==np.round(np.nanmean(sc[l-lmi-1].hdu.data),5)):\n",
    "                    ep = l-lmi-1\n",
    "\n",
    "                else:\n",
    "                    print(\"B\",lmi)\n",
    "                    break\n",
    "\n",
    "            print(sp,ep)#These are the start and stop slices where the actual unique data resides\n",
    "\n",
    "            sc.allow_huge_operations=True\n",
    "            sc = sc[sp:ep]\n",
    "\n",
    "            \n",
    "            sc.write(Cube_Name_Save,overwrite=True)\n",
    "            del sc\n",
    "            del sc_Hdu\n",
    "            gc.collect()\n",
    "            print(kl,km,'ready')\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa77b571-c985-4310-84cd-45065446bb09",
   "metadata": {},
   "source": [
    "# 6.3 Noise matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce45a15d-f510-4c58-be8e-b33353f31e29",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 982, 1279)\n",
      "0.305 Noise (K) matched to  0.115\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2104\\2734619688.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0mQp_Noisy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSpectralCube\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCube_Name_Load_Noisy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_spectral_unit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkm\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvelocity_convention\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"radio\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[0mNoise_matching\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mInput_Cube_Match\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mQp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mInput_Cube_Noisy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mQp_Noisy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mCube_Name_Save\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mCube_Name_Save\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mForce_region\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mFVX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mFVY\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mForce_Noise\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mFNV1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.305\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mFNV2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.115\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2104\\676554372.py\u001b[0m in \u001b[0;36mNoise_matching\u001b[1;34m(Input_Cube_Match, Input_Cube_Noisy, Cube_Name_Save, Force_region, FVX, FVY, Force_Noise, FNV1, FNV2)\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0mnew_seed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1e9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m         \u001b[0madditional_noise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgauss_correlated_noise_2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhdu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhdu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0madditional_sigma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeam_gauss_width\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mfwhm_factor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandomseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnew_seed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m         \u001b[0mpp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madditional_noise\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda new\\lib\\site-packages\\spectral_cube\\spectral_cube.py\u001b[0m in \u001b[0;36mhdu\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2530\u001b[0m         \u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Creating HDU\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2531\u001b[1;33m         \u001b[0mhdu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPrimaryHDU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munitless_filled_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2532\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhdu\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda new\\lib\\site-packages\\spectral_cube\\cube_utils.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, view)\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mview\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_other\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mview\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda new\\lib\\site-packages\\spectral_cube\\base_class.py\u001b[0m in \u001b[0;36munitless_filled_data\u001b[1;34m(self, view)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \"\"\"\n\u001b[1;32m--> 441\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_filled_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fill_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda new\\lib\\site-packages\\spectral_cube\\base_class.py\u001b[0m in \u001b[0;36m_get_filled_data\u001b[1;34m(self, view, fill, check_endian, use_memmap)\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m         return self._mask._filled(data=data, wcs=self._wcs, fill=fill,\n\u001b[0m\u001b[0;32m    406\u001b[0m                                   \u001b[0mview\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwcs_tolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wcs_tolerance\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda new\\lib\\site-packages\\spectral_cube\\masks.py\u001b[0m in \u001b[0;36m_filled\u001b[1;34m(self, data, wcs, fill, view, use_memmap, **kwargs)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmasked_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msliced_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfill\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda new\\lib\\site-packages\\numpy\\ma\\core.py\u001b[0m in \u001b[0;36mfilled\u001b[1;34m(self, fill_value)\u001b[0m\n\u001b[0;32m   3838\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3839\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'K'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3840\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#match noise\n",
    "\n",
    "\n",
    "\n",
    "iterations = 6\n",
    "iter_factor = 1/5\n",
    "\n",
    "ovs = 3 #over sample factor for beam\n",
    "min_vel = 3.3#km/s\n",
    "FOV = [70,360]#pc\n",
    "Min_res=4.3*u.pc#Smallest resolution\n",
    "Min_beam_req = 1/5\n",
    "\n",
    "Params = [iterations,iter_factor,ovs,min_vel,FOV,Min_res,Min_beam_req]\n",
    "savePath='/home/ben/Documents/Grad Stuff/MM data/Result Files'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Line_Name = '_CMZ_CO_J3_2_4.3_start'\n",
    "Line_Name_NGC = '_NGC_CO_J3_2_'\n",
    "\n",
    "\n",
    "\n",
    "Smoothe_4 = False\n",
    "Match_to_HCO = False\n",
    "if(Smoothe_4):\n",
    "    Smoothe_title=\"G_width_4\"\n",
    "else:\n",
    "    Smoothe_title=''\n",
    "    if(Match_to_HCO):\n",
    "        Smoothe_title='Smoothe_to_3.3'\n",
    "Smoothe_2_5 =True\n",
    "if(Smoothe_2_5):\n",
    "    Smoothe_title=\"Smoothe_to_2.5\"\n",
    "\n",
    "for kl in range(5,6):\n",
    "      \n",
    "    Prime_Beam = Min_res*((kl*iter_factor+1))#\n",
    "    if(kl==5):\n",
    "        Prime_Beam = 3*u.pc#Nico\n",
    "        FOVp=[200,800]\n",
    "            \n",
    "    print(Prime_Beam)\n",
    "\n",
    "    for km in range(5,6):\n",
    "        vel_prime = min_vel*((km*iter_factor+1))\n",
    "        if(km==5 and kl==5):\n",
    "            vel_prime=2.5\n",
    "            NGCCO32_Noise=.115\n",
    "\n",
    "        '''\n",
    "        #Make subcube\n",
    "\n",
    "        #Find noise for ngc253\n",
    "        Cube_Name_Load = \"Cropped_\"+str(Prime_Beam.value)+\"pc_beam_\"+Line_Name_NGC+str(FOVp[0])+\"x\"+str(FOVp[1])+'pc_'+str(vel_prime)+'_vel_res.fits'\n",
    "        path = Cube_Name_Load\n",
    "        \n",
    "        Qp = SpectralCube.read(path).with_spectral_unit(u.km/u.s,velocity_convention=\"radio\") \n",
    "        Qp.allow_huge_operations=True\n",
    "\n",
    "        Qp = Qp.to(u.K)#Jy to Kelvin\n",
    "\n",
    "        datn = Qp.hdu.data\n",
    "        del Qp\n",
    "\n",
    "\n",
    "        Non_nan=((datn[0,:,int(np.shape(datn)[2]/1.5):int(np.shape(datn)[2]-1)]>0)  | (datn[0,:,int(np.shape(datn)[2]/1.5):int(np.shape(datn)[2]-1)]<0 ))\n",
    "        \n",
    "        if(kl==5 and km==5):\n",
    "            pass\n",
    "        else:\n",
    "            NGCCO32_Noise = (np.nanstd(datn[0,:,int(np.shape(datn)[2]/1.5):int(np.shape(datn)[2]-1)],where= Non_nan)) #Noise K\n",
    "        print(np.shape(datn))\n",
    "        del datn\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        \n",
    "        \n",
    "        Cube_Name_Load = \"Cropped_\"+str(Prime_Beam.value)+\"pc_beam_\"+Line_Name+str(FOVp[0])+\"x\"+str(FOVp[1])+'pc_'+str(vel_prime)+'_vel_res_NEW'+Smoothe_title+'.fits'\n",
    "        print(Cube_Name_Load)\n",
    "        Cube_Name_Save = \"Noise_Matched_\"+\"Cropped_\"+str(Prime_Beam.value)+\"pc_beam_\"+Line_Name+str(FOVp[0])+\"x\"+str(FOVp[1])+'pc_'+str(vel_prime)+'_vel_res_NEW'+Smoothe_title+'.fits'\n",
    "        path = Cube_Name_Load\n",
    "        \n",
    "        #Qp = SpectralCube.read(path).with_spectral_unit(u.km/u.s,velocity_convention=\"radio\") \n",
    "        Qp = SpectralCube.read(path).with_spectral_unit(u.km/u.s,velocity_convention=\"optical\") \n",
    "        \n",
    "        Qp.allow_huge_operations=True\n",
    "        Q = Qp.to(u.K)#Jy to Kelvin\n",
    "        del Qp\n",
    "        datn=Q.hdu.data\n",
    "        Non_nan=((datn[0,:,0:int(np.shape(datn)[2]/2)]>0)  | (datn[0,:,0:int(np.shape(datn)[2]/2)]<0 ))\n",
    "        print(np.shape(datn))\n",
    "        m = (np.nanstd(datn[0,:,0:int(np.shape(datn)[2]/2)],where= Non_nan)) #Noise K\n",
    "        \n",
    "        m=.037\n",
    "\n",
    "        print(m,\"Noise (K) matched to \",NGCCO32_Noise)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        npixels = np.product(Q.hdu.data.shape)\n",
    "\n",
    "        target_noise = float(NGCCO32_Noise)\n",
    "        actual_noise = m\n",
    "        additional_sigma = np.sqrt(target_noise**2 - actual_noise**2)\n",
    "\n",
    "        additional_noise = np.random.normal(0., additional_sigma, npixels)\n",
    "        additional_noise = np.reshape(additional_noise, Q.hdu.data.shape)\n",
    "        \n",
    "        \n",
    "        fwhm_factor = np.sqrt(8*np.log(2))\n",
    "        add_noise = np.zeros(np.shape(datn))\n",
    "        for lmi in range(len(datn)):\n",
    "            new_seed = np.random.randint(1e9)\n",
    "            additional_noise = gauss_correlated_noise_2D(shape=(Q.hdu.data[6].shape[0],Q.hdu.data[6].shape[1]), sigma=additional_sigma, beam_gauss_width=5/fwhm_factor,randomseed=new_seed)\n",
    "            pp=np.where(additional_noise!=np.nan)\n",
    "            add_noise[lmi][pp]=additional_noise[pp]\n",
    "            print(lmi)\n",
    "        \n",
    "        new_data = datn+add_noise\n",
    "        QCopy = Q.hdu\n",
    "        QCopy.data = new_data\n",
    "        Q = SpectralCube.read(QCopy)\n",
    "        del QCopy\n",
    "\n",
    "        \n",
    "        Q.write(Cube_Name_Save,overwrite=True)\n",
    "        del Q\n",
    "        print(kl,km)\n",
    "print(\"Doen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fa9391-1bee-41f6-bf20-05ec2087087b",
   "metadata": {},
   "source": [
    "# Part 8: Dendograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "006fb76f-9c00-4bc3-844c-932b383a6723",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#CO 3-2 all resses starting at 4.3\n",
    "\n",
    "\n",
    "Num=5\n",
    "Overlaps=0#4\n",
    "Ram_Limiter=1#What percent of the cube my ram can handle\n",
    "LineN=\"CMZ_CO_J3_2_all_NEW\"\n",
    "Name = \"CMZ_CO_J3_2_all_NEW\"\n",
    "name = \"CMZ_CO_J3_2_CM_Contours_all_NEW.jpeg\"\n",
    "\n",
    "Abs_Levels = [\"All\",\"None\",\"No Clusters\", \"None (m)\", \"None All Channels\"]\n",
    "\n",
    "\n",
    "\n",
    "iterations = 6\n",
    "iter_factor = 1/5\n",
    "#Line_Name = '_CMZ_CO_J3_2_4.3_start'\n",
    "\n",
    "NM= True\n",
    "\n",
    "Smoothe_4 = False\n",
    "Match_to_HCO = False\n",
    "if(Smoothe_4):\n",
    "    Smoothe_title=\"G_width_4\"\n",
    "else:\n",
    "    Smoothe_title=''\n",
    "    if(Match_to_HCO):\n",
    "        Smoothe_title='Smoothe_to_3.3'\n",
    "Smoothe_2_5 =True\n",
    "if(Smoothe_2_5):\n",
    "    Smoothe_title=\"Smoothe_to_2.5\"\n",
    "\n",
    "Edge_cases=True\n",
    "\n",
    "if(Edge_cases):\n",
    "    Edge_title=\"Edges\"\n",
    "else:\n",
    "    Edge_title=''\n",
    "    \n",
    "Line_Name = '_CMZ_CO_J3_2_4.3_start'\n",
    "\n",
    "if(NM):\n",
    "    Line_Name_Save = Line_Name+'_NM'+Smoothe_title+Edge_title\n",
    "else:\n",
    "    Line_Name_Save=Line_Name+Smoothe_title+Edge_title\n",
    "\n",
    "\n",
    "\n",
    "ovs = 3 #over sample factor for beam\n",
    "min_vel = 3.3#km/s\n",
    "FOV = [70,360]#pc\n",
    "Min_res=4.3*u.pc#Smallest resolution\n",
    "Min_beam_req = 1/5\n",
    "\n",
    "Params = [iterations,iter_factor,ovs,min_vel,FOV,Min_res,Min_beam_req]\n",
    "savePath='/home/ben/Documents/Grad Stuff/MM data/Result Files'\n",
    "if(NM):\n",
    "    #Name_File = \"CMZ_Names_New_All_Kinds_NM_Fixed\"\n",
    "    Name_File = \"CMZ_Names_New_All_Kinds_NM\"+Smoothe_title+Edge_title\n",
    "else:\n",
    "    #Name_File= \"CMZ_Names_New_All_Kind_Fixed\"\n",
    "    Name_File= \"CMZ_Names_New_All_Kinds\"+Smoothe_title+Edge_title\n",
    "\n",
    "np.savetxt(Line_Name+\"_Params\", Params,fmt='%s')#[iterations,iter_factor ,Line_Name,Name,ovs,min_vel,FOV,Min_res,Min_beam_req]\n",
    "\n",
    "\n",
    "cen_p1 = SkyCoord('-00d03m20.76s  ', '-00d02m46.176s', frame='galactic')\n",
    "cen_p2 = SkyCoord('-00d03m20.76s  ', '-00d02m46.176s', frame='galactic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06fa3611-741a-4207-9976-ba5f4b72e3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "savePath='/home/ben/Documents/Grad Stuff/MM data/Result Files'\n",
    "\n",
    "savePath=\"/Users/b347m182/Documents/Grad Stuff/MM Data/Result Files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c55b231e-83f2-49ff-8231-ffb75bb597b3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0 pc\n",
      "[Errno 2] No such file or directory: 'NGC_Names_New_All_Kinds_NM.npy'\n",
      "initialized names\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Noise_Matched_Cropped_3.0pc_beam__NGC253_CO_J3_2_200x800pc_2.5_vel_res_NEW.fits'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9220\\1251709699.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCube_Name_Load\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m     \u001b[0mQp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSpectralCube\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_spectral_unit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkm\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvelocity_convention\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"radio\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m     \u001b[0mQp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mallow_huge_operations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda new\\lib\\site-packages\\spectral_cube\\io\\core.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, filename, *args, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'target_cls'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBaseSpectralCube\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mregistry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseSpectralCube\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mIsADirectoryError\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# See note above StringWrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mregistry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseSpectralCube\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mStringWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda new\\lib\\site-packages\\astropy\\io\\registry\\compat.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(registry, *args, **kwargs)\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mregistry\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefault_registry\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;31m# get and call bound method from registry instance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregistry\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda new\\lib\\site-packages\\astropy\\io\\registry\\core.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, cls, format, cache, *args, **kwargs)\u001b[0m\n\u001b[0;32m    195\u001b[0m                         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m                             \u001b[0mctx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_readable_fileobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m                             \u001b[0mfileobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__enter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    198\u001b[0m                         \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m                             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda new\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"generator didn't yield\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda new\\lib\\site-packages\\astropy\\utils\\data.py\u001b[0m in \u001b[0;36mget_readable_fileobj\u001b[1;34m(name_or_obj, encoding, cache, show_progress, remote_timeout, sources, http_headers)\u001b[0m\n\u001b[0;32m    269\u001b[0m                 \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mremote_timeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msources\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msources\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m                 http_headers=http_headers)\n\u001b[1;32m--> 271\u001b[1;33m         \u001b[0mfileobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFileIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_url\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m             \u001b[0mdelete_fds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Noise_Matched_Cropped_3.0pc_beam__NGC253_CO_J3_2_200x800pc_2.5_vel_res_NEW.fits'"
     ]
    }
   ],
   "source": [
    "#Krieger\n",
    "\n",
    "#Beam\n",
    "Abs_Level = Abs_Levels[0]\n",
    "\n",
    "\n",
    "\n",
    "if gal ==\"GC\":\n",
    "    pathCont = '4.3pc_beam_CMZ_850um_Cont_140x800pc.fits'#'CMZ_Continuum_Splice.fits'\n",
    "else:\n",
    "    pathCont = 'Continuum_Reproject.fits'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "start_num=0\n",
    "km=0\n",
    "for kl in range(5,6):\n",
    "      \n",
    "    Prime_Beam = Min_res*((kl*iter_factor+1))#\n",
    "    max_size = Prime_Beam*7   \n",
    "    if(kl==5):\n",
    "        Prime_Beam = 3*u.pc#Nico\n",
    "        km=5\n",
    "        FOVp=[200,800]\n",
    "        max_size = 20#pc\n",
    "    else:\n",
    "        FOVp=FOV\n",
    "    print(Prime_Beam)\n",
    "    \n",
    "    \n",
    "    vel_prime = min_vel*((km*iter_factor+1))\n",
    "\n",
    "    if(km==5):\n",
    "        vel_prime=2.5\n",
    "    if(kl==5,km==5):\n",
    "        Trunks=True\n",
    "    else:\n",
    "        Trunks=True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    try:\n",
    "        Names=list(np.load(Name_File+\".npy\",allow_pickle=True))\n",
    "        if(iterations!=np.shape(Names)[3]):\n",
    "            del popasasd\n",
    "    except Exception as e:\n",
    "\n",
    "        print(e)\n",
    "        print(\"initialized names\")\n",
    "        Names = list(np.empty((20,iterations,iterations,iterations,iterations,iterations,iterations),dtype=object))\n",
    "\n",
    "\n",
    "    #Continuum image\n",
    "    scCont = spectral_cube.Projection.from_hdu(fits.open(pathCont)[0])\n",
    "    #Put this up here for the column density map\n",
    "    metadata = {}\n",
    "    metadata[\"distance\"] = dist_cmz\n",
    "    arc_per_pix_yc =  abs(scCont.hdu.header[\"CDELT1\"]*3600.0 * u.arcsec)/u.pix\n",
    "    arc_per_pix_xc =  abs(scCont.hdu.header[\"CDELT2\"]*3600.0 * u.arcsec)/u.pix\n",
    "    beam_majorc =  scCont.hdu.header[\"BMAJ\"]*3600.0 * u.arcsec\n",
    "    beam_minorc =  scCont.hdu.header[\"BMIN\"]*3600.0 * u.arcsec\n",
    "    beam_area_ratioc = beam_minorc*beam_majorc/arc_per_pix_yc/arc_per_pix_xc*1.13309#beam_area_ratioc = beam_minorc*beam_majorc/arc_per_pix_yc/arc_per_pix_xc#This is for FWHM, use *(2*np.sqrt(2*np.log(2)))**2#For gaussian beam\n",
    "    metadata['beam_area_ratioc']=beam_area_ratioc\n",
    "    pc_per_pixelc = abs(scCont.hdu.header[\"CDELT1\"])/180*np.pi*metadata['distance']/u.Mpc\n",
    "    print(pc_per_pixelc,\"MPC per pix\")\n",
    "\n",
    "    #Make subcube\n",
    "\n",
    "\n",
    "    if(NM):\n",
    "        Cube_Name_Load = 'Noise_Matched_'+\"Cropped_\"+str(Prime_Beam.value)+\"pc_beam_\"+Line_Name+str(FOVp[0])+\"x\"+str(FOVp[1])+'pc_'+str(vel_prime)+'_vel_res_NEW'+Smoothe_title+'.fits'\n",
    "    else:\n",
    "        Cube_Name_Load = \"Cropped_\"+str(Prime_Beam.value)+\"pc_beam_\"+Line_Name+str(FOVp[0])+\"x\"+str(FOVp[1])+'pc_'+str(vel_prime)+'_vel_res_NEW'+Smoothe_title+'.fits'\n",
    "    path = Cube_Name_Load\n",
    "\n",
    "    Qp = SpectralCube.read(path).with_spectral_unit(u.km/u.s,velocity_convention=\"radio\") \n",
    "    Qp.allow_huge_operations=True\n",
    "\n",
    "    Q = Qp.to(u.K)#Jy to Kelvin\n",
    "\n",
    "    sc = Q.unmasked_copy()\n",
    "\n",
    "\n",
    "\n",
    "    scW = sc.wcs[:][:][0]\n",
    "    dat = sc.hdu.data[int(len(sc)*((1-Ram_Limiter)/2)):int(len(sc)*(Ram_Limiter + (1-Ram_Limiter)/2)),:,:]\n",
    "    scn = sc[int(len(sc)*((1-Ram_Limiter)/2)):int(len(sc)*(Ram_Limiter + (1-Ram_Limiter)/2)),:,:]\n",
    "    scF = scn\n",
    "    datn = dat\n",
    "\n",
    "\n",
    "    #m=.115\n",
    "\n",
    "    #print(m,\"Presumed Noise (K)\")\n",
    "\n",
    "    #Continuum image\n",
    "    scCont = spectral_cube.Projection.from_hdu(fits.open(pathCont)[0])\n",
    "    #Do the same thing to the continuum image\n",
    "    scCont.allow_huge_operations=True\n",
    "    scContW = scCont.reproject(scF.moment0().header)\n",
    "    #m=.115\n",
    "\n",
    "\n",
    "    scW = sc.wcs[:][:][0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Do the same thing to the continuum image\n",
    "\n",
    "    Continuum_Data  =scContW.hdu.data\n",
    "    scWCS = scF.wcs[:][:][0]\n",
    "\n",
    "    moment_0_sub  = scF.to(u.K).moment(order=0,how='slice')            # Calculate the Moment 0 map \n",
    "\n",
    "\n",
    "\n",
    "    ######Moment 0 for both\n",
    "    ######and cont\n",
    "    Make_Plot((LineN+\" Moment 0\"),\"Moment 0 (K km/s)\",moment_0_sub.hdu.data,0,np.nanmax(moment_0_sub.hdu.data),moment_0_sub.wcs,1,1,1,True)\n",
    "\n",
    "\n",
    "    cSD = (Flux_to_Mass(scContW.hdu.data*u.Jy/u.beam/beam_area_ratioc*u.pix**2*u.beam)/(pc_per_pixelc*10**6*3.086*10**18*u.cm)**2)*(1.989*10**30*u.kg/u.M_sun)*Num_per_kg/u.kg #Flux goes to luminosity for a gaussian beam and goes to column density for square pixels, mass goes to kg to number\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    rm=moment_0_sub.hdu.data/cSD\n",
    "    rmU = rm*u.K*u.km/u.s#Just put back in the units\n",
    "    rmU = np.array(rmU /(u.K*u.km/u.s)/u.cm**2*10**22,dtype='float64')#Now remove them all\n",
    "    print(rmU)\n",
    "\n",
    "    ######ratio\n",
    "\n",
    "    bp = np.where(cSD<=.0001*10**22/u.cm**2)\n",
    "    bp2 = np.where( moment_0_sub.hdu.data < .00022)\n",
    "    Continuum_Data[bp] = np.nan\n",
    "    cSD[bp]=np.nan\n",
    "    rmU[bp]=np.nan\n",
    "    rmU[bp2]=np.nan\n",
    "\n",
    "    Non_nan=((datn[0,:,0:int(np.shape(datn)[2]/2)]>0)  | (datn[0,:,0:int(np.shape(datn)[2]/2)]<0 ))\n",
    "\n",
    "    m = (np.nanstd(datn[0,:,0:int(np.shape(datn)[2]/2)],where= Non_nan)) #Noise K\n",
    "    mp=m\n",
    "    if(Abs_Level==\"All\"):\n",
    "        pass\n",
    "    if(Abs_Level==\"None\"):\n",
    "        datn[np.where(datn<0)]=np.nan\n",
    "    if(Abs_Level==\"None (m)\"):\n",
    "        datn[np.where(datn<-m)]=np.nan\n",
    "    if(Abs_Level==\"None All Channels\"):\n",
    "        for lmi in range(len(datn)):\n",
    "            bpP = np.where(datn[lmi]<-m)\n",
    "            for lmj in range(len(datn)):\n",
    "                datn[lmj][bpP]=np.nan\n",
    "    if(Abs_Level==\"No Clusters\"):\n",
    "\n",
    "        #IDs,RAs,Decs,HWHM  =    np.genfromtxt(\"NGC_Clusters_\"+\"IDs\"+\"\",dtype=type(\"12h23.14s\")),np.genfromtxt(\"NGC_Clusters_\"+\"RAs\"+\"\",dtype=type(\"12h23.14s\")),np.genfromtxt(\"NGC_Clusters_\"+\"Decs\"+\"\",dtype=type(\"12h23.14s\")),np.genfromtxt(\"NGC_Clusters_\"+\"HWHM\"+\"\")\n",
    "\n",
    "        HWHM_rad,CDs_New,glons_New,glats_New,IDs_New   =    np.genfromtxt(\"CMZ_Clusters_\"+\"HWHM\"+\"\"),np.genfromtxt(\"CMZ_Clusters_\"+\"CD\"+\"\"),np.genfromtxt(\"CMZ_Clusters_\"+\"Glon\"+\"\"),np.genfromtxt(\"CMZ_Clusters_\"+\"Glat\"+\"\"),np.genfromtxt(\"CMZ_Clusters_\"+\"IDs\"+\"\")\n",
    "\n",
    "        datn=  Mask_Clusters_CMZ(HWHM_rad,scWCS,scF.hdu.header,datn,glons_New,glats_New,One_Pc=False,One_Pc_Size=1,HWHM_Fac=3)\n",
    "\n",
    "    print(m,\"Unmatched Noise (K)\", \"Abs = \",Abs_Level)\n",
    "\n",
    "\n",
    "    Make_Plot(\"Column Density\",\"(#/cm^2)\",cSD,float(np.nanmin(cSD*u.cm**2)),float(np.nanmax(cSD*u.cm**2)),scCont.wcs,1,1,1,True)\n",
    "    Make_Plot((LineN+\" Moment 0/Column Density\"),\"Moment 0 over Column Density of the Continuum (K km/s/(#/cm^2))\",rmU,np.nanmean(rmU)*.5,abs(np.nanmean(rmU))*8,scCont.wcs,1,1,1,True)\n",
    "\n",
    "    print(np.nanmin(rmU))\n",
    "\n",
    "\n",
    "\n",
    "    header = scF.hdu.header\n",
    "    print()\n",
    "    #make metadata for the dendrogram\n",
    "\n",
    "    try:\n",
    "        freq = header[\"RESTFREQ\"]*u.Hz#\n",
    "        metadata['wavelength']=299792458*u.m/header[\"RESTFREQ\"]#\n",
    "        print(1,freq,metadata['wavelength'])\n",
    "    except:\n",
    "        freq = header[\"RESTFRQ\"]*u.Hz#\n",
    "        metadata['wavelength']=299792458*u.m/header[\"RESTFRQ\"]#\n",
    "    metadata['data_unit'] =scF[0][0][0].unit# header['BUNIT']\n",
    "    metadata['arc_per_pix_y'] =  abs(header[\"CDELT1\"]*3600.0 * u.arcsec)/u.pix\n",
    "    metadata['arc_per_pix_x'] =  abs(header[\"CDELT2\"]*3600.0 * u.arcsec)/u.pix\n",
    "\n",
    "\n",
    "    metadata['beam_major'] =  header[\"BMAJ\"]*3600.0 * u.arcsec\n",
    "    metadata['beam_minor'] =  header[\"BMIN\"]*3600.0 * u.arcsec\n",
    "    beam_area_ratio = metadata['beam_minor']*metadata['beam_major']/metadata['arc_per_pix_y']/metadata['arc_per_pix_x']*1.13309#beam_area_ratio = metadata['beam_minor']*metadata['beam_major']/metadata['arc_per_pix_y']/metadata['arc_per_pix_x']#This is for FWHM, use *(2*np.sqrt(2*np.log(2)))**2#For gaussian beam\n",
    "    metadata['beam_area_ratio']=beam_area_ratio\n",
    "    metadata['spatial_scale'] = np.sqrt(abs(header[\"CDELT1\"])*u.degree**2*abs(header[\"CDELT2\"]))\n",
    "    #area_res = abs(header[\"CDELT1\"])*abs(header[\"CDELT2\"])*(np.pi/180*3.5)**2#mpc^2/pix^2\n",
    "    #print(area_res,type(area_res))\n",
    "\n",
    "    print(metadata['beam_minor'],metadata['beam_major'])\n",
    "    print(beam_area_ratio)\n",
    "    #metadata[\"wcs\"] = wcs\n",
    "    metadata[\"velocity_scale\"] = abs(header[\"CDELT3\"])*u.km/u.s#u.km/u.s\n",
    "\n",
    "    metadata[\"vaxis\"]=0\n",
    "    metadata[\"wcsu\"]=scF.wcs\n",
    "\n",
    "\n",
    "    #for k3 in range(start_num):\n",
    "    k3=2\n",
    "\n",
    "\n",
    "    beam_req = Min_beam_req*(k3+1)\n",
    "    if kl==5:\n",
    "        beam_req=.9/3\n",
    "    k4=0\n",
    "    print(kl,km,k3,k4)\n",
    "    pix_thresh_factor = k4+1\n",
    "    k6=2\n",
    "    delt_factor = (3/5+k6/5)\n",
    "\n",
    "    k7=2\n",
    "    noise_factor = (3/5+k7/5)\n",
    "    if(kl==5):\n",
    "        m=.115\n",
    "    else:\n",
    "        m=mp\n",
    "    print(kl,km,k3,k4,k6,k7)\n",
    "    print(\"actiev noise = \",m)\n",
    "    try:\n",
    "\n",
    "\n",
    "\n",
    "        Cube_Name_Save = Name+\"_Cropped_\"+str(Prime_Beam.value)+\"pc_beam_\"+Line_Name_Save+str(FOVp[0])+\"x\"+str(FOVp[1])+'pc_'+str(vel_prime)+'_vel_res_'+str(beam_req)+\"_beam_size_req_\"+str(pix_thresh_factor)+'_times_beam_pixels_'+str(delt_factor)+\"_delt_factor_\"+str(noise_factor*5)+\"_SNR_NEW.fits\"\n",
    "\n",
    "\n",
    "\n",
    "        Names[Num][kl][km][k3][k4][k6][k7] = Cube_Name_Save\n",
    "\n",
    "        NameS = (Cube_Name_Save+\"Sigmas\")\n",
    "        NameR = (Cube_Name_Save+\"Radii\")\n",
    "        NameCol = (Cube_Name_Save+\"_Column\")\n",
    "        NameLum = (Cube_Name_Save+\"_Luminosities\")\n",
    "\n",
    "        NameFlux = (Cube_Name_Save+\"Flux_Dense\")\n",
    "        NameRFF = (Cube_Name_Save+\"Rad_For_Flux\")\n",
    "\n",
    "        print(Cube_Name_Save)\n",
    "\n",
    "        #np.save(\"CMZ_Names_New_All_Kinds\",Names)\n",
    "\n",
    "        np.save(Name_File,Names)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        d = astrodendro.Dendrogram.compute(datn,min_delta=m*delt_factor,min_value=m*5*(noise_factor),min_npix=beam_area_ratio.value*pix_thresh_factor) #The main culprit\n",
    "        #d = astrodendro.Dendrogram.compute(datn,min_delta=m,min_value=m*5,min_npix=beam_area_ratio.value) #The main culprit\n",
    "\n",
    "        vel,RA,Dec = scF.world[:,0,0]\n",
    "        Rads,Sigmas,CD,Lumin,SIDS,MOM0FLUX,Distances,V_err = Dendro_Arrays(d,datn,vel,Continuum_Data,metadata,beam_size=Prime_Beam.value,beam_req=beam_req,Trunks=Trunks,max_size =max_size,edge_cases=Edge_cases )\n",
    "\n",
    "\n",
    "        ##Analyze dendograms\n",
    "        pc_per_pixel = abs(header[\"CDELT1\"])/180*np.pi*metadata['distance']/u.Mpc\n",
    "\n",
    "        sig_per_pixel=np.nan#metadata['spectral_resolution']/u.pix\n",
    "\n",
    "\n",
    "        #Finds Size, Linewidth, Luminosity, and Column Density of a structure for each structure and returns them in [[][]] arrays [Leaves][Branches]\n",
    "\n",
    "\n",
    "        from scipy.optimize import curve_fit\n",
    "        from scipy.optimize import leastsq\n",
    "\n",
    "        def func(R,a,b):\n",
    "            return a*R**(b)\n",
    "        try:\n",
    "            popt, pcov = curve_fit(func, Rads[0]*10**6,Sigmas[0])\n",
    "        except:\n",
    "            popt, pcov = [np.nan,np.nan],[[np.nan,np.nan],[np.nan,np.nan]]\n",
    "        try:\n",
    "            poptB, pcovB = curve_fit(func,  Rads[1]*10**6,Sigmas[1])\n",
    "        except:\n",
    "            poptB, pcovB = [np.nan,np.nan],[[np.nan,np.nan],[np.nan,np.nan]]\n",
    "\n",
    "\n",
    "\n",
    "        Rcon = np.concatenate((Rads[0],Rads[1]))\n",
    "\n",
    "\n",
    "        Scon = np.concatenate((Sigmas[0],Sigmas[1]))\n",
    "        Scon2 = np.concatenate((Sigmas[2],Sigmas[3]))\n",
    "        print(np.shape(Rcon))\n",
    "\n",
    "        poptCon, pcovCon = curve_fit(func, Rcon*10**6, Scon)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        xs=np.linspace(np.nanmin(Rcon*10**6),np.nanmax(Rcon*10**6),50)\n",
    "\n",
    "        ysL,ysB,ysCon=func(xs,popt[0],popt[1]),func(xs,poptB[0],poptB[1]),func(xs,poptCon[0],poptCon[1])\n",
    "\n",
    "\n",
    "        LuminCon = np.concatenate((Lumin[0],Lumin[1]))\n",
    "        ColumnCon= np.concatenate((CD[0],CD[1]))\n",
    "\n",
    "        MOM0FLUXcon = np.concatenate((MOM0FLUX[0],MOM0FLUX[1]))\n",
    "        DistancesCon= np.concatenate((Distances[0],Distances[1]))\n",
    "        print(Distances)\n",
    "\n",
    "        #Radius Luminosity fit\n",
    "        #Good pixels are places where the luminosity and therefore column density are above zero\n",
    "        gp = np.where(LuminCon>0)\n",
    "        print(np.shape(Rcon),np.shape(LuminCon))\n",
    "        lgp = LuminCon[gp]\n",
    "        radgp = Rcon[gp]*10**6\n",
    "\n",
    "        gp2 = np.where(ColumnCon>0)\n",
    "        cgp = ColumnCon[gp2]\n",
    "        rgp=Scon[gp2]**2/Rcon[gp2]/10**6\n",
    "        dgp=DistancesCon[gp2]\n",
    "        radgpFORRAT = Rcon[gp2]*10**6\n",
    "        siggpFORRAT = Scon[gp2]\n",
    "        lumFORRAT = LuminCon[gp2]\n",
    "        mom0FORRAT = MOM0FLUXcon[gp2]\n",
    "\n",
    "        #print(np.shape(Rcon[gp]*10**6),np.shape(LuminCon[gp]))\n",
    "\n",
    "        RLpopt,RLpcov = curve_fit(func, np.array(radgp,dtype='float64'),np.array(lgp,dtype='float64'),maxfev=999999,p0 = np.array([10**27,1],dtype='float64'),ftol = 10**-10)\n",
    "\n",
    "        xsRL=np.linspace(np.nanmin(radgp),np.nanmax(radgp),50)\n",
    "        ysRL = func(xsRL,RLpopt[0],RLpopt[1])\n",
    "        #Column density to Size-linewidth\n",
    "        CDpopt,CDpcov = curve_fit(func, np.array(cgp,dtype='float64') ,np.array(rgp,dtype='float64'),maxfev=9999099,p0 = np.array([10,.01],dtype='float64'),ftol = 10**-10)\n",
    "\n",
    "        Dist_popt,Dist_pcov = curve_fit(func, np.array(DistancesCon,dtype='float64') ,np.array(Scon,dtype='float64'),maxfev=9999099,ftol = 10**-10)\n",
    "        Dist_popt2,Dist_pcov2 = curve_fit(func, np.array(dgp,dtype='float64') ,np.array(rgp,dtype='float64'),maxfev=9999099,ftol = 10**-10)\n",
    "\n",
    "        xsDist=np.linspace(np.nanmin(DistancesCon),np.nanmax(DistancesCon),50)\n",
    "        xsDist2=np.linspace(np.nanmin(dgp),np.nanmax(dgp),50)\n",
    "        ysDist=func(xsDist,Dist_popt[0],Dist_popt[1])\n",
    "        ysDist2=func(xsDist2,Dist_popt2[0],Dist_popt2[1])\n",
    "\n",
    "        gp3 = np.where(lumFORRAT>0)\n",
    "        lumFORRAT = lumFORRAT[gp3]\n",
    "        rgpFORRAT = rgp[gp3]\n",
    "        mom0FORRAT = mom0FORRAT[gp3]\n",
    "\n",
    "        xsCD=np.linspace(np.nanmin(cgp),np.nanmax(cgp),50)\n",
    "        ysCD = func(xsCD,CDpopt[0],CDpopt[1])\n",
    "\n",
    "\n",
    "        print(poptCon,pcovCon,\"Size Linewidth All_structures:\")\n",
    "        print(\"a = \",poptCon[0],\"+-\",np.sqrt(pcovCon[0][0]))\n",
    "        print(\"b = \",poptCon[1],\"+-\",np.sqrt(pcovCon[1][1]))\n",
    "\n",
    "\n",
    "        print(RLpopt,RLpcov,\"Radius to Luminosity:\")\n",
    "        print(\"c = \",RLpopt[0],\"+-\",np.sqrt(RLpcov[0][0]))\n",
    "        print(\"d = \",RLpopt[1],\"+-\",np.sqrt(RLpcov[1][1]))\n",
    "\n",
    "\n",
    "\n",
    "        print(CDpopt,CDpcov,\"Column Density to linewidth^2/size:\")\n",
    "        print(\"e = \",CDpopt[0],\"+-\",np.sqrt(CDpcov[0][0]))\n",
    "        print(\"f = \",CDpopt[1],\"+-\",np.sqrt(CDpcov[1][1]))\n",
    "\n",
    "\n",
    "\n",
    "        gp4=np.where(MOM0FLUXcon>0)\n",
    "        mom0FORFlux=MOM0FLUXcon[gp4]\n",
    "        radgpFORFlux=Rcon[gp4]*10**6\n",
    "        rgpFORFlux=Scon[gp4]**2/Rcon[gp4]/10**6\n",
    "\n",
    "\n",
    "        '''\n",
    "\n",
    "        '''\n",
    "        fig = plt.figure(1,figsize=(40,40))\n",
    "\n",
    "\n",
    "        axAlpha = pylab.subplot(5, 5, 7)\n",
    "        axBeta = pylab.subplot(5, 5, 8)\n",
    "        axGamma = pylab.subplot(5, 5, 9)\n",
    "        axDelta = pylab.subplot(5, 5, 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        p1=d.plotter()\n",
    "        p1.plot_tree(axAlpha)\n",
    "        axAlpha.set_xlabel(\"Structure\")\n",
    "        axAlpha.set_ylabel(\"Flux (K)\")\n",
    "        axAlpha.set_title(\"Whole data set\")\n",
    "\n",
    "\n",
    "\n",
    "        #Plot contours for the top ten clusters\n",
    "\n",
    "\n",
    "        #scCropped =scF.moment0().hdu.data\n",
    "        scCropped =scF.moment0().hdu.data\n",
    "        scCropped[np.where(scF.moment0().hdu.data<.22)]=np.nan\n",
    "        print(np.nanmean(np.nanstd(scF.moment0().hdu.data))*1)\n",
    "        scCropped[bp]=np.nan\n",
    "        axDelta = pylab.subplot(5,5,8,projection=scF.moment0().wcs)\n",
    "        #axBeta.imshow(scCropped.moment0().hdu.data, origin='lower', interpolation='nearest', cmap=plt.cm.Blues,norm=colors.LogNorm(vmin=5))\n",
    "        imBeta = axDelta.imshow(scCropped, origin='lower', interpolation='nearest', cmap=plt.cm.Blues,vmin=0,vmax = np.nanmax(scCropped)*.7 )\n",
    "\n",
    "\n",
    "\n",
    "        ColumnCon= np.concatenate((CD[0],CD[1]))\n",
    "        SIDScon = np.concatenate((SIDS[0],SIDS[1]))\n",
    "        nth =0# sorted(CD[0])[len(CD[0])-20]\n",
    "\n",
    "        G1 = True\n",
    "\n",
    "        RA = axDelta.coords[0]                                                                  # \n",
    "        Dec = axDelta.coords[1]\n",
    "\n",
    "        RA.set_ticks(size=-3)                                                                                      \n",
    "        Dec.set_ticks(size=-3) \n",
    "        RA.set_ticklabel(exclude_overlapping=True) \n",
    "        Dec.set_ticklabel(exclude_overlapping=True)                                                                                     \n",
    "        pylab.xlabel('Right Ascension',fontsize=20,labelpad=1)                               \n",
    "        pylab.ylabel('Declination',fontsize=20,labelpad=1)\n",
    "        axDelta.tick_params(axis = 'both', which = 'major', labelsize = 15)    \n",
    "        cb=pylab.colorbar(imBeta,fraction=0.016,pad=0.04)                                     \n",
    "        cb.set_label(label=\"Moment 0 K km/s\",fontsize=10,rotation=270,labelpad=20) \n",
    "        cb.ax.tick_params(which = 'major', labelsize = 10)   \n",
    "        pylab.annotate(s=LineN,fontsize=10,xy=(.01,1.05),xycoords=\"axes fraction\",c=\"black\")  \n",
    "        pylab.annotate(s=\"Highest Density\",fontsize=10,xy=(.31,1.05),xycoords=\"axes fraction\",c=\"red\")  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ax2 = pylab.subplot(5, 5, 1)\n",
    "        ax3 = pylab.subplot(5, 5, 2)\n",
    "        ax4 = pylab.subplot(5, 5, 3)\n",
    "\n",
    "        xpcon = ax2.scatter(Rcon*10**6,Scon,label=\"All_structures\",s=30,alpha=.7)\n",
    "\n",
    "\n",
    "        p = ax2.plot(xs,ysCon)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        st=\"WDS: a=\"+ str(np.format_float_scientific(poptCon[0],1))+\"+-\"+str(np.format_float_scientific(np.sqrt(pcovCon[0][0]),1))+\" b=\"+str(np.format_float_scientific(poptCon[1],1))+\"+-\"+str(np.format_float_scientific(np.sqrt(pcovCon[1][1]),2))\n",
    "        ax2.annotate(s=st,fontsize=10,xy=(0.01,0.01),xycoords=\"axes fraction\")\n",
    "\n",
    "        ax2.annotate(s=r'$\\sigma$ = $a*R^b$',fontsize=10,xy=(0.01,0.10),xycoords=\"axes fraction\")\n",
    "        ax2.set_yscale('log')\n",
    "        ax2.set_xscale('log')\n",
    "        ax2.set_ylim(np.nanmin(Scon),np.nanmax(Scon))\n",
    "        ax2.set_xlabel(\"Size (pc)\",fontsize=12)\n",
    "        ax2.set_ylabel(\"Sigma (km/s)\",fontsize=12)\n",
    "        ax2.legend(prop={'size': 12},loc=\"upper right\")\n",
    "        ax2.annotate(s=LineN,fontsize=10,xy=(0.01,0.89),xycoords=\"axes fraction\")\n",
    "\n",
    "        #gp = np.where(FRs>0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        xspL = ax4.scatter(radgpFORRAT,siggpFORRAT,label=\"All_structures\",s=30)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ax4.set_yscale('log')\n",
    "        ax4.set_xscale('log')\n",
    "\n",
    "        ax4.set_xlabel(\"Radius (pc)\",fontsize=12)\n",
    "        ax4.set_ylabel(\"sig (km/s)\",fontsize=12)\n",
    "        ax4.legend(prop={'size': 12},loc=\"upper right\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        xspF = ax3.scatter(radgpFORRAT,rgp,label=\"All_structures\",s=30)\n",
    "\n",
    "        ax3.annotate(s=st,fontsize=12,xy=(0.01,0.04),xycoords=\"axes fraction\")\n",
    "        ax3.set_yscale('log')\n",
    "        ax3.set_xscale('log')\n",
    "        ax3.set_ylim(np.nanmin(rgp),np.nanmax(rgp))\n",
    "        ax3.set_xlabel(\"Rad (pc)\",fontsize=12)\n",
    "        ax3.set_ylabel(\"Linewidth Ratio (km^2/s^2/pc)\",fontsize=12)\n",
    "        ax3.legend(prop={'size': 12})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ax5 = pylab.subplot(5, 5, 4)\n",
    "        ax6 = pylab.subplot(5, 5, 5)\n",
    "        ax7 = pylab.subplot(5, 5, 6)\n",
    "\n",
    "\n",
    "\n",
    "        xpconhh = ax5.scatter(radgpFORRAT,cgp,label=\"All_structures\",s=30,alpha=.7)\n",
    "        ax5.set_yscale('log')\n",
    "        ax5.set_xscale('log')\n",
    "        ax5.set_xlabel(\"Size (pc)\",fontsize=12)\n",
    "        ax5.set_ylabel(\"Column Density (#/cm^2 > 7e22)\",fontsize=12)\n",
    "        ax5.legend(prop={'size': 12},loc=\"upper right\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        xspF2 = ax6.scatter(cgp,rgp,label=\"All_structures\",s=30,alpha=.7)\n",
    "        pF2 = ax6.plot(xsCD,ysCD)\n",
    "\n",
    "        ax6.set_yscale('log')\n",
    "        ax6.set_xscale('log')\n",
    "        ax6.set_ylim(np.nanmin(rgp),np.nanmax(rgp))\n",
    "        ax6.set_xlabel(\"Column Density (#/cm^2 > 7e22)\",fontsize=12)\n",
    "        ax6.set_ylabel(\"Linewidth Ratio (km^2/s^2/pc)\",fontsize=12)\n",
    "        ax6.legend(prop={'size': 12},loc=\"upper right\")\n",
    "        ax6.annotate(s=LineN,fontsize=10,xy=(0.01,0.89),xycoords=\"axes fraction\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        xspLu2 = ax7.scatter(radgp,lgp,label=\"All_structure Whole Data Set\",s=30,alpha=.7)\n",
    "        pFLLu2 = ax7.plot(xsRL,ysRL)\n",
    "\n",
    "        st = \"WDS, c = \"+ str(np.format_float_scientific(RLpopt[0],3))+\"+-\"+str(np.format_float_scientific(np.sqrt(RLpcov[0][0]),3))+\" d = \"+str(np.format_float_scientific(RLpopt[1],3))+\"+-\"+str(np.format_float_scientific(np.sqrt(RLpcov[1][1]),3))\n",
    "        ax7.annotate(s='L = $c*R^d$',fontsize=12,xy=(0.01,0.13),xycoords=\"axes fraction\")\n",
    "        ax7.annotate(s=st,fontsize=12,xy=(0.01,0.04),xycoords=\"axes fraction\")\n",
    "\n",
    "        ax7.set_yscale('log')\n",
    "        ax7.set_xscale('log')\n",
    "        ax7.set_ylim(np.nanmin(lgp),np.nanmax(lgp))\n",
    "        ax7.set_xlabel(\"Radius (pc)\",fontsize=9)\n",
    "        ax7.set_ylabel(\"Luminosity (erg)\",fontsize=9)\n",
    "        ax7.legend(prop={'size': 12},loc=\"upper right\")\n",
    "        ax7.annotate(s=LineN,fontsize=10,xy=(0.01,0.89),xycoords=\"axes fraction\")\n",
    "\n",
    "\n",
    "        axLam = pylab.subplot(5, 5, 11)\n",
    "        lum_rat = axLam.scatter(lumFORRAT/radgpFORRAT**2,rgpFORRAT,label=\"All_structure  \",s=30,alpha=.7)\n",
    "        #Off by factors for area, simply using r^2\n",
    "\n",
    "        axLam.set_yscale('log')\n",
    "        axLam.set_xscale('log')\n",
    "        axLam.set_xlabel(\"Lum/R^2 (erg/pc^2)\",fontsize=9)\n",
    "        axLam.set_ylabel(\"Linewidth Ratio (km/s)^2/pc\",fontsize=9)\n",
    "        axLam.legend(prop={'size': 12},loc=\"upper right\")\n",
    "        axLam.annotate(s=LineN,fontsize=10,xy=(0.01,0.89),xycoords=\"axes fraction\")\n",
    "\n",
    "\n",
    "\n",
    "        axDelta = pylab.subplot(5, 5, 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        mom0_rat = axDelta.scatter(mom0FORFlux/radgpFORFlux**2,rgpFORFlux,label=\"All_structure  \",s=30,alpha=.7)\n",
    "        #Off by factors for area, simply using r^2\n",
    "\n",
    "        axDelta.set_yscale('log')\n",
    "        axDelta.set_xscale('log')\n",
    "        axDelta.set_xlabel(\"Mom0 Flux/pc^2 (K km/s / R^2)\",fontsize=9)\n",
    "        axDelta.set_ylabel(\"Linewidth Ratio (km/s)^2/pc\",fontsize=9)\n",
    "        axDelta.legend(prop={'size': 12},loc=\"upper right\")\n",
    "        axDelta.annotate(s=LineN,fontsize=10,xy=(0.01,0.89),xycoords=\"axes fraction\")\n",
    "\n",
    "\n",
    "\n",
    "        axdis = pylab.subplot(5, 5, 12)\n",
    "        axdis2 = pylab.subplot(5, 5, 13)\n",
    "        axdis.scatter(DistancesCon,Scon)\n",
    "        axdis2.scatter(dgp,rgp)\n",
    "        axdis.plot(xsDist,ysDist)\n",
    "        axdis2.plot(xsDist2,ysDist2)\n",
    "        axdis2.set_yscale('log')\n",
    "        axdis2.set_xscale('log')\n",
    "        axdis.set_yscale('log')\n",
    "        axdis.set_xscale('log')\n",
    "\n",
    "        pylab.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        v1 = d.viewer()\n",
    "        v1.show()\n",
    "\n",
    "\n",
    "        #Must use text because np load is broken\n",
    "        if(Abs_Level==\"All\"):\n",
    "            Suffix=''\n",
    "        if(Abs_Level==\"None\"):\n",
    "            Suffix='_NA'\n",
    "        if(Abs_Level==\"No Clusters\"):\n",
    "            Suffix='_No_Clusters'\n",
    "        if(Abs_Level==\"None (m)\"):\n",
    "            Suffix='None_m'\n",
    "        if(Abs_Level==\"None All Channels\"):\n",
    "            Suffix='None_All_Channels'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        np.savetxt(os.path.join(savePath,NameCol+\"_Leaves\"+Suffix), CD[0],fmt='%s')\n",
    "        np.savetxt(os.path.join(savePath,NameCol+\"_Branches\"+Suffix), CD[1],fmt='%s')\n",
    "\n",
    "\n",
    "\n",
    "        np.savetxt(os.path.join(savePath,NameLum+\"_Leaves\"+Suffix), Lumin[0],fmt='%s')\n",
    "        np.savetxt(os.path.join(savePath,NameLum+\"_Branches\"+Suffix), Lumin[1],fmt='%s')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        np.savetxt(os.path.join(savePath,NameS+\"_Leaves\"+Suffix), Sigmas[0],fmt='%s')\n",
    "        np.savetxt(os.path.join(savePath,NameS+\"_Branches\"+Suffix), Sigmas[1],fmt='%s')\n",
    "\n",
    "\n",
    "\n",
    "        np.savetxt(os.path.join(savePath,NameR+\"_Leaves\"+Suffix), Rads[0],fmt='%s')\n",
    "        np.savetxt(os.path.join(savePath,NameR+\"_Branches\"+Suffix), Rads[1],fmt='%s')\n",
    "\n",
    "\n",
    "        np.savetxt(os.path.join(savePath,NameFlux+\"_Leaves\"+Suffix), MOM0FLUX[0],fmt='%s')\n",
    "        np.savetxt(os.path.join(savePath,NameFlux+\"_Branches\"+Suffix), MOM0FLUX[1],fmt='%s')\n",
    "\n",
    "\n",
    "\n",
    "        np.savetxt(os.path.join(savePath,Cube_Name_Save+\"Distances_Leaves\"+Suffix), Distances[0],fmt='%s')\n",
    "        np.savetxt(os.path.join(savePath,Cube_Name_Save+\"Distances_Branches\"+Suffix), Distances[1],fmt='%s')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        np.savetxt(os.path.join(savePath,Cube_Name_Save+\"V_err_Leaves\"+Suffix), V_err[0],fmt='%s')\n",
    "        np.savetxt(os.path.join(savePath,Cube_Name_Save+\"V_err_Branches\"+Suffix), V_err[1],fmt='%s')\n",
    "\n",
    "        SIDS=np.concatenate((SIDS[0],SIDS[1]))\n",
    "\n",
    "        print(SIDS[len(SIDS)-3:len(SIDS)-1])\n",
    "\n",
    "        \n",
    "        \n",
    "        import datetime\n",
    "        now = str(datetime.datetime.now())\n",
    "        string=now+ \" \"+ \"Nico's method, common Gauss Smoothing (No Trunks,  min size=.9pc, delt = 1*m, m=.115K, SNR=5, max_size=21pc, G_width = sqrt(2.5^2-1),NM=true )\"\n",
    "        ax2.annotate(s=string,fontsize=18,xy=(0.01,1.0),xycoords=\"axes fraction\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(kl,km,k3,k4)\n",
    "        print(\"Failed\")\n",
    "        print(\"-\"*60)\n",
    "        traceback.print_exc(file=sys.stdout)\n",
    "\n",
    "        if(Abs_Level==\"All\"):\n",
    "            Suffix=''\n",
    "        if(Abs_Level==\"None\"):\n",
    "            Suffix='_NA'\n",
    "        if(Abs_Level==\"No Clusters\"):\n",
    "            Suffix='_No_Clusters'\n",
    "        if(Abs_Level==\"None (m)\"):\n",
    "            Suffix='None_m'\n",
    "        if(Abs_Level==\"None All Channels\"):\n",
    "            Suffix='None_All_Channels'\n",
    "        nans = [[np.nan,np.nan],[np.nan,np.nan]]\n",
    "\n",
    "\n",
    "\n",
    "        np.savetxt(os.path.join(savePath,NameCol+\"_Leaves\"+Suffix), nans[0],fmt='%s')\n",
    "        np.savetxt(os.path.join(savePath,NameCol+\"_Branches\"+Suffix), nans[1],fmt='%s')\n",
    "\n",
    "\n",
    "\n",
    "        np.savetxt(os.path.join(savePath,NameLum+\"_Leaves\"+Suffix), nans[0],fmt='%s')\n",
    "        np.savetxt(os.path.join(savePath,NameLum+\"_Branches\"+Suffix), nans[1],fmt='%s')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        np.savetxt(os.path.join(savePath,NameS+\"_Leaves\"+Suffix), nans[0],fmt='%s')\n",
    "        np.savetxt(os.path.join(savePath,NameS+\"_Branches\"+Suffix), nans[1],fmt='%s')\n",
    "\n",
    "\n",
    "\n",
    "        np.savetxt(os.path.join(savePath,NameR+\"_Leaves\"+Suffix), nans[0],fmt='%s')\n",
    "        np.savetxt(os.path.join(savePath,NameR+\"_Branches\"+Suffix), nans[1],fmt='%s')\n",
    "\n",
    "\n",
    "        np.savetxt(os.path.join(savePath,NameFlux+\"_Leaves\"+Suffix), nans[0],fmt='%s')\n",
    "        np.savetxt(os.path.join(savePath,NameFlux+\"_Branches\"+Suffix), nans[1],fmt='%s')\n",
    "\n",
    "\n",
    "\n",
    "        np.savetxt(os.path.join(savePath,Cube_Name_Save+\"Distances_Leaves\"+Suffix), nans[0],fmt='%s')\n",
    "        np.savetxt(os.path.join(savePath,Cube_Name_Save+\"Distances_Branches\"+Suffix), nans[1],fmt='%s')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        np.savetxt(os.path.join(savePath,Cube_Name_Save+\"V_err_Leaves\"+Suffix), nans[0],fmt='%s')\n",
    "        np.savetxt(os.path.join(savePath,Cube_Name_Save+\"V_err_Branches\"+Suffix), nans[1],fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2575ed1a-d936-4293-b177-99ee034d8534",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#All, all abs levels\n",
    "#Newest method\n",
    "#SL cmz\n",
    "\n",
    "\n",
    "CMZLs = [\"HCO+_1_0\",\"HCN_1_0\",'H13CN_1_0','H13CO+_1_0',\"CO_3_2\",'CO_J3']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Line_Names = ['_NGC_HCOp_J1_0_','_NGC_HCN_J1_0_','','','','_NGC_CO_J3_2_']\n",
    "\n",
    "\n",
    "NM= True\n",
    "\n",
    "Smoothe_4 = False\n",
    "Match_to_HCO = False\n",
    "if(Smoothe_4):\n",
    "    Smoothe_title=\"G_width_4\"\n",
    "else:\n",
    "    Smoothe_title=''\n",
    "    if(Match_to_HCO):\n",
    "        Smoothe_title='Smoothe_to_3.3'\n",
    "Smoothe_2_5 =True\n",
    "if(Smoothe_2_5):\n",
    "    Smoothe_title=\"Smoothe_to_2.5\"\n",
    "\n",
    "Edge_cases=True\n",
    "\n",
    "if(Edge_cases):\n",
    "    Edge_title=\"Edges\"\n",
    "else:\n",
    "    Edge_title=''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if(NM):\n",
    "    #Name_File = \"CMZ_Names_New_All_Kinds_NM_Fixed\"\n",
    "    Name_File = \"CMZ_Names_New_All_Kinds_NM\"+Smoothe_title+Edge_title\n",
    "    NM_mod=\"NM\"\n",
    "else:\n",
    "    #Name_File= \"CMZ_Names_New_All_Kind_Fixed\"\n",
    "    Name_File= \"CMZ_Names_New_All_Kinds\"+Smoothe_title+Edge_title\n",
    "    NM_mod=\"\"\n",
    "\n",
    "CMZNames=list(np.load(Name_File+\".npy\",allow_pickle=True))    \n",
    "\n",
    "\n",
    "#CMZNames=list(np.load(\"CMZ_Names_New_All_Kinds.npy\"))\n",
    "\n",
    "\n",
    "\n",
    "Abs_Levels = [\"All\",\"None\",\"No Clusters\", \"None (m)\", \"None All Channels\"]\n",
    "Suffixes=['','_NA','_No_Clusters','None_m','None_All_Channels']\n",
    "savePath='/home/ben/Documents/Grad Stuff/MM data/Result Files'\n",
    "\n",
    "\n",
    "Plot=True\n",
    "for i in range(0,6):\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    Params=np.genfromtxt(os.path.join(savePath,\"_NGC_CO_J3_2_\"+\"_Params\"))#[iterations,iter_factor ,Line_Name,Name,ovs,min_vel,FOV,Min_res,Min_beam_req]\n",
    "    iterations,iter_factor,ovs,min_vel,FOV,Min_res,Min_beam_req = int(Params[0]),Params[1],int(Params[2]),Params[3],np.array(Params[4]),Params[5],Params[6]\n",
    "    iterations=6\n",
    "    for kl in range(5,6):\n",
    "        \n",
    "        if(Line_Names[i]==''):\n",
    "            break\n",
    "    \n",
    "        \n",
    "        \n",
    "        Prime_Beam = Min_res*((kl*iter_factor+1))#\n",
    "        if(kl==5):\n",
    "            if(i==5):\n",
    "                Prime_Beam=3\n",
    "            else:\n",
    "                Prime_Beam=4.3\n",
    "        print(Prime_Beam)\n",
    "    \n",
    "    \n",
    "        for km in range(5,6):\n",
    "            \n",
    "            vel_prime = min_vel*((km*iter_factor+1))\n",
    "            \n",
    "            if(km==5):\n",
    "                if(i==5):\n",
    "                    vel_prime=2.5\n",
    "                else:\n",
    "                    vel_prime=3.3\n",
    "            fig = plt.figure(1,figsize=(8,8))\n",
    "            gs0 = gridspec.GridSpec(len(Suffixes), 1, figure=fig)\n",
    "            \n",
    "            \n",
    "            \n",
    "            min_space=np.array([[np.full(100,Prime_Beam/ovs)],[np.linspace(-100,1000,100)]])\n",
    "            Beams_s=np.array([[np.full(100,Prime_Beam)],[np.linspace(-100,1000,100)]])\n",
    "            spec=np.array([[np.linspace(-100,1000,100)],[np.full(100,vel_prime)]])\n",
    "            zeroes=np.array([[np.full(100,0)]])\n",
    "            \n",
    "            \n",
    "            #for k5 in range(len(Suffixes)):\n",
    "            for k5 in range(0,1):\n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "                Suffix=Suffixes[k5]\n",
    "                Abs_Level =Abs_Levels[k5]\n",
    "\n",
    "                \n",
    "                \n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                #fig.suptitle((CMZLs[i]+\" Size-Linewidth Relation (\"+str(Abs_Level)+\")\"), fontsize=18)\n",
    "                #gs0.set_title((CMZLs[i]+\" Size-Linewidth Relation (\"+str(Abs_Level)+\")\"), fontsize=18)\n",
    "                \n",
    "                gs00 = gridspec.GridSpecFromSubplotSpec(iterations, iterations, subplot_spec=gs0[k5])\n",
    "\n",
    "                \n",
    "                \n",
    "\n",
    "                for k3 in range(2,3):\n",
    "\n",
    "                    beam_req = Min_beam_req*(k3+1)\n",
    "                    if kl==5:\n",
    "                        beam_req=.9/3\n",
    "                    \n",
    "                    beam_req_line = Beams_s*beam_req\n",
    "                    for k4 in range(0,1):\n",
    "                        for k6 in range(2,3):\n",
    "                            delt_factor = (3/5+k6/5)\n",
    "\n",
    "                            for k7 in range(2,3):\n",
    "                                noise_factor = (3/5+k7/5)\n",
    "                                \n",
    "                                \n",
    "                                print(kl,km,k3,k4,k6,k7)\n",
    "                                \n",
    "                                #ax = fig.add_subplot(gs00[k6, k7])\n",
    "                                ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "                                try:\n",
    "\n",
    "                                    pix_thresh_factor = k4+1\n",
    "\n",
    "                                    Name = CMZNames[i][kl][km][k3][k4][k6][k7]\n",
    "                                    print(CMZNames[i][kl][km][k3][k4])\n",
    "                                    #print(Name)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                                    rname=Name+\"Radii\"\n",
    "\n",
    "                                    sname=Name+\"Sigmas\"\n",
    "\n",
    "                                    sEname=Name+\"V_err\"\n",
    "\n",
    "                                    radsBase=[[],[]]\n",
    "                                    sigsBase=[[],[]]\n",
    "\n",
    "                                    sigs_err_Base=[[],[]]\n",
    "                                    radsBase[0],radsBase[1] = np.genfromtxt(os.path.join(savePath,rname+\"_Leaves\"+Suffix))*10**6, np.genfromtxt(os.path.join(savePath,rname+\"_Branches\"+Suffix))*10**6#km/s\n",
    "                                    sigsBase[0] ,sigsBase[1] = np.genfromtxt(os.path.join(savePath,sname+\"_Leaves\"+Suffix)),np.genfromtxt(os.path.join(savePath,sname+\"_Branches\"+Suffix))#km/s\n",
    "                                    \n",
    "                                    sigs_err_Base[0] ,sigs_err_Base[1] = np.genfromtxt(os.path.join(savePath,sEname+\"_Leaves\"+Suffix)),np.genfromtxt(os.path.join(savePath,sEname+\"_Branches\"+Suffix))#km/s\n",
    "\n",
    "\n",
    "\n",
    "                                    er_r=1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                                    rads=np.concatenate((radsBase[0],radsBase[1]))\n",
    "                                    \n",
    "                                    sigs = np.concatenate((sigsBase[0],sigsBase[1]))\n",
    "                                    sigs_err = np.concatenate((sigs_err_Base[0],sigs_err_Base[1]))\n",
    "                                    print(np.shape(rads))\n",
    "\n",
    "                                    from scipy.optimize import curve_fit\n",
    "\n",
    "                                    def func(R,a,b):\n",
    "                                        return a*R**(b)\n",
    "\n",
    "                                    x   =  rads\n",
    "                                    y     = sigs\n",
    "                                    y_err = sigs_err\n",
    "\n",
    "                                    try:\n",
    "                                        #(Vars, CoVar) = (curve_fit(func, x, y, sigma=y_err))\n",
    "                                        (Vars, CoVar) = (curve_fit(func, x, y, ))\n",
    "                                    except:\n",
    "                                        (Vars, CoVar) = [np.nan,np.nan],[[np.nan,np.nan],[np.nan,np.nan]]\n",
    "                                    np.savetxt(os.path.join(savePath,Name+\"_CMZ_Coeffs\"+Suffix+NM_mod), Vars,fmt='%s')\n",
    "                                    np.savetxt(os.path.join(savePath,Name+\"_CMZ_Coeff_CoVar\"+Suffix+NM_mod),CoVar ,fmt='%s')\n",
    "\n",
    "                                    np.savetxt(os.path.join(savePath,Name+\"_CMZ_Fit_weights\"+Suffix+NM_mod),[(len(sigs))] ,fmt='%s')\n",
    "                                    #np.savetxt(CMZName+\"_CMZ_Coeffs\"+Suffix, Vars2,fmt='%s')\n",
    "                                    #np.savetxt(CMZName+\"_CMZ_Coeff_CoVar\"+Suffix,CoVar2 ,fmt='%s')\n",
    "\n",
    "                                    if Plot:\n",
    "                                        print(Vars,CoVar)\n",
    "                                        #gggg=ax.plot(x,func(x,Vars[0],Vars[1]),color=\"Red\",label=CMZLs[i])\n",
    "                                        #ax.fill_between(x,func(x,Vars[0]+np.sqrt(CoVar[0][0])*er_r,Vars[1]+np.sqrt(CoVar[1][1])*er_r),func(x,Vars[0]-np.sqrt(CoVar[0][0])*er_r,Vars[1]-np.sqrt(CoVar[1][1])*er_r),alpha=.2,color=\"Red\")\n",
    "                                        #ax.errorbar(x, y, yerr=y_err,lolims=True, uplims=True,fmt=\"o\",color=\"Blue\")\n",
    "                                        \n",
    "                                        ax.fill_betweenx(beam_req_line[1][0],beam_req_line[0][0] ,zeroes[0][0], alpha=.1,color=\"Black\")\n",
    "                                        ax.plot(Beams_s[0][0],Beams_s[1][0], alpha=.1,color=\"Black\")\n",
    "\n",
    "                                        spec=np.array([[np.linspace(-100,1000,100)],[np.full(100,vel_prime)]])\n",
    "\n",
    "                                        ax.plot(spec[0][0],spec[1][0], alpha=.1,color=\"Black\")\n",
    "\n",
    "                                        #ax.scatter(x,y,color=\"Red\",alpha=.51,s=50)\n",
    "\n",
    "\n",
    "\n",
    "                                        ax.set_xlabel(r'$R_{astrodendro}$ (pc)',fontsize=15)\n",
    "                                        ax.set_ylabel(r'$\\sigma   (km/s)$',fontsize=15)\n",
    "                                        ax.set_yscale('log')\n",
    "                                        ax.set_xscale('log')\n",
    "                                        #string = (\"NGC253 (Binned\"+Suffix+\"): a=\"+str(round(Vars[0],3))+\" +-\" + str(round(np.sqrt(CoVar[0][0]),3)) +\", b=\"+str(round(Vars[1],3))+\"+-\" + str(round(np.sqrt(CoVar[1][1]),3)) )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                                        #axA.annotate(text=string,fontsize=18,xy=(0.01,.01+0.025*Index),xycoords=\"axes fraction\")\n",
    "                                        ax.set_xlim(0.5,40.0)\n",
    "                                        ax.set_ylim(0.5,50.0)\n",
    "\n",
    "                                        #axA.legend(loc='upper left',fontsize=18)\n",
    "\n",
    "                                        import datetime\n",
    "                                        now = str(datetime.datetime.now())\n",
    "                                        string=now+ \" \"+ \"Nico's method, common Gauss Smoothing (No Trunks,  min size=.9pc, delt = 1*m, m=.115K, SNR=5, max_size=21pc, G_width = sqrt(2.5^2-1),NM=true )\"\n",
    "                                        ax.annotate(text=string,fontsize=18,xy=(0.01,1.05),xycoords=\"axes fraction\")\n",
    "                                        \n",
    "                                        \n",
    "                                        ax.set_title((\"beam={0},vel_res={1},beam_req={2},pix_thresh={3},abs={4},delta={5},SNR={6}\".format(Prime_Beam,vel_prime,beam_req,pix_thresh_factor,Abs_Level,delt_factor,noise_factor*5)), fontsize=14)\n",
    "                                        if i==5:\n",
    "\n",
    "                                            def NicoCOCoef(sig10,exp):\n",
    "                                                return sig10/10**exp\n",
    "                                            def NicoAErr(Aer,b,bErr):\n",
    "                                                return np.sqrt(Aer**2/10**(2*b)+b**2*Aer**2*bErr**2/b**(2*b+2))\n",
    "\n",
    "                                            Nxs=np.linspace(np.nanmin(.5),np.nanmax(20),50)\n",
    "                                            xs=np.linspace(np.nanmin(.9),np.nanmax(20),50)\n",
    "                                            NicoCO32 = .72\n",
    "                                            NicoCOErr32=.03\n",
    "                                            NicoCO_32= 8.9\n",
    "                                            NicoCO_32Err= .2\n",
    "                                            NNicoCO32 = .62\n",
    "                                            NNicoCOErr32=.01\n",
    "                                            NNicoCO_32=17.1\n",
    "                                            NNicoCO_32Err= .1\n",
    "\n",
    "\n",
    "                                            NNI32 = func(Nxs,NicoCOCoef(NNicoCO_32,NNicoCO32),NNicoCO32)\n",
    "                                            NNIU32 = func(Nxs,NicoCOCoef(NNicoCO_32+NicoAErr(NNicoCO_32Err,NNicoCO32,NNicoCOErr32)*er_r,NNicoCO32+NNicoCOErr32*er_r),NNicoCO32+ NNicoCOErr32*er_r)\n",
    "                                            NNIL32 = func(Nxs,NicoCOCoef(NNicoCO_32-NicoAErr(NNicoCO_32Err,NNicoCO32,NNicoCOErr32)*er_r,NNicoCO32-NNicoCOErr32*er_r),NNicoCO32- NNicoCOErr32*er_r)\n",
    "\n",
    "                                            NCI32 = func(xs,NicoCOCoef(NicoCO_32,NicoCO32),NicoCO32)\n",
    "                                            NCIU32 = func(xs,NicoCOCoef(NicoCO_32+NicoAErr(NicoCO_32Err,NicoCO32,NicoCOErr32)*er_r,NicoCO32+NicoCOErr32*er_r),NicoCO32+ NicoCOErr32*er_r)\n",
    "                                            NCIL32 = func(xs,NicoCOCoef(NicoCO_32-NicoAErr(NicoCO_32Err,NicoCO32,NicoCOErr32)*er_r,NicoCO32-NicoCOErr32*er_r),NicoCO32- NicoCOErr32*er_r)\n",
    "\n",
    "\n",
    "\n",
    "                                            NicoNM32 = ax.plot(xs,NCI32,c='black',label='Krieger CO_3-2 CMZ')\n",
    "                                            NicoFill32 = ax.fill_between(xs,NCIL32,NCIU32,color=\"black\",alpha=.2)\n",
    "                                            \n",
    "                                            \n",
    "                                            \n",
    "                                            #cmz bins\n",
    "                                            xs=np.linspace(np.nanmin(rads),np.nanmax(rads),50)\n",
    "                                            Bin_s=[]\n",
    "                                            Bin_s16=[]\n",
    "                                            Bin_s84=[]\n",
    "                                            s_err=[]\n",
    "                                            Bin_rad=[]\n",
    "                                            bins=[]\n",
    "                                            '''\n",
    "                                            bins = np.logspace(np.log10(np.nanmin(rads)),np.log10(np.nanmax(rads)),15)\n",
    "                                            bins=list(bins)\n",
    "                                            for lmi in range(len(bins)-1):\n",
    "                                                SBin=[]\n",
    "                                                for lmj in range(len(rads)):\n",
    "                                                    if(rads[lmj]>bins[lmi] and rads[lmj]<bins[lmi+1]):\n",
    "                                                        SBin.append(sigs[lmj])\n",
    "                                                if(str(np.nanmean(SBin))!=str(np.nan) and str(np.nanmean(SBin))!= str(np.inf)):\n",
    "                                                    \n",
    "                                                    if False:\n",
    "                                                        Bin_s.append(np.nanmean(SBin))\n",
    "                                                        s_err.append(np.nanstd(SBin))\n",
    "                                                    else:\n",
    "                                                        y_perc = np.percentile(SBin, [16,50,84])\n",
    "                                                        #Bin_s.append(y_perc[1])\n",
    "                                                        Bin_s.append(np.nanmean(SBin))\n",
    "                                                        Bin_s16.append(y_perc[0])\n",
    "                                                        Bin_s84.append(y_perc[2])\n",
    "                                                        err= (y_perc[1]-y_perc[0]+ y_perc[2]-y_perc[1])/2#apparently the error\n",
    "                                                        s_err.append(err)\n",
    "                                                        #print(y_perc[1],np.nanmean(SBin),\"err\",err,np.nanstd(SBin))\n",
    "                                                        #print(\"#  16th 50th 84th\")\n",
    "                                                        #print(lmi,y_perc[0],y_perc[1],y_perc[2])\n",
    "\n",
    "                                                else:\n",
    "                                                    Bin_s.append(np.nan)\n",
    "                                                    #Ns_err.append(np.nan)\n",
    "                                                    s_err.append(np.nan)\n",
    "\n",
    "                                            Bin_s.append(np.nan)\n",
    "                                            s_err.append(np.nan)#get right shapes\n",
    "                                            del Bin_s[len(Bin_s)-1]\n",
    "                                            del s_err[len(s_err)-1]\n",
    "                                            del bins[len(bins)-1]\n",
    "                                            bw = (bins[0+1]-bins[0])\n",
    "                                            '''\n",
    "                                            def filter_window(x,y,window_min,window_max):\n",
    "                                                \"\"\"select values in the window\"\"\"\n",
    "                                                x_window = x[(window_min<x) & (x<window_max)]\n",
    "                                                y_window = y[(window_min<x) & (x<window_max)]\n",
    "                                                return x_window,y_window\n",
    "                                            \n",
    "                                            \n",
    "                                            def crossmatch(*args):\n",
    "                                                \"\"\"Crossmatch lists for non-finite values.\n",
    "                                                Parameters\n",
    "                                                ----------\n",
    "                                                x : list\n",
    "                                                y : list\n",
    "                                                ...\n",
    "                                                Returns\n",
    "                                                -------\n",
    "                                                list, list\n",
    "                                                    Lists in input order with the non-finite (infinite and NaN) values removed from the list and\n",
    "                                                    also the corresponding element of the other list.\n",
    "                                                \"\"\"\n",
    "                                                import numpy as np\n",
    "\n",
    "                                                lists = []\n",
    "                                                for list in args:\n",
    "                                                    lists.append( np.array(list) )\n",
    "\n",
    "                                                selection = np.isfinite(lists[0])\n",
    "                                                for list in lists[1:]:\n",
    "                                                    selection = selection & np.isfinite(list)\n",
    "\n",
    "                                                matched_lists = []\n",
    "                                                for list in lists:\n",
    "                                                    matched_lists.append( list[selection] )\n",
    "\n",
    "                                                return matched_lists\n",
    "                                            def get_binned_percentiles(x_measure, y_measure, x_step, xdata, ydata):\n",
    "\n",
    "                                                from astropy.table import Table\n",
    "\n",
    "                                                def filter_window(x,y,window_min,window_max):\n",
    "                                                    \"\"\"select values in the window\"\"\"\n",
    "                                                    x_window = x[(window_min<x) & (x<window_max)]\n",
    "                                                    y_window = y[(window_min<x) & (x<window_max)]\n",
    "                                                    return x_window,y_window\n",
    "\n",
    "\n",
    "                                                # binned percentiles table\n",
    "                                                bin_perc = Table(names = ['window min','window center','window max','x 16th','x median','x 84th','y 16th','y median','y 84th'],\n",
    "                                                                 meta = {'x': x_measure, 'y': y_measure, 'x_step': x_step}\n",
    "                                                                )\n",
    "\n",
    "                                                x_matched, y_matched = crossmatch(xdata,ydata)\n",
    "\n",
    "                                                x_min = np.nanmin(x_matched)\n",
    "                                                x_max = np.nanmax(x_matched)\n",
    "                                                y_min = np.nanmin(y_matched)\n",
    "                                                y_max = np.nanmax(y_matched)\n",
    "\n",
    "                                                for log_window_cen in np.arange(np.log10(x_min), np.log10(x_max)+x_step, x_step):\n",
    "                                                    log_window_min = log_window_cen-x_step/2.\n",
    "                                                    log_window_max = log_window_cen+x_step/2.\n",
    "                                                    window_min = np.power(10,log_window_min)\n",
    "                                                    window_cen = np.power(10,log_window_cen)\n",
    "                                                    window_max = np.power(10,log_window_max)\n",
    "                                                    x_window,y_window = filter_window(x_matched,y_matched,window_min,window_max)\n",
    "\n",
    "                                                    # percentiles only make sense when at least two measurements are available\n",
    "                                                    if len(x_window)>1:\n",
    "                                                        x_perc = np.percentile(x_window, [16,50,84])\n",
    "                                                        y_perc = np.percentile(y_window, [16,50,84])\n",
    "                                                        bin_perc.add_row( flatten([window_min,window_cen,window_max,x_perc,y_perc]) )\n",
    "\n",
    "                                                return bin_perc\n",
    "                                            def flatten(x):\n",
    "                                                \"\"\"Flatten list of lists.\n",
    "                                                Parameters\n",
    "                                                ----------\n",
    "                                                x : list,tuple\n",
    "                                                    List of lists of lists of ...\n",
    "                                                    Can contain a mixture of lists and values.\n",
    "                                                Returns\n",
    "                                                -------\n",
    "                                                list\n",
    "                                                    Flattened list.\n",
    "                                                \"\"\"\n",
    "                                                import collections\n",
    "                                                if isinstance(x, collections.Iterable):\n",
    "                                                    return [a for i in x for a in flatten(i)]\n",
    "                                                else:\n",
    "                                                    return [x]\n",
    "\n",
    "\n",
    "\n",
    "                                                # binned percentiles table\n",
    "                                                bin_perc = Table(names = ['window min','window center','window max','x 16th','x median','x 84th','y 16th','y median','y 84th'],\n",
    "                                                                 meta = {'x': x_measure, 'y': y_measure, 'x_step': x_step}\n",
    "                                                                )\n",
    "\n",
    "                                                x_matched, y_matched = crossmatch(xdata,ydata)\n",
    "\n",
    "                                                x_min = np.nanmin(x_matched)\n",
    "                                                x_max = np.nanmax(x_matched)\n",
    "                                                y_min = np.nanmin(y_matched)\n",
    "                                                y_max = np.nanmax(y_matched)\n",
    "\n",
    "                                                for log_window_cen in np.arange(np.log10(x_min), np.log10(x_max)+x_step, x_step):\n",
    "                                                    log_window_min = log_window_cen-x_step/2.\n",
    "                                                    log_window_max = log_window_cen+x_step/2.\n",
    "                                                    window_min = np.power(10,log_window_min)\n",
    "                                                    window_cen = np.power(10,log_window_cen)\n",
    "                                                    window_max = np.power(10,log_window_max)\n",
    "                                                    x_window,y_window = filter_window(x_matched,y_matched,window_min,window_max)\n",
    "\n",
    "                                                    # percentiles only make sense when at least two measurements are available\n",
    "                                                    if len(x_window)>1:\n",
    "                                                        x_perc = np.percentile(x_window, [16,50,84])\n",
    "                                                        y_perc = np.percentile(y_window, [16,50,84])\n",
    "                                                        bin_perc.add_row( flatten([window_min,window_cen,window_max,x_perc,y_perc]) )\n",
    "\n",
    "                                                return bin_perc\n",
    "                                            x_matched, y_matched = crossmatch(rads,sigs)\n",
    "\n",
    "                                            x_step=.1\n",
    "                                            x_min = np.nanmin(rads)\n",
    "                                            x_max = np.nanmax(rads)\n",
    "                                            #y_min = np.nanmin(y_matched)\n",
    "                                            #y_max = np.nanmax(y_matched)\n",
    "\n",
    "                                            for log_window_cen in np.arange(np.log10(x_min), np.log10(x_max)+x_step, x_step):\n",
    "                                                log_window_min = log_window_cen-x_step/2.\n",
    "                                                log_window_max = log_window_cen+x_step/2.\n",
    "                                                window_min = np.power(10,log_window_min)\n",
    "                                                window_cen = np.power(10,log_window_cen)\n",
    "                                                window_max = np.power(10,log_window_max)\n",
    "                                                x_window,y_window = filter_window(x_matched,y_matched,window_min,window_max)\n",
    "\n",
    "                                                # percentiles only make sense when at least two measurements are available\n",
    "                                                if len(x_window)>1:\n",
    "                                                    x_perc = np.percentile(x_window, [16,50,84])\n",
    "                                                    y_perc = np.percentile(y_window, [16,50,84])\n",
    "                                                    #bin_perc.add_row( flatten([window_min,window_cen,window_max,x_perc,y_perc]) )\n",
    "                                                    bins.append(window_cen)\n",
    "                                                    Bin_s.append(y_perc[1])\n",
    "                                                    #Bin_s.append(np.nanmean(SBin))\n",
    "                                                    Bin_s16.append(y_perc[0])\n",
    "                                                    Bin_s84.append(y_perc[2])\n",
    "                                                    err= (y_perc[1]-y_perc[0]+ y_perc[2]-y_perc[1])/2#apparently the error\n",
    "                                                    s_err.append(err)\n",
    "                                                    #print(y_perc[1],np.nanmean(SBin),\"err\",err,np.nanstd(SBin))\n",
    "                                                    #print(\"#  16th 50th 84th\")\n",
    "                                                    #print(lmi,y_perc[0],y_perc[1],y_perc[2])\n",
    "                                            er_r=1\n",
    "                                            \n",
    "                                            '''\n",
    "                                            xp1BinC = ax.plot([bins[0],bins[1]], [Bin_s[0],Bin_s[0]],c=\"blue\",alpha=1,label=(\"Binned CMZ CO 3-2 fit\"))\n",
    "                                            '''\n",
    "                                            #xp1BinC = ax.plot([bins[0],bins[1]], [Bin_s[0],Bin_s[0]],c=\"blue\",alpha=1,label=(\"Binned CMZ CO 3-2 fit\"))\n",
    "                                            '''\n",
    "                                            for lmi in range(len(bins)):\n",
    "                                                if((s_err[lmi])==0.0):            \n",
    "                                                    s_err[lmi] = Bin_s[lmi]#Only one structure in a bin gives a large error\n",
    "                                            '''\n",
    "                                            '''\n",
    "\n",
    "\n",
    "                                            for w in range(len(bins)-1):\n",
    "                                                bw = (bins[w+1]-bins[w])\n",
    "                                                xp1BinC = ax.plot([bins[w],bins[w+1]], [Bin_s[w],Bin_s[w]],c=\"blue\",alpha=1)\n",
    "                                                \n",
    "                                                ax.fill_between([bins[w],bins[w+1]], Bin_s16[w],Bin_s84[w], color='blue', alpha=.3)\n",
    "                                                \n",
    "                                                #ax.add_patch(Rectangle(\n",
    "                                                #xy=(bins[w], Bin_s[w]-s_err[w]*er_r) ,width=bw, height=s_err[w]*er_r*2,\n",
    "                                                #linewidth=1, color='blue', fill=True,alpha=.3,))\n",
    "                                                \n",
    "                                            Bin_Centers=[]\n",
    "                                            for lmi in range(len(bins)-1):\n",
    "                                                Bin_Centers.append((bins[lmi]+bins[lmi+1])/2)\n",
    "        \n",
    "                                            del Bin_s[len(Bin_s)-1]\n",
    "                                            del s_err[len(s_err)-1]\n",
    "\n",
    "                                            for lmi in range(len(bins)-1):\n",
    "                                                if(lmi>len(Bin_s)-1):\n",
    "                                                    break\n",
    "                                                #print(lmi,len(NBin_s),len(Bin_Centers))\n",
    "                                                if(str(Bin_s[lmi])==str(np.nan)):\n",
    "                                                    del Bin_s[lmi]\n",
    "                                                    del Bin_Centers[lmi]\n",
    "                                                    del s_err[lmi]\n",
    "                                                elif((s_err[lmi])==0.0):\n",
    "                                                    s_err[lmi] = Bin_s[lmi]#Only one structure in a bin gives a large error\n",
    "                                            #(popt_bin, pcov_bin) = (curve_fit(func, Bin_Centers, Bin_s,sigma=s_err))#Should 'perfectly' replcate krieger\n",
    "                                            '''\n",
    "                                            '''(popt_bin, pcov_bin) = (curve_fit(func, Bin_Centers, Bin_s,sigma=s_err))#Should 'perfectly' replcate krieger\n",
    "                                            '''\n",
    "                                            \n",
    "                                            x     = np.array(bins)\n",
    "                                            y     = np.array(Bin_s)\n",
    "                                            y_p16 = np.array(Bin_s16)\n",
    "                                            y_p84 = np.array(Bin_s84)\n",
    "                                            print(y)\n",
    "                                            print(y_p16)\n",
    "                                            print(y_p84)\n",
    "                                            print(np.shape(y))\n",
    "                                            print(np.shape(y_p16))\n",
    "                                            print(np.shape(y_p84))\n",
    "                                            print(type(y))\n",
    "                                            print(type(y_p16))\n",
    "                                            print(type(y_p84))\n",
    "                                            \n",
    "                                            print(y-y_p16)\n",
    "                                            print(y_p84-y)\n",
    "                                            y_err = np.nanmean([y-y_p16, y_p84-y], axis=0)\n",
    "\n",
    "                                            fit = fit_MCMC(log_x     = np.log10(x),\n",
    "                                                           log_y     = np.log10(y),\n",
    "                                                           log_x_err = [0.05 for x in x],            # half bin width\n",
    "                                                           log_y_err = np.log10(y_err),\n",
    "                                                           source=\"GC\", line=\"co 3-2\",\n",
    "                                                           xlabel =\" R_measure.replace('_',' ')\",\n",
    "                                                           ylabel = \"lw_measure.replace('%',r'\\%')\",\n",
    "                                                           savepath = \"\"\n",
    "                                                          )\n",
    "                                            \n",
    "                                            (popt_bin, pcov_bin) = [np.nan,np.nan],[[np.nan,np.nan],[np.nan,np.nan]]\n",
    "                                            \n",
    "                                            \n",
    "                                            bins = get_binned_percentiles(\"R_measure\", \"lw_measure\",\n",
    "                                              x_step = 0.1,\n",
    "                                              xdata  = x_matched,\n",
    "                                              ydata  = y_matched\n",
    "                                             )\n",
    "                                            \n",
    "                                            print(\"j\",bins)\n",
    "                                            i = 0\n",
    "                                            for bin in bins:\n",
    "                                                window = [bin['window min'], bin['window max']]\n",
    "                                                window_cen = bin['window center']\n",
    "                                                median = [bin['y median'], bin['y median']]\n",
    "                                                perc16 = [bin['y 16th'], bin['y 16th']]\n",
    "                                                perc84 = [bin['y 84th'], bin['y 84th']]\n",
    "\n",
    "                                                ax.plot(window, median,                 color=\"purple\",                                zorder=3, label='')\n",
    "                                                ax.fill_between(window, perc16, perc84, facecolor=\"purple\", edgecolor=None, alpha=0.5, zorder=2, label='')\n",
    "                                                i += 1\n",
    "\n",
    "                                            x = np.logspace(np.log10(np.min(bins['window min'])), np.log10(np.max(bins['window max'])), 100)\n",
    "                                            if gal ==\"GC\":\n",
    "                                                ax.plot(x, powlaw(x,fit.a['ls'][0],np.power(10,fit.c['ls'][0])), color=\"blue\", zorder=4,label=\"co 3-2 cmz with kr analysis\")\n",
    "                                            else:\n",
    "                                                ax.plot(x, powlaw(x,fit.a['ls'][0],np.power(10,fit.c['ls'][0])), color=\"blue\", zorder=4,label=\"co 3-2 NGC253 with kr analysis\")\n",
    "                                            \n",
    "                                            \n",
    "                                            print(\"AAAAA\", fit.a['ls'][0]     ,    fit.a['ls'][1]   ,      fit.y10['ls'][0], fit.y10['ls'][1])\n",
    "                                            \n",
    "                                            \n",
    "                                            #gggghg=ax.plot(Bin_Centers,func(Bin_Centers,popt_bin[0],popt_bin[1]),color=\"blue\",label=\"Binned fit \")\n",
    "                                            #fbbff=ax.fill_between(Bin_Centers,func(Bin_Centers,popt_bin[0]+np.sqrt(pcov_bin[0][0])*er_r,popt_bin[1]+np.sqrt(pcov_bin[1][1])*er_r),func(Bin_Centers,popt_bin[0]-np.sqrt(pcov_bin[0][0])*er_r,popt_bin[1]-np.sqrt(pcov_bin[1][1])*er_r),alpha=.2,color=\"blue\")\n",
    "\n",
    "\n",
    "\n",
    "                                    ax.legend(loc='upper left',fontsize=18)\n",
    "\n",
    "                                    print(i,kl,km,k3,k4,k5,k6,k7,\"Clear\")\n",
    "                                except Exception as e:\n",
    "                                    print(e)\n",
    "                                    print(i,kl,km,k3,k4,k5,k6,k7,\"F\")\n",
    "                                    print(Name)\n",
    "                                    print(\"Failed\")\n",
    "                                    print(\"-\"*60)\n",
    "                                    traceback.print_exc(file=sys.stdout)\n",
    "                                if Plot:\n",
    "                                \n",
    "                                    plt.tight_layout(pad=5, w_pad=5 ,h_pad=50.0)\n",
    "\n",
    "                                    pylab.show()\n",
    "                                    fname = \"All_\"+str(Prime_Beam)+\"_beam_\"+str(vel_prime) +\"_vel_res_\"+Suffix+\"_.jpeg\"\n",
    "                                    fig.savefig(bbox_inches='tight',fname=fname)\n",
    "                                    \n",
    "                                    \n",
    "                                    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
